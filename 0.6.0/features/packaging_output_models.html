<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Packaging Olive artifacts &mdash; Olive  documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../_static/autodoc_pydantic.css" />
      <link rel="stylesheet" type="text/css" href="../_static/tabs.css?v=a5c4661c" />
      <link rel="stylesheet" type="text/css" href="../_static/css/width.css?v=b55249da" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=b3ba4146"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
        <script src="../_static/js/custom_version.js?v=3856a39b"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Custom Scripts" href="custom_scripts.html" />
    <link rel="prev" title="Huggingface Model Optimization" href="huggingface_model_optimization.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Olive
          </a>
              <div class="version">
                0.6.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">OVERVIEW</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../overview/olive.html">Olive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overview/quicktour.html">Quick Tour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overview/options.html">Olive Options</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">GET STARTED</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../getstarted/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getstarted/quickstart_examples.html">Quickstart Examples</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">EXAMPLES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../examples.html">Examples</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FEATURES</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="cli.html">Command Line Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_transformations_and_optimizations.html">Model Transformations and Optimizations</a></li>
<li class="toctree-l1"><a class="reference internal" href="huggingface_model_optimization.html">Huggingface Model Optimization</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Packaging Olive artifacts</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#what-is-olive-packaging">What is Olive Packaging</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#zipfile">Zipfile</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#candidatemodels">CandidateModels</a></li>
<li class="toctree-l4"><a class="reference internal" href="#samplecode">SampleCode</a></li>
<li class="toctree-l4"><a class="reference internal" href="#models-rank-json-file">Models rank JSON file</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#azuremlmodels">AzureMLModels</a></li>
<li class="toctree-l3"><a class="reference internal" href="#azuremldata">AzureMLData</a></li>
<li class="toctree-l3"><a class="reference internal" href="#azuremldeployment">AzureMLDeployment</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#how-to-package-olive-artifacts">How to package Olive artifacts</a></li>
<li class="toctree-l2"><a class="reference internal" href="#packaged-files">Packaged files</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#inference-config-file">Inference config file</a></li>
<li class="toctree-l3"><a class="reference internal" href="#model-configuration-file">Model configuration file</a></li>
<li class="toctree-l3"><a class="reference internal" href="#metrics-file">Metrics file</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="custom_scripts.html">Custom Scripts</a></li>
<li class="toctree-l1"><a class="reference internal" href="azureml_integration.html">Azure ML integration</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">EXTENDING OLIVE</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../extending_olive/design.html">Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../extending_olive/how_to_add_optimization_pass.html">How to add new optimization Pass</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">TUTORIALS</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/configure_systems.html">How To Configure System</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/configure_metrics.html">How To Configure Metric</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/configure_auto_optimizer.html">How To Configure Auto Optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/configure_pass.html">How To Configure Pass</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/configure_data.html">How To Configure Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/configure_model_path.html">How To Set Model Path</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/advanced_users.html">Advanced User Tour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/azure_arc.html">Self-hosted Kubernetes cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/azureml_scripts.html">Azure ML scripts</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API REFERENCE</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api/models.html">OliveModels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/resource_path.html">ResourcePath</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/systems.html">OliveSystems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/evaluator.html">OliveEvaluator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/metric.html">Metric</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/search-algorithms.html">SearchAlgorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/engine.html">Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/passes.html">Passes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Olive</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Packaging Olive artifacts</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/features/packaging_output_models.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="packaging-olive-artifacts">
<h1>Packaging Olive artifacts<a class="headerlink" href="#packaging-olive-artifacts" title="Permalink to this heading">¶</a></h1>
<section id="what-is-olive-packaging">
<h2>What is Olive Packaging<a class="headerlink" href="#what-is-olive-packaging" title="Permalink to this heading">¶</a></h2>
<p>Olive will output multiple candidate models based on metrics priorities. It also can package output artifacts when the user requires. Olive packaging can be used in different scenarios. There are 4 packaging types: <code class="docutils literal notranslate"><span class="pre">Zipfile</span></code>, <code class="docutils literal notranslate"><span class="pre">AzureMLModels</span></code>, <code class="docutils literal notranslate"><span class="pre">AzureMLData</span></code> and <code class="docutils literal notranslate"><span class="pre">AzureMLDeployment</span></code>.</p>
<section id="zipfile">
<h3>Zipfile<a class="headerlink" href="#zipfile" title="Permalink to this heading">¶</a></h3>
<p>Zipfile packaging will generate a ZIP file which includes 3 folders: <code class="docutils literal notranslate"><span class="pre">CandidateModels</span></code>, <code class="docutils literal notranslate"><span class="pre">SampleCode</span></code> and <code class="docutils literal notranslate"><span class="pre">ONNXRuntimePackages</span></code>, and a <code class="docutils literal notranslate"><span class="pre">models_rank.json</span></code> file in the <code class="docutils literal notranslate"><span class="pre">output_dir</span></code> folder (from Engine Configuration):</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">CandidateModels</span></code>: top ranked output model set</p>
<ul>
<li><p>Model file</p></li>
<li><p>Olive Pass run history configurations for candidate model</p></li>
<li><p>Inference settings (<code class="docutils literal notranslate"><span class="pre">onnx</span></code> model only)</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">SampleCode</span></code>: code sample for ONNX model</p>
<ul>
<li><p>C++</p></li>
<li><p>C#</p></li>
<li><p>Python</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">ONNXRuntimePackages</span></code>: ONNXRuntime package files with the same version that were used by Olive Engine in this workflow run.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">models_rank.json</span></code>: A JSON file containing a list that ranks all output models based on specific metrics across all accelerators.</p></li>
</ul>
<section id="candidatemodels">
<h4>CandidateModels<a class="headerlink" href="#candidatemodels" title="Permalink to this heading">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">CandidateModels</span></code> includes k folders where k is the number of ranked output models, with name <code class="docutils literal notranslate"><span class="pre">BestCandidateModel_1</span></code>, <code class="docutils literal notranslate"><span class="pre">BestCandidateModel_2</span></code>, … and <code class="docutils literal notranslate"><span class="pre">BestCandidateModel_k</span></code>. The order is ranked by metrics priorities, starting from 1. e.g., if you have 3 metrics <code class="docutils literal notranslate"><span class="pre">metric_1</span></code>, <code class="docutils literal notranslate"><span class="pre">metric_2</span></code> and <code class="docutils literal notranslate"><span class="pre">metric_3</span></code> with priority <code class="docutils literal notranslate"><span class="pre">1</span></code>, <code class="docutils literal notranslate"><span class="pre">2</span></code> and <code class="docutils literal notranslate"><span class="pre">3</span></code>. The output models will be sorted firstly by <code class="docutils literal notranslate"><span class="pre">metric_1</span></code>. If the value of <code class="docutils literal notranslate"><span class="pre">metric_1</span></code> of 2 output models are same, they will be sorted by <code class="docutils literal notranslate"><span class="pre">metric_2</span></code>, and followed by next lower priority metric.</p>
<p>Each <code class="docutils literal notranslate"><span class="pre">BestCandidateModel</span></code> folder will include model file/folder. The folder also includes a json file which includes the Olive Pass run history configurations since input model, a json file with performance metrics and a json file for inference settings for the candidate model if the candidate model is an ONNX model.</p>
</section>
<section id="samplecode">
<h4>SampleCode<a class="headerlink" href="#samplecode" title="Permalink to this heading">¶</a></h4>
<p>Olive will only provide sample codes for ONNX model. Sample code supports 3 different programming languages: <code class="docutils literal notranslate"><span class="pre">C++</span></code>, <code class="docutils literal notranslate"><span class="pre">C#</span></code> and <code class="docutils literal notranslate"><span class="pre">Python</span></code>. And a code snippet introducing how to use Olive output artifacts to inference candidate model with recommended inference configurations.</p>
</section>
<section id="models-rank-json-file">
<h4>Models rank JSON file<a class="headerlink" href="#models-rank-json-file" title="Permalink to this heading">¶</a></h4>
<p>A file that contains a JSON list for ranked model info across all accelerators, e.g.:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;rank&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;model_config&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ONNXModel&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;config&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nt">&quot;model_path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;path/model.onnx&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="nt">&quot;inference_settings&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                    </span><span class="nt">&quot;execution_provider&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">                        </span><span class="s2">&quot;CPUExecutionProvider&quot;</span>
<span class="w">                    </span><span class="p">],</span>
<span class="w">                    </span><span class="nt">&quot;provider_options&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">                        </span><span class="p">{}</span>
<span class="w">                    </span><span class="p">],</span>
<span class="w">                    </span><span class="nt">&quot;io_bind&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="p">,</span>
<span class="w">                    </span><span class="nt">&quot;session_options&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                        </span><span class="nt">&quot;execution_mode&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">                        </span><span class="nt">&quot;graph_optimization_level&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">99</span><span class="p">,</span>
<span class="w">                        </span><span class="nt">&quot;inter_op_num_threads&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">                        </span><span class="nt">&quot;intra_op_num_threads&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">14</span>
<span class="w">                    </span><span class="p">}</span>
<span class="w">                </span><span class="p">},</span>
<span class="w">                </span><span class="nt">&quot;use_ort_extensions&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="p">,</span>
<span class="w">                </span><span class="nt">&quot;model_attributes&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="nt">&quot;&lt;model_attributes_key&gt;&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&lt;model_attributes_value&gt;&quot;</span><span class="p">},</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="nt">&quot;metrics&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;accuracy-accuracy&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nt">&quot;value&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.8602941176470589</span><span class="p">,</span>
<span class="w">                </span><span class="nt">&quot;priority&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">                </span><span class="nt">&quot;higher_is_better&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">            </span><span class="p">},</span>
<span class="w">            </span><span class="nt">&quot;latency-avg&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nt">&quot;value&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">36.2313</span><span class="p">,</span>
<span class="w">                </span><span class="nt">&quot;priority&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="w">                </span><span class="nt">&quot;higher_is_better&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span>
<span class="w">            </span><span class="p">},</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span><span class="nt">&quot;rank&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;model_config&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&lt;model_config&gt;&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;metrics&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&lt;metrics&gt;&quot;</span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span><span class="nt">&quot;rank&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;model_config&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&lt;model_config&gt;&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;metrics&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&lt;metrics&gt;&quot;</span><span class="p">}</span>
<span class="p">]</span>
</pre></div>
</div>
</section>
</section>
<section id="azuremlmodels">
<h3>AzureMLModels<a class="headerlink" href="#azuremlmodels" title="Permalink to this heading">¶</a></h3>
<p>AzureMLModels packaging will register the output models to your Azure Machine Learning workspace. The asset name will be set as <code class="docutils literal notranslate"><span class="pre">&lt;packaging_config_name&gt;_&lt;accelerator_spec&gt;_&lt;model_rank&gt;</span></code>. The order is ranked by metrics priorities, starting from 1. For instance, if the output model is ONNX model and the packaging config is:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;AzureMLModels&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;olive_output_model&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;config&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;version&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;1&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;description&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;description&quot;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>and for CPU, the best execution provider is CPUExecutionProvider, so the first ranked model name registered on AML will be <code class="docutils literal notranslate"><span class="pre">olive_output_model_cpu-cpu_1</span></code>.</p>
<p>Olive will also upload model configuration file, inference config file, metrics file and model info file to the Azure ML.</p>
</section>
<section id="azuremldata">
<h3>AzureMLData<a class="headerlink" href="#azuremldata" title="Permalink to this heading">¶</a></h3>
<p>AzureMLData packaging will upload the output models to your Azure Machine Learning workspace as Data assets. The asset name will be set as <code class="docutils literal notranslate"><span class="pre">&lt;packaging_config_name&gt;_&lt;accelerator_spec&gt;_&lt;model_rank&gt;</span></code>. The order is ranked by metrics priorities, starting from 1. For instance, if the output model is ONNX model and the packaging config is:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;AzureMLData&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;olive_output_model&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;config&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;version&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;1&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;description&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;description&quot;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>and for CPU, the best execution provider is CPUExecutionProvider, so the first ranked model Data name on AML will be <code class="docutils literal notranslate"><span class="pre">olive_output_model_cpu-cpu_1</span></code>.</p>
<p>Olive will also upload model configuration file, inference config file, metrics file and model info file to the Azure ML.</p>
</section>
<section id="azuremldeployment">
<h3>AzureMLDeployment<a class="headerlink" href="#azuremldeployment" title="Permalink to this heading">¶</a></h3>
<p>AzureMLDeployment packaging will <a class="reference external" href="https://learn.microsoft.com/en-us/azure/machine-learning/how-to-package-models?view=azureml-api-2&amp;amp;tabs=sdk">package</a> ranked No. 1 model across all output models to Azure ML workspace, and create an endpoint for it if the endpoint doesn’t exist, then deploy the output model to this endpoint.</p>
</section>
</section>
<section id="how-to-package-olive-artifacts">
<h2>How to package Olive artifacts<a class="headerlink" href="#how-to-package-olive-artifacts" title="Permalink to this heading">¶</a></h2>
<p>Olive packaging configuration is configured in <code class="docutils literal notranslate"><span class="pre">PackagingConfig</span></code> in Engine configuration. <code class="docutils literal notranslate"><span class="pre">PackagingConfig</span></code> can be a single packaging configuration. Alternatively, if you want to apply multiple packaging types, you can also define a list of packaging configurations.</p>
<p>If not specified, Olive will not package artifacts.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">PackagingConfig</span></code></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">type</span> <span class="pre">[PackagingType]</span></code>:
Olive packaging type. Olive will package different artifacts based on <code class="docutils literal notranslate"><span class="pre">type</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">name</span> <span class="pre">[str]</span></code>:
For <code class="docutils literal notranslate"><span class="pre">PackagingType.Zipfile</span></code> type, Olive will generate a ZIP file with <code class="docutils literal notranslate"><span class="pre">name</span></code> prefix: <code class="docutils literal notranslate"><span class="pre">&lt;name&gt;.zip</span></code>.
For <code class="docutils literal notranslate"><span class="pre">PackagingType.AzureMLModels</span></code> and <code class="docutils literal notranslate"><span class="pre">PackagingType.AzureMLData</span></code>, Olive will use this <code class="docutils literal notranslate"><span class="pre">name</span></code> for Azure ML resource.
The default value is <code class="docutils literal notranslate"><span class="pre">OutputModels</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">config</span> <span class="pre">[dict]</span></code>:
The packaging config.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">Zipfile</span></code></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">export_in_mlflow_format</span> <span class="pre">[bool]</span></code>:
Export model in mlflow format. This is <code class="docutils literal notranslate"><span class="pre">false</span></code> by default.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">AzureMLModels</span></code></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">export_in_mlflow_format</span> <span class="pre">[bool]</span></code>:
Export model in mlflow format. This is <code class="docutils literal notranslate"><span class="pre">false</span></code> by default.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">version</span> <span class="pre">[int</span> <span class="pre">|</span> <span class="pre">str]</span></code>：
The version for this model registration. This is <code class="docutils literal notranslate"><span class="pre">1</span></code> by default.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">description</span> <span class="pre">[str]</span></code>
The description for this model registration. This is <code class="docutils literal notranslate"><span class="pre">None</span></code> by default.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">AzureMLData</span></code></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">export_in_mlflow_format</span> <span class="pre">[bool]</span></code>:
Export model in mlflow format. This is <code class="docutils literal notranslate"><span class="pre">false</span></code> by default.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">version</span> <span class="pre">[int</span> <span class="pre">|</span> <span class="pre">str]</span></code>：
The version for this data asset. This is <code class="docutils literal notranslate"><span class="pre">1</span></code> by default.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">description</span> <span class="pre">[str]</span></code>
The description for this data asset. This is <code class="docutils literal notranslate"><span class="pre">None</span></code> by default.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">AzureMLDeployment</span></code></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">model_name</span> <span class="pre">[str]</span></code>:
The model name when registering your output model to your Azure ML workspace. <code class="docutils literal notranslate"><span class="pre">olive-deployment-model</span></code> by default</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">model_version</span> <span class="pre">[int</span> <span class="pre">|</span> <span class="pre">str]</span></code>:
The model version when registering your output model to your Azure ML workspace. Please note if there is already a model with the same name and the same version in your workspace, this will override your existing registered model. <code class="docutils literal notranslate"><span class="pre">1</span></code> by default.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">description</span> <span class="pre">[str]</span></code>
The description for this model registration. This is <code class="docutils literal notranslate"><span class="pre">None</span></code> by default.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">model_package</span> <span class="pre">[ModelPackageConfig]</span></code>:
The configurations for model packaging.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">target_environment</span> <span class="pre">[str]</span></code>:
The environment name for the environment created by Olive. <code class="docutils literal notranslate"><span class="pre">olive-target-environment</span></code> by default.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">target_environment_version</span> <span class="pre">[str]</span></code>
The environment version for the environment created by Olive. Please note if there is already an environment with the same name and the same version in your workspace, your existing environment version will plus 1. This <code class="docutils literal notranslate"><span class="pre">target_environment_version</span></code> will not be applied for your environment. <code class="docutils literal notranslate"><span class="pre">None</span></code> by default.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inferencing_server</span> <span class="pre">[InferenceServerConfig]</span></code></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">type</span> <span class="pre">[str]</span></code>
The targeted inferencing server type. <code class="docutils literal notranslate"><span class="pre">AzureMLOnline</span></code> or <code class="docutils literal notranslate"><span class="pre">AzureMLBatch</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">code_folder</span> <span class="pre">[str]</span></code>
The folder path to your scoring script.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scoring_script</span> <span class="pre">[str]</span></code>
The scoring script name.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">base_environment_id</span> <span class="pre">[str]</span></code>
The base environment id that will be used for Azure ML packaging. The format is <code class="docutils literal notranslate"><span class="pre">azureml:&lt;base-environment-name&gt;:&lt;base-environment-version&gt;</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">environment_variables</span> <span class="pre">[dict]</span></code>
Env vars that are required for the package to run, but not necessarily known at Environment creation time. <code class="docutils literal notranslate"><span class="pre">None</span></code> by default.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">deployment_config</span> <span class="pre">[DeploymentConfig]</span></code>
The deployment configuration.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">endpoint_name</span> <span class="pre">[str]</span></code>
The endpoint name for the deployment. If the endpoint doesn’t exist, Olive will create one endpoint with this name. <code class="docutils literal notranslate"><span class="pre">olive-default-endpoint</span></code> by default.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">deployment_name</span> <span class="pre">[str]</span></code>
The name of the deployment. <code class="docutils literal notranslate"><span class="pre">olive-default-deployment</span></code> by default.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">instance_type</span> <span class="pre">[str]</span></code>
Azure compute sku. ManagedOnlineDeployment only. <code class="docutils literal notranslate"><span class="pre">None</span></code> by default.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">compute</span> <span class="pre">[str]</span></code>
Compute target for batch inference operation. BatchDeployment only. <code class="docutils literal notranslate"><span class="pre">None</span></code> by default.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">instance_count</span> <span class="pre">[str]</span></code>
Number of instances the interfering will run on. <code class="docutils literal notranslate"><span class="pre">1</span></code> by default.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mini_batch_size</span> <span class="pre">[str]</span></code>
Size of the mini-batch passed to each batch invocation. <code class="docutils literal notranslate"><span class="pre">10</span></code> by default.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">extra_config</span> <span class="pre">[dict]</span></code>
Extra configurations for deployment. <code class="docutils literal notranslate"><span class="pre">None</span></code> by default.</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">include_sample_code</span> <span class="pre">[bool]</span></code>:
Whether or not to include sample code in zip file. Defaults to True</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">include_runtime_packages</span> <span class="pre">[bool]</span></code>:
Whether or not to include runtime packages (like onnxruntime) in zip file. Defaults to True</p></li>
</ul>
</li>
</ul>
<p>You can add different types <code class="docutils literal notranslate"><span class="pre">PackagingConfig</span></code> as a list to Engine configurations. e.g.:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="nt">&quot;engine&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;search_strategy&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;execution_order&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;joint&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;search_algorithm&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;tpe&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;search_algorithm_config&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;num_samples&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">5</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;seed&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="nt">&quot;evaluator&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;common_evaluator&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;host&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;local_system&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;target&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;local_system&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;packaging_config&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Zipfile&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;OutputModels&quot;</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;AzureMLModels&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;OutputModels&quot;</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;AzureMLData&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;OutputModels&quot;</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;AzureMLDeployment&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;config&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nt">&quot;model_package&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                    </span><span class="nt">&quot;inferencing_server&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;AzureMLOnline&quot;</span><span class="p">,</span>
<span class="w">                        </span><span class="nt">&quot;code_folder&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;code&quot;</span><span class="p">,</span>
<span class="w">                        </span><span class="nt">&quot;scoring_script&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;score.py&quot;</span>
<span class="w">                    </span><span class="p">},</span>
<span class="w">                    </span><span class="nt">&quot;base_environment_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;azureml:olive-aml-packaging:1&quot;</span>
<span class="w">                </span><span class="p">}</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">]</span>
<span class="w">    </span><span class="nt">&quot;cache_dir&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;cache&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="packaged-files">
<h2>Packaged files<a class="headerlink" href="#packaged-files" title="Permalink to this heading">¶</a></h2>
<section id="inference-config-file">
<h3>Inference config file<a class="headerlink" href="#inference-config-file" title="Permalink to this heading">¶</a></h3>
<p>The inference config file is a json file including <code class="docutils literal notranslate"><span class="pre">execution_provider</span></code> and <code class="docutils literal notranslate"><span class="pre">session_options</span></code>. e.g.:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;execution_provider&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">        </span><span class="p">[</span>
<span class="w">            </span><span class="s2">&quot;CPUExecutionProvider&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="p">{}</span>
<span class="w">        </span><span class="p">]</span>
<span class="w">    </span><span class="p">],</span>
<span class="w">    </span><span class="nt">&quot;session_options&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;execution_mode&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;graph_optimization_level&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">99</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;extra_session_config&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;inter_op_num_threads&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;intra_op_num_threads&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">64</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="model-configuration-file">
<h3>Model configuration file<a class="headerlink" href="#model-configuration-file" title="Permalink to this heading">¶</a></h3>
<p>The model configuration file is a json file including the history of applied Passes history to the output model. e.g.:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;53fc6781998a4624b61959bb064622ce&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;0_OnnxConversion-53fc6781998a4624b61959bb064622ce-7a320d6d630bced3548f242238392730&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">//...</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;1_OrtTransformersOptimization-0-c499e39e42693aaab050820afd31e0c3-cpu-cpu&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">//...</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;2_OnnxQuantization-1-1431c563dcfda9c9c3bf26c5d61ef58e&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">//...</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;3_OrtPerfTuning-2-a843d77ae4964c04e145b83567fb5b05-cpu-cpu&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">//...</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="metrics-file">
<h3>Metrics file<a class="headerlink" href="#metrics-file" title="Permalink to this heading">¶</a></h3>
<p>The metrics file is a json file including input model metrics and output model metrics.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="huggingface_model_optimization.html" class="btn btn-neutral float-left" title="Huggingface Model Optimization" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="custom_scripts.html" class="btn btn-neutral float-right" title="Custom Scripts" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, olivedevteam@microsoft.com.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>