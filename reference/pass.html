
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Passes &#8212; Olive  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/autodoc_pydantic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/css/header.css?v=5dcc4e7b" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/jquery.js?v=5d32c60e"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
    <script src="../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'reference/pass';</script>
    <script src="../_static/js/custom_version.js?v=3856a39b"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Extending Olive" href="../extending/index.html" />
    <link rel="prev" title="Olive Options" href="options.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="latest" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Olive  documentation</p>
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../why-olive.html">
    Overview
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../getting-started/getting-started.html">
    Getting started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../how-to/index.html">
    How-to
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../examples.html">
    Examples
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button"
                data-bs-toggle="dropdown" aria-expanded="false"
                aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../features/index.html">
    Features
  </a>
</li>


<li class=" current active">
  <a class="nav-link dropdown-item nav-internal" href="index.html">
    Reference
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../extending/index.html">
    Extending Olive
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/microsoft/Olive" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/olive-ai" title="PyPI" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-custom fa-pypi fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPI</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../why-olive.html">
    Overview
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../getting-started/getting-started.html">
    Getting started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../how-to/index.html">
    How-to
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../examples.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../features/index.html">
    Features
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="index.html">
    Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../extending/index.html">
    Extending Olive
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/microsoft/Olive" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/olive-ai" title="PyPI" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-custom fa-pypi fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPI</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="index.html" class="nav-link">Reference</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Passes</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="passes">
<h1>Passes<a class="headerlink" href="#passes" title="Link to this heading">#</a></h1>
<p>The following passes are available in Olive.</p>
<p>Each pass is followed by a description of the pass and a list of the pass’s configuration options.</p>
</section>
<section id="onnx">
<h1>ONNX<a class="headerlink" href="#onnx" title="Link to this heading">#</a></h1>
<section id="onnxconversion">
<span id="onnx-conversion"></span><h2>OnnxConversion<a class="headerlink" href="#onnxconversion" title="Link to this heading">#</a></h2>
<p>Convert a PyTorch model to ONNX model using torch.onnx.export on CPU.</p>
<p><strong>Input:</strong> handler.hf.DistributedHfModelHandler | handler.hf.HfModelHandler | handler.pytorch.PyTorchModelHandler</p>
<p><strong>Output:</strong> handler.onnx.DistributedOnnxModelHandler | handler.onnx.ONNXModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-user_script">
<span class="sig-name descname"><span class="pre">user_script</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-user_script" title="Link to this definition">#</a></dt>
<dd><p>Path to user script. The values for other parameters which were assigned function or object names will be imported from this script.</p>
<p><strong>type:</strong> pathlib.Path | str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-script_dir">
<span class="sig-name descname"><span class="pre">script_dir</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-script_dir" title="Link to this definition">#</a></dt>
<dd><p>Directory containing user script dependencies.</p>
<p><strong>type:</strong> pathlib.Path | str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-save_as_external_data">
<span class="sig-name descname"><span class="pre">save_as_external_data</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-save_as_external_data" title="Link to this definition">#</a></dt>
<dd><p>Serializes tensor data to separate files instead of directly in the ONNX file. Large models (&gt;2GB) may be forced to save external data regardless of the value of this parameter.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-all_tensors_to_one_file">
<span class="sig-name descname"><span class="pre">all_tensors_to_one_file</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-all_tensors_to_one_file" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, save all tensors to one external file specified by ‘external_data_name’. If false, save each tensor to a file named with the tensor name.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-external_data_name">
<span class="sig-name descname"><span class="pre">external_data_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-external_data_name" title="Link to this definition">#</a></dt>
<dd><p>Effective only if all_tensors_to_one_file is True and save_as_external_data is True. If not specified, the external data file will be named with &lt;model_path_name&gt;.data</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-size_threshold">
<span class="sig-name descname"><span class="pre">size_threshold</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-size_threshold" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. Threshold for size of data. Only when tensor’s data is &gt;= the size_threshold it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1024</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-convert_attribute">
<span class="sig-name descname"><span class="pre">convert_attribute</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-convert_attribute" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, convert all tensors to external data If false, convert only non-attribute tensors to external data</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-target_opset">
<span class="sig-name descname"><span class="pre">target_opset</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-target_opset" title="Link to this definition">#</a></dt>
<dd><p>The version of the default (ai.onnx) opset to target.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 20</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-use_dynamo_exporter">
<span class="sig-name descname"><span class="pre">use_dynamo_exporter</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-use_dynamo_exporter" title="Link to this definition">#</a></dt>
<dd><p>Whether to use dynamo_export API to export ONNX model.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-past_key_value_name">
<span class="sig-name descname"><span class="pre">past_key_value_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-past_key_value_name" title="Link to this definition">#</a></dt>
<dd><p>The arguments name to point to past key values. For model loaded from huggingface, it is ‘past_key_values’. Basically, it is used only when <cite>use_dynamo_exporter</cite> is True.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> past_key_values</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-device">
<span class="sig-name descname"><span class="pre">device</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-device" title="Link to this definition">#</a></dt>
<dd><p>The device to use for conversion, e.g., ‘cuda’ or ‘cpu’. If not specified, will use ‘cpu’ for PyTorch model and ‘cuda’ for DistributedHfModel.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-torch_dtype">
<span class="sig-name descname"><span class="pre">torch_dtype</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-torch_dtype" title="Link to this definition">#</a></dt>
<dd><p>The dtype to cast the model to before conversion, e.g., ‘float32’ or ‘float16’. If not specified, will use the model as is.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-parallel_jobs">
<span class="sig-name descname"><span class="pre">parallel_jobs</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-parallel_jobs" title="Link to this definition">#</a></dt>
<dd><p>Number of parallel jobs. Defaulted to number of CPUs. Set it to 0 to disable.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-merge_adapter_weights">
<span class="sig-name descname"><span class="pre">merge_adapter_weights</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-merge_adapter_weights" title="Link to this definition">#</a></dt>
<dd><p>Whether to merge adapter weights before conversion. After merging, the model structure is consistent with base model. That is useful if you cannot run conversion for some fine-tuned models with adapter weights</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-save_metadata_for_token_generation">
<span class="sig-name descname"><span class="pre">save_metadata_for_token_generation</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-save_metadata_for_token_generation" title="Link to this definition">#</a></dt>
<dd><p>Whether to save metadata for token generation or not. Includes config.json, generation_config.json, and tokenizer related files.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-optimize">
<span class="sig-name descname"><span class="pre">optimize</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-optimize" title="Link to this definition">#</a></dt>
<dd><p>Whether to export the model with constant folding and redundancies elimination.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-dynamic">
<span class="sig-name descname"><span class="pre">dynamic</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-dynamic" title="Link to this definition">#</a></dt>
<dd><p>Whether to export the model with dynamic axes/shapes.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="onnxopversionconversion">
<span id="onnx-op-version-conversion"></span><h2>OnnxOpVersionConversion<a class="headerlink" href="#onnxopversionconversion" title="Link to this heading">#</a></h2>
<p><strong>Input:</strong> handler.onnx.ONNXModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-0">
<span class="sig-name descname"><span class="pre">target_opset</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-0" title="Link to this definition">#</a></dt>
<dd><p>The version of the default (ai.onnx) opset to target. Default: latest opset version.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 22</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-1">
<span class="sig-name descname"><span class="pre">save_as_external_data</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-1" title="Link to this definition">#</a></dt>
<dd><p>Serializes tensor data to separate files instead of directly in the ONNX file. Large models (&gt;2GB) may be forced to save external data regardless of the value of this parameter.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-2">
<span class="sig-name descname"><span class="pre">all_tensors_to_one_file</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-2" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, save all tensors to one external file specified by ‘external_data_name’. If false, save each tensor to a file named with the tensor name.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-3">
<span class="sig-name descname"><span class="pre">external_data_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-3" title="Link to this definition">#</a></dt>
<dd><p>Effective only if all_tensors_to_one_file is True and save_as_external_data is True. If not specified, the external data file will be named with &lt;model_path_name&gt;.data</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-4">
<span class="sig-name descname"><span class="pre">size_threshold</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-4" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. Threshold for size of data. Only when tensor’s data is &gt;= the size_threshold it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1024</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-5">
<span class="sig-name descname"><span class="pre">convert_attribute</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-5" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, convert all tensors to external data If false, convert only non-attribute tensors to external data</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="onnxscriptfusion">
<span id="onnx-peephole-optimizer"></span><h2>OnnxScriptFusion<a class="headerlink" href="#onnxscriptfusion" title="Link to this heading">#</a></h2>
<p>Fuse Ops using onnxscript.</p>
<p><strong>Input:</strong> handler.onnx.ONNXModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-6">
<span class="sig-name descname"><span class="pre">save_as_external_data</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-6" title="Link to this definition">#</a></dt>
<dd><p>Serializes tensor data to separate files instead of directly in the ONNX file. Large models (&gt;2GB) may be forced to save external data regardless of the value of this parameter.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-7">
<span class="sig-name descname"><span class="pre">all_tensors_to_one_file</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-7" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, save all tensors to one external file specified by ‘external_data_name’. If false, save each tensor to a file named with the tensor name.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-8">
<span class="sig-name descname"><span class="pre">external_data_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-8" title="Link to this definition">#</a></dt>
<dd><p>Effective only if all_tensors_to_one_file is True and save_as_external_data is True. If not specified, the external data file will be named with &lt;model_path_name&gt;.data</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-9">
<span class="sig-name descname"><span class="pre">size_threshold</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-9" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. Threshold for size of data. Only when tensor’s data is &gt;= the size_threshold it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1024</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-10">
<span class="sig-name descname"><span class="pre">convert_attribute</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-10" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, convert all tensors to external data If false, convert only non-attribute tensors to external data</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="onnxpeepholeoptimizer">
<span id="onnxscript-fusion"></span><h2>OnnxPeepholeOptimizer<a class="headerlink" href="#onnxpeepholeoptimizer" title="Link to this heading">#</a></h2>
<p>Optimize ONNX model by fusing nodes.</p>
<p><strong>Input:</strong> handler.onnx.ONNXModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-11">
<span class="sig-name descname"><span class="pre">save_as_external_data</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-11" title="Link to this definition">#</a></dt>
<dd><p>Serializes tensor data to separate files instead of directly in the ONNX file. Large models (&gt;2GB) may be forced to save external data regardless of the value of this parameter.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-12">
<span class="sig-name descname"><span class="pre">all_tensors_to_one_file</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-12" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, save all tensors to one external file specified by ‘external_data_name’. If false, save each tensor to a file named with the tensor name.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-13">
<span class="sig-name descname"><span class="pre">external_data_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-13" title="Link to this definition">#</a></dt>
<dd><p>Effective only if all_tensors_to_one_file is True and save_as_external_data is True. If not specified, the external data file will be named with &lt;model_path_name&gt;.data</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-14">
<span class="sig-name descname"><span class="pre">size_threshold</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-14" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. Threshold for size of data. Only when tensor’s data is &gt;= the size_threshold it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1024</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-15">
<span class="sig-name descname"><span class="pre">convert_attribute</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-15" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, convert all tensors to external data If false, convert only non-attribute tensors to external data</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="orttransformersoptimization">
<span id="ort-transformers-optimization"></span><h2>OrtTransformersOptimization<a class="headerlink" href="#orttransformersoptimization" title="Link to this heading">#</a></h2>
<p>Use ONNX Transformer Optimizer to optimize transformer based models.

    Optimize transformer based models in scenarios where ONNX Runtime does not apply the optimization at load time.
    It is based on onnxruntime.transformers.optimizer.</p>
<p><strong>Input:</strong> handler.onnx.ONNXModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-model_type">
<span class="sig-name descname"><span class="pre">model_type</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-model_type" title="Link to this definition">#</a></dt>
<dd><p>Transformer based model type, including bert (exported by PyTorch), gpt2 (exported by PyTorch), bert_tf (BERT exported by tf2onnx), bert_keras (BERT exported by keras2onnx), and unet/vae/clip (stable diffusion).</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-num_heads">
<span class="sig-name descname"><span class="pre">num_heads</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-num_heads" title="Link to this definition">#</a></dt>
<dd><p>Number of attention heads.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 0</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-num_key_value_heads">
<span class="sig-name descname"><span class="pre">num_key_value_heads</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-num_key_value_heads" title="Link to this definition">#</a></dt>
<dd><p>Number of key/value attention heads.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 0</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-hidden_size">
<span class="sig-name descname"><span class="pre">hidden_size</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-hidden_size" title="Link to this definition">#</a></dt>
<dd><p>Number of hidden nodes.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 0</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-optimization_options">
<span class="sig-name descname"><span class="pre">optimization_options</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-optimization_options" title="Link to this definition">#</a></dt>
<dd><p>Optimization options that turn on/off some fusions.</p>
<p><strong>type:</strong> Dict[str, Any] | onnxruntime.transformers.fusion_options.FusionOptions</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-opt_level">
<span class="sig-name descname"><span class="pre">opt_level</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-opt_level" title="Link to this definition">#</a></dt>
<dd><p>Graph optimization level of Onnx Runtime: 0 - disable all (default), 1 - basic, 2 - extended, 99 - all.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-use_gpu">
<span class="sig-name descname"><span class="pre">use_gpu</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-use_gpu" title="Link to this definition">#</a></dt>
<dd><p>Flag for GPU inference.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-only_onnxruntime">
<span class="sig-name descname"><span class="pre">only_onnxruntime</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-only_onnxruntime" title="Link to this definition">#</a></dt>
<dd><p>Whether only use onnxruntime to optimize model, and no python fusion. Disable some optimizers that might cause failure in symbolic shape inference or attention fusion, when opt_level &gt; 1.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-float16">
<span class="sig-name descname"><span class="pre">float16</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-float16" title="Link to this definition">#</a></dt>
<dd><p>Whether half-precision float will be used.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-keep_io_types">
<span class="sig-name descname"><span class="pre">keep_io_types</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-keep_io_types" title="Link to this definition">#</a></dt>
<dd><p>Keep input and output tensors in their original data type. Only used when float16 is True.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-force_fp32_ops">
<span class="sig-name descname"><span class="pre">force_fp32_ops</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-force_fp32_ops" title="Link to this definition">#</a></dt>
<dd><p>Operators that are forced to run in float32. Only used when float16 is True.</p>
<p><strong>type:</strong> List[str]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-force_fp32_nodes">
<span class="sig-name descname"><span class="pre">force_fp32_nodes</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-force_fp32_nodes" title="Link to this definition">#</a></dt>
<dd><p>Nodes that are forced to run in float32. Only used when float16 is True.</p>
<p><strong>type:</strong> List[str]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-force_fp16_inputs">
<span class="sig-name descname"><span class="pre">force_fp16_inputs</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-force_fp16_inputs" title="Link to this definition">#</a></dt>
<dd><p>Force the conversion of the inputs of some operators to float16, even if ‘convert_float_to_float16` tool prefers it to keep them in float32.</p>
<p><strong>type:</strong> Dict[str, List[int]]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-use_gqa">
<span class="sig-name descname"><span class="pre">use_gqa</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-use_gqa" title="Link to this definition">#</a></dt>
<dd><p>Replace MultiHeadAttention with GroupQueryAttention. True is only supported when float16 is True.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-input_int32">
<span class="sig-name descname"><span class="pre">input_int32</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-input_int32" title="Link to this definition">#</a></dt>
<dd><p>Whether int32 tensors will be used as input.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-16">
<span class="sig-name descname"><span class="pre">save_as_external_data</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-16" title="Link to this definition">#</a></dt>
<dd><p>Serializes tensor data to separate files instead of directly in the ONNX file. Large models (&gt;2GB) may be forced to save external data regardless of the value of this parameter.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-17">
<span class="sig-name descname"><span class="pre">all_tensors_to_one_file</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-17" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, save all tensors to one external file specified by ‘external_data_name’. If false, save each tensor to a file named with the tensor name.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-18">
<span class="sig-name descname"><span class="pre">external_data_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-18" title="Link to this definition">#</a></dt>
<dd><p>Effective only if all_tensors_to_one_file is True and save_as_external_data is True. If not specified, the external data file will be named with &lt;model_path_name&gt;.data</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-19">
<span class="sig-name descname"><span class="pre">size_threshold</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-19" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. Threshold for size of data. Only when tensor’s data is &gt;= the size_threshold it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1024</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-20">
<span class="sig-name descname"><span class="pre">convert_attribute</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-20" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, convert all tensors to external data If false, convert only non-attribute tensors to external data</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="ortsessionparamstuning">
<span id="ort-session-params-tuning"></span><h2>OrtSessionParamsTuning<a class="headerlink" href="#ortsessionparamstuning" title="Link to this heading">#</a></h2>
<p>Optimize ONNX Runtime inference settings.</p>
<p><strong>Input:</strong> handler.onnx.ONNXModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-21">
<span class="sig-name descname"><span class="pre">user_script</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-21" title="Link to this definition">#</a></dt>
<dd><p>Path to user script. The values for other parameters which were assigned function or object names will be imported from this script.</p>
<p><strong>type:</strong> pathlib.Path | str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-22">
<span class="sig-name descname"><span class="pre">script_dir</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-22" title="Link to this definition">#</a></dt>
<dd><p>Directory containing user script dependencies.</p>
<p><strong>type:</strong> pathlib.Path | str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-data_config">
<span class="sig-name descname"><span class="pre">data_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-data_config" title="Link to this definition">#</a></dt>
<dd><p>Data config to load data for computing latency.</p>
<p><strong>type:</strong> olive.data.config.DataConfig | Dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-23">
<span class="sig-name descname"><span class="pre">device</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-23" title="Link to this definition">#</a></dt>
<dd><p>Device selected for tuning process.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> cpu</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-cpu_cores">
<span class="sig-name descname"><span class="pre">cpu_cores</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-cpu_cores" title="Link to this definition">#</a></dt>
<dd><p>CPU cores used for thread tuning.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-io_bind">
<span class="sig-name descname"><span class="pre">io_bind</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-io_bind" title="Link to this definition">#</a></dt>
<dd><p>Whether enable IOBinding Search for ONNX Runtime inference.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-enable_cuda_graph">
<span class="sig-name descname"><span class="pre">enable_cuda_graph</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-enable_cuda_graph" title="Link to this definition">#</a></dt>
<dd><p>Whether enable CUDA Graph for CUDA execution provider.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-providers_list">
<span class="sig-name descname"><span class="pre">providers_list</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-providers_list" title="Link to this definition">#</a></dt>
<dd><p>Execution providers framework list to execute the ONNX models.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> CPUExecutionProvider</p>
<p><strong>search_defaults:</strong> Categorical([‘CPUExecutionProvider’])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-provider_options_list">
<span class="sig-name descname"><span class="pre">provider_options_list</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-provider_options_list" title="Link to this definition">#</a></dt>
<dd><p>Execution provider options to execute the ONNX models.</p>
<p><strong>type:</strong> Dict[str, Any]</p>
<p><strong>default_value:</strong> {}</p>
<p><strong>search_defaults:</strong> Categorical([{}])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-execution_mode_list">
<span class="sig-name descname"><span class="pre">execution_mode_list</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-execution_mode_list" title="Link to this definition">#</a></dt>
<dd><p>Parallelism list between operators.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> Categorical([None])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-opt_level_list">
<span class="sig-name descname"><span class="pre">opt_level_list</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-opt_level_list" title="Link to this definition">#</a></dt>
<dd><p>Optimization level list for ONNX model.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> Categorical([None])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-trt_fp16_enable">
<span class="sig-name descname"><span class="pre">trt_fp16_enable</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-trt_fp16_enable" title="Link to this definition">#</a></dt>
<dd><p>Whether enable FP16 mode for TensorRT execution provider.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-intra_thread_num_list">
<span class="sig-name descname"><span class="pre">intra_thread_num_list</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-intra_thread_num_list" title="Link to this definition">#</a></dt>
<dd><p>List of intra thread number for test.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> Categorical([None])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-inter_thread_num_list">
<span class="sig-name descname"><span class="pre">inter_thread_num_list</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-inter_thread_num_list" title="Link to this definition">#</a></dt>
<dd><p>List of inter thread number for test.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> Categorical([None])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-extra_session_config">
<span class="sig-name descname"><span class="pre">extra_session_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-extra_session_config" title="Link to this definition">#</a></dt>
<dd><p>Extra customized session options during tuning process.</p>
<p><strong>type:</strong> Dict[str, Any]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-force_evaluate_other_eps">
<span class="sig-name descname"><span class="pre">force_evaluate_other_eps</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-force_evaluate_other_eps" title="Link to this definition">#</a></dt>
<dd><p>Whether force to evaluate all execution providers which are different with the associated execution provider.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-enable_profiling">
<span class="sig-name descname"><span class="pre">enable_profiling</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-enable_profiling" title="Link to this definition">#</a></dt>
<dd><p>Whether enable profiling for ONNX Runtime inference.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="onnxfloattofloat16">
<span id="onnx-float-to-float16"></span><h2>OnnxFloatToFloat16<a class="headerlink" href="#onnxfloattofloat16" title="Link to this heading">#</a></h2>
<p>Converts a model to float16.

    It uses the float16 converter from onnxruntime to convert the model to float16.</p>
<p><strong>Input:</strong> handler.onnx.ONNXModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-min_positive_val">
<span class="sig-name descname"><span class="pre">min_positive_val</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-min_positive_val" title="Link to this definition">#</a></dt>
<dd><p>Constant values will be clipped against this value</p>
<p><strong>type:</strong> float</p>
<p><strong>default_value:</strong> 1e-07</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-max_finite_val">
<span class="sig-name descname"><span class="pre">max_finite_val</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-max_finite_val" title="Link to this definition">#</a></dt>
<dd><p>Constant values will be clipped against this value</p>
<p><strong>type:</strong> float</p>
<p><strong>default_value:</strong> 10000.0</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-24">
<span class="sig-name descname"><span class="pre">keep_io_types</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-24" title="Link to this definition">#</a></dt>
<dd><p>Whether model inputs/outputs should be left as float32</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-use_symbolic_shape_infer">
<span class="sig-name descname"><span class="pre">use_symbolic_shape_infer</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-use_symbolic_shape_infer" title="Link to this definition">#</a></dt>
<dd><p>Use symbolic shape inference instead of onnx shape inference. Defaults to True.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-op_block_list">
<span class="sig-name descname"><span class="pre">op_block_list</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-op_block_list" title="Link to this definition">#</a></dt>
<dd><p>List of op types to leave as float32</p>
<p><strong>type:</strong> List[str]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-node_block_list">
<span class="sig-name descname"><span class="pre">node_block_list</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-node_block_list" title="Link to this definition">#</a></dt>
<dd><p>List of node names to leave as float32</p>
<p><strong>type:</strong> List[str]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-25">
<span class="sig-name descname"><span class="pre">save_as_external_data</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-25" title="Link to this definition">#</a></dt>
<dd><p>Serializes tensor data to separate files instead of directly in the ONNX file. Large models (&gt;2GB) may be forced to save external data regardless of the value of this parameter.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-26">
<span class="sig-name descname"><span class="pre">all_tensors_to_one_file</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-26" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, save all tensors to one external file specified by ‘external_data_name’. If false, save each tensor to a file named with the tensor name.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-27">
<span class="sig-name descname"><span class="pre">external_data_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-27" title="Link to this definition">#</a></dt>
<dd><p>Effective only if all_tensors_to_one_file is True and save_as_external_data is True. If not specified, the external data file will be named with &lt;model_path_name&gt;.data</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-28">
<span class="sig-name descname"><span class="pre">size_threshold</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-28" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. Threshold for size of data. Only when tensor’s data is &gt;= the size_threshold it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1024</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-29">
<span class="sig-name descname"><span class="pre">convert_attribute</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-29" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, convert all tensors to external data If false, convert only non-attribute tensors to external data</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="onnxiodatatypeconverter">
<span id="onnx-io-float16-to-float32"></span><h2>OnnxIODataTypeConverter<a class="headerlink" href="#onnxiodatatypeconverter" title="Link to this heading">#</a></h2>
<p>Converts model inputs/outputs from a source dtype to a target dtype based on a name pattern.</p>
<p><strong>Input:</strong> handler.onnx.ONNXModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-name_pattern">
<span class="sig-name descname"><span class="pre">name_pattern</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-name_pattern" title="Link to this definition">#</a></dt>
<dd><p>Only convert inputs/outputs whose name matches this pattern. By defaultlooking for logits names</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> logits</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-source_dtype">
<span class="sig-name descname"><span class="pre">source_dtype</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-source_dtype" title="Link to this definition">#</a></dt>
<dd><p>Source data type int value to convert from (default: FLOAT16). Check <a class="github reference external" href="https://github.com/onnx/onnx/blob/96a0ca4374d2198944ff882bd273e64222b59cb9/onnx/onnx.proto3#L503-L551for">onnx/onnx</a> details.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 10</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-target_dtype">
<span class="sig-name descname"><span class="pre">target_dtype</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-target_dtype" title="Link to this definition">#</a></dt>
<dd><p>Target data type int value to convert to (default: FLOAT). Check <a class="github reference external" href="https://github.com/onnx/onnx/blob/96a0ca4374d2198944ff882bd273e64222b59cb9/onnx/onnx.proto3#L503-L551for">onnx/onnx</a> details.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-30">
<span class="sig-name descname"><span class="pre">save_as_external_data</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-30" title="Link to this definition">#</a></dt>
<dd><p>Serializes tensor data to separate files instead of directly in the ONNX file. Large models (&gt;2GB) may be forced to save external data regardless of the value of this parameter.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-31">
<span class="sig-name descname"><span class="pre">all_tensors_to_one_file</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-31" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, save all tensors to one external file specified by ‘external_data_name’. If false, save each tensor to a file named with the tensor name.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-32">
<span class="sig-name descname"><span class="pre">external_data_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-32" title="Link to this definition">#</a></dt>
<dd><p>Effective only if all_tensors_to_one_file is True and save_as_external_data is True. If not specified, the external data file will be named with &lt;model_path_name&gt;.data</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-33">
<span class="sig-name descname"><span class="pre">size_threshold</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-33" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. Threshold for size of data. Only when tensor’s data is &gt;= the size_threshold it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1024</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-34">
<span class="sig-name descname"><span class="pre">convert_attribute</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-34" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, convert all tensors to external data If false, convert only non-attribute tensors to external data</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="ortmixedprecision">
<span id="ort-mixed-precision"></span><h2>OrtMixedPrecision<a class="headerlink" href="#ortmixedprecision" title="Link to this heading">#</a></h2>
<p>Convert model to mixed precision.</p>
<p><strong>Input:</strong> handler.onnx.ONNXModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-35">
<span class="sig-name descname"><span class="pre">op_block_list</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-35" title="Link to this definition">#</a></dt>
<dd><p>List of op types to leave as float32</p>
<p><strong>type:</strong> List[str]</p>
<p><strong>default_value:</strong> [‘SimplifiedLayerNormalization’, ‘SkipSimplifiedLayerNormalization’, ‘Relu’, ‘Add’]</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-atol">
<span class="sig-name descname"><span class="pre">atol</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-atol" title="Link to this definition">#</a></dt>
<dd><p>Absolute tolerance for checking float16 conversion</p>
<p><strong>type:</strong> float</p>
<p><strong>default_value:</strong> 1e-06</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-36">
<span class="sig-name descname"><span class="pre">save_as_external_data</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-36" title="Link to this definition">#</a></dt>
<dd><p>Serializes tensor data to separate files instead of directly in the ONNX file. Large models (&gt;2GB) may be forced to save external data regardless of the value of this parameter.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-37">
<span class="sig-name descname"><span class="pre">all_tensors_to_one_file</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-37" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, save all tensors to one external file specified by ‘external_data_name’. If false, save each tensor to a file named with the tensor name.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-38">
<span class="sig-name descname"><span class="pre">external_data_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-38" title="Link to this definition">#</a></dt>
<dd><p>Effective only if all_tensors_to_one_file is True and save_as_external_data is True. If not specified, the external data file will be named with &lt;model_path_name&gt;.data</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-39">
<span class="sig-name descname"><span class="pre">size_threshold</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-39" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. Threshold for size of data. Only when tensor’s data is &gt;= the size_threshold it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1024</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-40">
<span class="sig-name descname"><span class="pre">convert_attribute</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-40" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, convert all tensors to external data If false, convert only non-attribute tensors to external data</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="qnnpreprocess">
<span id="qnn-preprocess"></span><h2>QNNPreprocess<a class="headerlink" href="#qnnpreprocess" title="Link to this heading">#</a></h2>
<p>Preprocess ONNX model for quantization targeting QNN Execution Provider.</p>
<p><strong>Input:</strong> handler.onnx.ONNXModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-fuse_layernorm">
<span class="sig-name descname"><span class="pre">fuse_layernorm</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-fuse_layernorm" title="Link to this definition">#</a></dt>
<dd><p>Whether to fuse ReduceMean sequence into a single LayerNormalization node.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-inputs_to_make_channel_last">
<span class="sig-name descname"><span class="pre">inputs_to_make_channel_last</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-inputs_to_make_channel_last" title="Link to this definition">#</a></dt>
<dd><p>inputs_to_make_channel_last: List of graph input names to transpose to be
                “channel-last”. For example, if “input0” originally has the shape (N, C, D1, D2, …, Dn),
                the resulting model will change input0’s shape to (N, D1, D2, …, Dn, C) and add a transpose
                node after it.

                Original:
                    input0 (N, C, D1, D2, …, Dn) –&gt; &lt;Nodes&gt;

                Updated:
                    input0 (N, D1, D2, …, Dn, C) –&gt; Transpose
                        –&gt; input0_chanfirst (N, C, D1, D2, …, Dn) –&gt; &lt;Nodes&gt;

                This can potentially improve inference latency for QDQ models running on QNN EP because the
                additional transpose node may allow other transpose nodes inserted during ORT layout
                transformation to cancel out.</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-outputs_to_make_channel_last">
<span class="sig-name descname"><span class="pre">outputs_to_make_channel_last</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-outputs_to_make_channel_last" title="Link to this definition">#</a></dt>
<dd><p>List of graph output names to transpose to be “channel-last”. For example,
            if “output0” originally has the shape (N, C, D1, D2, …, Dn), the resulting model will change
            output0’s shape to (N, D1, D2, …, Dn, C) and add a transpose node before it.

            Original:
                &lt;Nodes&gt; –&gt; output0 (N, C, D1, D2, …, Dn)

            Updated:
                &lt;Nodes&gt; –&gt; output0_chanfirst (N, C, D1, D2, …, Dn) –&gt; Transpose
                    –&gt; output0 (N, D1, D2, …, Dn, C)

            This can potentially improve inference latency for QDQ models running on QNN EP because the
            additional transpose node may allow other transpose nodes inserted during ORT layout transformation
            to cancel out.</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-41">
<span class="sig-name descname"><span class="pre">save_as_external_data</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-41" title="Link to this definition">#</a></dt>
<dd><p>Serializes tensor data to separate files instead of directly in the ONNX file. Large models (&gt;2GB) may be forced to save external data regardless of the value of this parameter.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-42">
<span class="sig-name descname"><span class="pre">all_tensors_to_one_file</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-42" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, save all tensors to one external file specified by ‘external_data_name’. If false, save each tensor to a file named with the tensor name.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-43">
<span class="sig-name descname"><span class="pre">external_data_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-43" title="Link to this definition">#</a></dt>
<dd><p>Effective only if all_tensors_to_one_file is True and save_as_external_data is True. If not specified, the external data file will be named with &lt;model_path_name&gt;.data</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-44">
<span class="sig-name descname"><span class="pre">size_threshold</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-44" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. Threshold for size of data. Only when tensor’s data is &gt;= the size_threshold it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1024</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-45">
<span class="sig-name descname"><span class="pre">convert_attribute</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-45" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, convert all tensors to external data If false, convert only non-attribute tensors to external data</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="onnxquantizationpreprocess">
<span id="onnx-quantization-preprocess"></span><h2>OnnxQuantizationPreprocess<a class="headerlink" href="#onnxquantizationpreprocess" title="Link to this heading">#</a></h2>
<p>ONNX Quantization Preprocess Pass. Same as OnnxQuantization quant_preprocess.</p>
<p><strong>Input:</strong> handler.onnx.ONNXModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-skip_optimization">
<span class="sig-name descname"><span class="pre">skip_optimization</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-skip_optimization" title="Link to this definition">#</a></dt>
<dd><p>Skip model optimization step if true. This may result in ONNX shape inference failure for some models.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-skip_onnx_shape">
<span class="sig-name descname"><span class="pre">skip_onnx_shape</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-skip_onnx_shape" title="Link to this definition">#</a></dt>
<dd><p>Skip ONNX shape inference. Symbolic shape inference is most effective with transformer based models. Skipping all shape inferences may reduce the effectiveness of quantization, as a tensor with unknown shape can not be quantized.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-skip_symbolic_shape">
<span class="sig-name descname"><span class="pre">skip_symbolic_shape</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-skip_symbolic_shape" title="Link to this definition">#</a></dt>
<dd><p>Skip symbolic shape inference. Symbolic shape inference is most effective with transformer based models. Skipping all shape inferences may reduce the effectiveness of quantization, as a tensor with unknown shape can not be quantized.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-46">
<span class="sig-name descname"><span class="pre">save_as_external_data</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-46" title="Link to this definition">#</a></dt>
<dd><p>Serializes tensor data to separate files instead of directly in the ONNX file. Large models (&gt;2GB) may be forced to save external data regardless of the value of this parameter.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-47">
<span class="sig-name descname"><span class="pre">all_tensors_to_one_file</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-47" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, save all tensors to one external file specified by ‘external_data_name’. If false, save each tensor to a file named with the tensor name.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-48">
<span class="sig-name descname"><span class="pre">external_data_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-48" title="Link to this definition">#</a></dt>
<dd><p>Effective only if all_tensors_to_one_file is True and save_as_external_data is True. If not specified, the external data file will be named with &lt;model_path_name&gt;.data</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-49">
<span class="sig-name descname"><span class="pre">size_threshold</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-49" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. Threshold for size of data. Only when tensor’s data is &gt;= the size_threshold it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1024</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-50">
<span class="sig-name descname"><span class="pre">convert_attribute</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-50" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, convert all tensors to external data If false, convert only non-attribute tensors to external data</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="mixedprecisionoverrides">
<span id="mixed-precision-overrides"></span><h2>MixedPrecisionOverrides<a class="headerlink" href="#mixedprecisionoverrides" title="Link to this heading">#</a></h2>
<p>Qnn mixed precision overrides pass.

    Pre-processes the model for mixed precision quantization by resolving
    constraints that each operator has when being converted to QNN operator
    Constraints refer to situations where certain tensor cannot be quantized
    to 16 bits standalone but rather neighboring tensors as well in order
    to have valid operators.

    Specific problem that arises here is the situation where certain tensor
    can be input to multiple nodes and each node requires different precision

    NOTE: This pass handles just initializer tensors as activation tensors are handled by onnxruntime</p>
<p><strong>Input:</strong> handler.onnx.ONNXModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-overrides_config">
<span class="sig-name descname"><span class="pre">overrides_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-overrides_config" title="Link to this definition">#</a></dt>
<dd><p>Path/Dict to mixed precision overrides json, with the format of {tensor_name: quant_type}</p>
<p><strong>type:</strong> str | Dict</p>
<p><strong>required:</strong> True</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-element_wise_binary_ops">
<span class="sig-name descname"><span class="pre">element_wise_binary_ops</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-element_wise_binary_ops" title="Link to this definition">#</a></dt>
<dd><p>List of element wise binary ops, if not provided defaults to [‘Add’, ‘Sub’, ‘Mul’, ‘Div’]</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-51">
<span class="sig-name descname"><span class="pre">save_as_external_data</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-51" title="Link to this definition">#</a></dt>
<dd><p>Serializes tensor data to separate files instead of directly in the ONNX file. Large models (&gt;2GB) may be forced to save external data regardless of the value of this parameter.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-52">
<span class="sig-name descname"><span class="pre">all_tensors_to_one_file</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-52" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, save all tensors to one external file specified by ‘external_data_name’. If false, save each tensor to a file named with the tensor name.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-53">
<span class="sig-name descname"><span class="pre">external_data_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-53" title="Link to this definition">#</a></dt>
<dd><p>Effective only if all_tensors_to_one_file is True and save_as_external_data is True. If not specified, the external data file will be named with &lt;model_path_name&gt;.data</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-54">
<span class="sig-name descname"><span class="pre">size_threshold</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-54" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. Threshold for size of data. Only when tensor’s data is &gt;= the size_threshold it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1024</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-55">
<span class="sig-name descname"><span class="pre">convert_attribute</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-55" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, convert all tensors to external data If false, convert only non-attribute tensors to external data</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="onnxdynamicquantization">
<span id="onnx-dynamic-quantization"></span><h2>OnnxDynamicQuantization<a class="headerlink" href="#onnxdynamicquantization" title="Link to this heading">#</a></h2>
<p>ONNX Dynamic Quantization Pass.</p>
<p><strong>Input:</strong> handler.onnx.ONNXModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-quant_mode">
<span class="sig-name descname"><span class="pre">quant_mode</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-quant_mode" title="Link to this definition">#</a></dt>
<dd><p>dynamic quantization mode</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> dynamic</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-weight_type">
<span class="sig-name descname"><span class="pre">weight_type</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-weight_type" title="Link to this definition">#</a></dt>
<dd><p>
            Data type for quantizing weights which is used both in dynamic
            and static quantization. ‘QInt8’ for signed 8-bit integer,
            ‘QUInt8’ for unsigned 8-bit integer.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> QInt8</p>
<p><strong>search_defaults:</strong> Categorical([‘QInt8’, ‘QUInt8’])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-op_types_to_quantize">
<span class="sig-name descname"><span class="pre">op_types_to_quantize</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-op_types_to_quantize" title="Link to this definition">#</a></dt>
<dd><p>
            List of operator types to quantize. If None, all quantizable.</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-op_types_to_exclude">
<span class="sig-name descname"><span class="pre">op_types_to_exclude</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-op_types_to_exclude" title="Link to this definition">#</a></dt>
<dd><p>
            List of operator types to exclude from quantization. If None, all quantizable. op_types_to_quantize takes
            precedence over op_types_to_exclude. If both are set, op_types_to_quantize will be used.</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-nodes_to_quantize">
<span class="sig-name descname"><span class="pre">nodes_to_quantize</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-nodes_to_quantize" title="Link to this definition">#</a></dt>
<dd><p>
            List of node names to quantize. If None, all quantizable.</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-nodes_to_exclude">
<span class="sig-name descname"><span class="pre">nodes_to_exclude</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-nodes_to_exclude" title="Link to this definition">#</a></dt>
<dd><p>
            List of node names to exclude from quantization. If None, all quantizable.</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-per_channel">
<span class="sig-name descname"><span class="pre">per_channel</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-per_channel" title="Link to this definition">#</a></dt>
<dd><p>
            Quantize weights per channel.
            Tips: When to use reduce_range and per-channel quantization:
            <a class="reference external" href="https://onnxruntime.ai/docs/performance/quantization.html#when-to-use-reduce-range-and-per-channel-quantization">https://onnxruntime.ai/docs/performance/quantization.html#when-to-use-reduce-range-and-per-channel-quantization</a></p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> Categorical([True, False])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-reduce_range">
<span class="sig-name descname"><span class="pre">reduce_range</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-reduce_range" title="Link to this definition">#</a></dt>
<dd><p>
            Quantize weights with 7-bits. It may improve the accuracy for
            some models running on non-VNNI machine, especially for per-channel mode.
            Tips: When to use reduce_range and per-channel quantization:
            <a class="reference external" href="https://onnxruntime.ai/docs/performance/quantization.html#when-to-use-reduce-range-and-per-channel-quantization">https://onnxruntime.ai/docs/performance/quantization.html#when-to-use-reduce-range-and-per-channel-quantization</a></p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> Categorical([True, False])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-quant_preprocess">
<span class="sig-name descname"><span class="pre">quant_preprocess</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-quant_preprocess" title="Link to this definition">#</a></dt>
<dd><p>
            Shape inference and model optimization, in preparation for quantization.
            <a class="reference external" href="https://onnxruntime.ai/docs/performance/quantization.html#pre-processing">https://onnxruntime.ai/docs/performance/quantization.html#pre-processing</a></p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> Categorical([True, False])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-activation_symmetric">
<span class="sig-name descname"><span class="pre">activation_symmetric</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-activation_symmetric" title="Link to this definition">#</a></dt>
<dd><p>
            Symmetric quantization for activations.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-weight_symmetric">
<span class="sig-name descname"><span class="pre">weight_symmetric</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-weight_symmetric" title="Link to this definition">#</a></dt>
<dd><p>
            Symmetric quantization for weights. Defaults to None. If set to None, it is assumed true if
            weight_type is signed, false otherwise.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-extra_options">
<span class="sig-name descname"><span class="pre">extra_options</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-extra_options" title="Link to this definition">#</a></dt>
<dd><p>
            Key value pair dictionary for <cite>extra_options</cite> in quantization. Please refer to
            <a class="github reference external" href="https://github.com/microsoft/onnxruntime/blob/main/onnxruntime/python/tools/quantization/quantize.py">microsoft/onnxruntime</a>
            for details about the supported options. If an option is one of
            ActivationSymmetric, WeightSymmetric, MinimumRealRange or TensorQuantOverrides, it will be overwritten
            by the corresponding config parameter value.</p>
<p><strong>type:</strong> dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-56">
<span class="sig-name descname"><span class="pre">save_as_external_data</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-56" title="Link to this definition">#</a></dt>
<dd><p>Serializes tensor data to separate files instead of directly in the ONNX file. Large models (&gt;2GB) may be forced to save external data regardless of the value of this parameter.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-57">
<span class="sig-name descname"><span class="pre">all_tensors_to_one_file</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-57" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, save all tensors to one external file specified by ‘external_data_name’. If false, save each tensor to a file named with the tensor name.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-58">
<span class="sig-name descname"><span class="pre">external_data_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-58" title="Link to this definition">#</a></dt>
<dd><p>Effective only if all_tensors_to_one_file is True and save_as_external_data is True. If not specified, the external data file will be named with &lt;model_path_name&gt;.data</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-59">
<span class="sig-name descname"><span class="pre">size_threshold</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-59" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. Threshold for size of data. Only when tensor’s data is &gt;= the size_threshold it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1024</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-60">
<span class="sig-name descname"><span class="pre">convert_attribute</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-60" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, convert all tensors to external data If false, convert only non-attribute tensors to external data</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="onnxstaticquantization">
<span id="onnx-static-quantization"></span><h2>OnnxStaticQuantization<a class="headerlink" href="#onnxstaticquantization" title="Link to this heading">#</a></h2>
<p>ONNX Static Quantization Pass.</p>
<p><strong>Input:</strong> handler.onnx.ONNXModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-61">
<span class="sig-name descname"><span class="pre">quant_mode</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-61" title="Link to this definition">#</a></dt>
<dd><p>static quantization mode</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> static</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-62">
<span class="sig-name descname"><span class="pre">weight_type</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-62" title="Link to this definition">#</a></dt>
<dd><p>
            Data type for quantizing weights which is used both in dynamic
            and static quantization. ‘QInt8’ for signed 8-bit integer,
            ‘QUInt8’ for unsigned 8-bit integer.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> QInt8</p>
<p><strong>search_defaults:</strong> Categorical([‘QInt8’, ‘QUInt8’])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-63">
<span class="sig-name descname"><span class="pre">op_types_to_quantize</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-63" title="Link to this definition">#</a></dt>
<dd><p>
            List of operator types to quantize. If None, all quantizable.</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-64">
<span class="sig-name descname"><span class="pre">op_types_to_exclude</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-64" title="Link to this definition">#</a></dt>
<dd><p>
            List of operator types to exclude from quantization. If None, all quantizable. op_types_to_quantize takes
            precedence over op_types_to_exclude. If both are set, op_types_to_quantize will be used.</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-65">
<span class="sig-name descname"><span class="pre">nodes_to_quantize</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-65" title="Link to this definition">#</a></dt>
<dd><p>
            List of node names to quantize. If None, all quantizable.</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-66">
<span class="sig-name descname"><span class="pre">nodes_to_exclude</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-66" title="Link to this definition">#</a></dt>
<dd><p>
            List of node names to exclude from quantization. If None, all quantizable.</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-67">
<span class="sig-name descname"><span class="pre">per_channel</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-67" title="Link to this definition">#</a></dt>
<dd><p>
            Quantize weights per channel.
            Tips: When to use reduce_range and per-channel quantization:
            <a class="reference external" href="https://onnxruntime.ai/docs/performance/quantization.html#when-to-use-reduce-range-and-per-channel-quantization">https://onnxruntime.ai/docs/performance/quantization.html#when-to-use-reduce-range-and-per-channel-quantization</a></p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> Categorical([True, False])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-68">
<span class="sig-name descname"><span class="pre">reduce_range</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-68" title="Link to this definition">#</a></dt>
<dd><p>
            Quantize weights with 7-bits. It may improve the accuracy for
            some models running on non-VNNI machine, especially for per-channel mode.
            Tips: When to use reduce_range and per-channel quantization:
            <a class="reference external" href="https://onnxruntime.ai/docs/performance/quantization.html#when-to-use-reduce-range-and-per-channel-quantization">https://onnxruntime.ai/docs/performance/quantization.html#when-to-use-reduce-range-and-per-channel-quantization</a></p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> Categorical([True, False])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-69">
<span class="sig-name descname"><span class="pre">quant_preprocess</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-69" title="Link to this definition">#</a></dt>
<dd><p>
            Shape inference and model optimization, in preparation for quantization.
            <a class="reference external" href="https://onnxruntime.ai/docs/performance/quantization.html#pre-processing">https://onnxruntime.ai/docs/performance/quantization.html#pre-processing</a></p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> Categorical([True, False])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-70">
<span class="sig-name descname"><span class="pre">activation_symmetric</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-70" title="Link to this definition">#</a></dt>
<dd><p>
            Symmetric quantization for activations.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-71">
<span class="sig-name descname"><span class="pre">weight_symmetric</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-71" title="Link to this definition">#</a></dt>
<dd><p>
            Symmetric quantization for weights. Defaults to None. If set to None, it is assumed true if
            weight_type is signed, false otherwise.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-72">
<span class="sig-name descname"><span class="pre">data_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-72" title="Link to this definition">#</a></dt>
<dd><p>
            Data config for calibration, required if quant_mode is ‘static’</p>
<p><strong>type:</strong> olive.data.config.DataConfig | Dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-calibrate_method">
<span class="sig-name descname"><span class="pre">calibrate_method</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-calibrate_method" title="Link to this definition">#</a></dt>
<dd><p>Supported calibration methods are MinMax, Entropy and Percentile.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> MinMax</p>
<p><strong>search_defaults:</strong> Categorical([‘MinMax’, ‘Entropy’, ‘Percentile’])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-calibration_providers">
<span class="sig-name descname"><span class="pre">calibration_providers</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-calibration_providers" title="Link to this definition">#</a></dt>
<dd><p>
            Execution providers to run the session during calibration.
            Default is None which uses [ “CPUExecutionProvider” ].</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-quant_format">
<span class="sig-name descname"><span class="pre">quant_format</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-quant_format" title="Link to this definition">#</a></dt>
<dd><p>
            QOperator format quantizes the model with quantized operators directly.
            QDQ format quantize the model by inserting QuantizeLinear/DeQuantizeLinear on the tensor.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> QDQ</p>
<p><strong>search_defaults:</strong> Categorical([‘QOperator’, ‘QDQ’])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-activation_type">
<span class="sig-name descname"><span class="pre">activation_type</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-activation_type" title="Link to this definition">#</a></dt>
<dd><p>
            Quantization data type of activation. Please refer to
            <a class="reference external" href="https://onnxruntime.ai/docs/performance/quantization.html">https://onnxruntime.ai/docs/performance/quantization.html</a> for more details on data type selection</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> QInt8</p>
<p><strong>search_defaults:</strong> Conditional(parents: (‘quant_format’, ‘weight_type’), support: {(‘QDQ’, ‘QInt8’): Categorical([‘QInt8’]), (‘QDQ’, ‘QUInt8’): Categorical([‘QUInt8’]), (‘QOperator’, ‘QUInt8’): Categorical([‘QUInt8’]), (‘QOperator’, ‘QInt8’): Categorical([&lt;SpecialParamValue.INVALID: ‘OLIVE_INVALID_PARAM_VALUE’&gt;])}, default: Categorical([&lt;SpecialParamValue.INVALID: ‘OLIVE_INVALID_PARAM_VALUE’&gt;]))</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-min_real_range">
<span class="sig-name descname"><span class="pre">min_real_range</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-min_real_range" title="Link to this definition">#</a></dt>
<dd><p>
            Minimum real range for quantization. If set, enforces the minimum range between rmin and rmax.</p>
<p><strong>type:</strong> float</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-tensor_quant_overrides">
<span class="sig-name descname"><span class="pre">tensor_quant_overrides</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-tensor_quant_overrides" title="Link to this definition">#</a></dt>
<dd><p>
            tensor-level quantization overrides.</p>
<p><strong>type:</strong> dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-prepare_qdq_config">
<span class="sig-name descname"><span class="pre">prepare_qdq_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-prepare_qdq_config" title="Link to this definition">#</a></dt>
<dd><p>
            Generate a quantization configuration for a full integer QDQ model. Otherwise, only a limited set of
            operators are quantized. Only supported after onnxruntime 1.21.0 for EPs other than QNN.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-73">
<span class="sig-name descname"><span class="pre">extra_options</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-73" title="Link to this definition">#</a></dt>
<dd><p>
            Key value pair dictionary for <cite>extra_options</cite> in quantization. Please refer to
            <a class="github reference external" href="https://github.com/microsoft/onnxruntime/blob/main/onnxruntime/python/tools/quantization/quantize.py">microsoft/onnxruntime</a>
            for details about the supported options. If an option is one of
            ActivationSymmetric, WeightSymmetric, MinimumRealRange or TensorQuantOverrides, it will be overwritten
            by the corresponding config parameter value.</p>
<p><strong>type:</strong> dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-74">
<span class="sig-name descname"><span class="pre">save_as_external_data</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-74" title="Link to this definition">#</a></dt>
<dd><p>Serializes tensor data to separate files instead of directly in the ONNX file. Large models (&gt;2GB) may be forced to save external data regardless of the value of this parameter.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-75">
<span class="sig-name descname"><span class="pre">all_tensors_to_one_file</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-75" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, save all tensors to one external file specified by ‘external_data_name’. If false, save each tensor to a file named with the tensor name.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-76">
<span class="sig-name descname"><span class="pre">external_data_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-76" title="Link to this definition">#</a></dt>
<dd><p>Effective only if all_tensors_to_one_file is True and save_as_external_data is True. If not specified, the external data file will be named with &lt;model_path_name&gt;.data</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-77">
<span class="sig-name descname"><span class="pre">size_threshold</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-77" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. Threshold for size of data. Only when tensor’s data is &gt;= the size_threshold it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1024</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-78">
<span class="sig-name descname"><span class="pre">convert_attribute</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-78" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, convert all tensors to external data If false, convert only non-attribute tensors to external data</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="onnxquantization">
<span id="onnx-quantization"></span><h2>OnnxQuantization<a class="headerlink" href="#onnxquantization" title="Link to this heading">#</a></h2>
<p>Quantize ONNX model with static/dynamic quantization techniques.</p>
<p><strong>Input:</strong> handler.onnx.ONNXModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-79">
<span class="sig-name descname"><span class="pre">quant_mode</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-79" title="Link to this definition">#</a></dt>
<dd><p>
                    Onnx Quantization mode. ‘dynamic’ for dynamic quantization,
                    ‘static’ for static quantization.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> static</p>
<p><strong>search_defaults:</strong> Categorical([‘dynamic’, ‘static’])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-80">
<span class="sig-name descname"><span class="pre">weight_type</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-80" title="Link to this definition">#</a></dt>
<dd><p>
            Data type for quantizing weights which is used both in dynamic
            and static quantization. ‘QInt8’ for signed 8-bit integer,
            ‘QUInt8’ for unsigned 8-bit integer.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> QInt8</p>
<p><strong>search_defaults:</strong> Categorical([‘QInt8’, ‘QUInt8’])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-81">
<span class="sig-name descname"><span class="pre">op_types_to_quantize</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-81" title="Link to this definition">#</a></dt>
<dd><p>
            List of operator types to quantize. If None, all quantizable.</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-82">
<span class="sig-name descname"><span class="pre">op_types_to_exclude</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-82" title="Link to this definition">#</a></dt>
<dd><p>
            List of operator types to exclude from quantization. If None, all quantizable. op_types_to_quantize takes
            precedence over op_types_to_exclude. If both are set, op_types_to_quantize will be used.</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-83">
<span class="sig-name descname"><span class="pre">nodes_to_quantize</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-83" title="Link to this definition">#</a></dt>
<dd><p>
            List of node names to quantize. If None, all quantizable.</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-84">
<span class="sig-name descname"><span class="pre">nodes_to_exclude</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-84" title="Link to this definition">#</a></dt>
<dd><p>
            List of node names to exclude from quantization. If None, all quantizable.</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-85">
<span class="sig-name descname"><span class="pre">per_channel</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-85" title="Link to this definition">#</a></dt>
<dd><p>
            Quantize weights per channel.
            Tips: When to use reduce_range and per-channel quantization:
            <a class="reference external" href="https://onnxruntime.ai/docs/performance/quantization.html#when-to-use-reduce-range-and-per-channel-quantization">https://onnxruntime.ai/docs/performance/quantization.html#when-to-use-reduce-range-and-per-channel-quantization</a></p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> Categorical([True, False])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-86">
<span class="sig-name descname"><span class="pre">reduce_range</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-86" title="Link to this definition">#</a></dt>
<dd><p>
            Quantize weights with 7-bits. It may improve the accuracy for
            some models running on non-VNNI machine, especially for per-channel mode.
            Tips: When to use reduce_range and per-channel quantization:
            <a class="reference external" href="https://onnxruntime.ai/docs/performance/quantization.html#when-to-use-reduce-range-and-per-channel-quantization">https://onnxruntime.ai/docs/performance/quantization.html#when-to-use-reduce-range-and-per-channel-quantization</a></p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> Categorical([True, False])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-87">
<span class="sig-name descname"><span class="pre">quant_preprocess</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-87" title="Link to this definition">#</a></dt>
<dd><p>
            Shape inference and model optimization, in preparation for quantization.
            <a class="reference external" href="https://onnxruntime.ai/docs/performance/quantization.html#pre-processing">https://onnxruntime.ai/docs/performance/quantization.html#pre-processing</a></p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> Categorical([True, False])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-88">
<span class="sig-name descname"><span class="pre">activation_symmetric</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-88" title="Link to this definition">#</a></dt>
<dd><p>
            Symmetric quantization for activations.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-89">
<span class="sig-name descname"><span class="pre">weight_symmetric</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-89" title="Link to this definition">#</a></dt>
<dd><p>
            Symmetric quantization for weights. Defaults to None. If set to None, it is assumed true if
            weight_type is signed, false otherwise.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-90">
<span class="sig-name descname"><span class="pre">data_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-90" title="Link to this definition">#</a></dt>
<dd><p>
            Data config for calibration, required if quant_mode is ‘static’</p>
<p><strong>type:</strong> olive.data.config.DataConfig | Dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-91">
<span class="sig-name descname"><span class="pre">calibrate_method</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-91" title="Link to this definition">#</a></dt>
<dd><p>Supported calibration methods are MinMax, Entropy and Percentile.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> ConditionalDefault(parents: (‘quant_mode’,), support: {(‘static’,): ‘MinMax’, (‘dynamic’,): &lt;SpecialParamValue.IGNORED: ‘OLIVE_IGNORED_PARAM_VALUE’&gt;}, default: OLIVE_INVALID_PARAM_VALUE)</p>
<p><strong>search_defaults:</strong> Conditional(parents: (‘quant_mode’,), support: {(‘static’,): Categorical([‘MinMax’, ‘Entropy’, ‘Percentile’])}, default: Categorical([&lt;SpecialParamValue.IGNORED: ‘OLIVE_IGNORED_PARAM_VALUE’&gt;]))</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-92">
<span class="sig-name descname"><span class="pre">calibration_providers</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-92" title="Link to this definition">#</a></dt>
<dd><p>
            Execution providers to run the session during calibration.
            Default is None which uses [ “CPUExecutionProvider” ].</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> ConditionalDefault(parents: (‘quant_mode’,), support: {(‘static’,): None, (‘dynamic’,): &lt;SpecialParamValue.IGNORED: ‘OLIVE_IGNORED_PARAM_VALUE’&gt;}, default: OLIVE_INVALID_PARAM_VALUE)</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-93">
<span class="sig-name descname"><span class="pre">quant_format</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-93" title="Link to this definition">#</a></dt>
<dd><p>
            QOperator format quantizes the model with quantized operators directly.
            QDQ format quantize the model by inserting QuantizeLinear/DeQuantizeLinear on the tensor.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> ConditionalDefault(parents: (‘quant_mode’,), support: {(‘static’,): ‘QDQ’, (‘dynamic’,): &lt;SpecialParamValue.IGNORED: ‘OLIVE_IGNORED_PARAM_VALUE’&gt;}, default: OLIVE_INVALID_PARAM_VALUE)</p>
<p><strong>search_defaults:</strong> Conditional(parents: (‘quant_mode’,), support: {(‘static’,): Categorical([‘QOperator’, ‘QDQ’])}, default: Categorical([&lt;SpecialParamValue.IGNORED: ‘OLIVE_IGNORED_PARAM_VALUE’&gt;]))</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-94">
<span class="sig-name descname"><span class="pre">activation_type</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-94" title="Link to this definition">#</a></dt>
<dd><p>
            Quantization data type of activation. Please refer to
            <a class="reference external" href="https://onnxruntime.ai/docs/performance/quantization.html">https://onnxruntime.ai/docs/performance/quantization.html</a> for more details on data type selection</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> ConditionalDefault(parents: (‘quant_mode’,), support: {(‘static’,): ‘QInt8’, (‘dynamic’,): &lt;SpecialParamValue.IGNORED: ‘OLIVE_IGNORED_PARAM_VALUE’&gt;}, default: OLIVE_INVALID_PARAM_VALUE)</p>
<p><strong>search_defaults:</strong> Conditional(parents: (‘quant_mode’, ‘quant_format’, ‘weight_type’), support: {(‘static’, ‘QDQ’, ‘QInt8’): Categorical([‘QInt8’]), (‘static’, ‘QDQ’, ‘QUInt8’): Categorical([‘QUInt8’]), (‘static’, ‘QOperator’, ‘QUInt8’): Categorical([‘QUInt8’]), (‘static’, ‘QOperator’, ‘QInt8’): Categorical([&lt;SpecialParamValue.INVALID: ‘OLIVE_INVALID_PARAM_VALUE’&gt;])}, default: Categorical([&lt;SpecialParamValue.IGNORED: ‘OLIVE_IGNORED_PARAM_VALUE’&gt;]))</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-95">
<span class="sig-name descname"><span class="pre">min_real_range</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-95" title="Link to this definition">#</a></dt>
<dd><p>
            Minimum real range for quantization. If set, enforces the minimum range between rmin and rmax.</p>
<p><strong>type:</strong> float</p>
<p><strong>default_value:</strong> ConditionalDefault(parents: (‘quant_mode’,), support: {(‘static’,): None, (‘dynamic’,): &lt;SpecialParamValue.IGNORED: ‘OLIVE_IGNORED_PARAM_VALUE’&gt;}, default: OLIVE_INVALID_PARAM_VALUE)</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-96">
<span class="sig-name descname"><span class="pre">tensor_quant_overrides</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-96" title="Link to this definition">#</a></dt>
<dd><p>
            tensor-level quantization overrides.</p>
<p><strong>type:</strong> dict</p>
<p><strong>default_value:</strong> ConditionalDefault(parents: (‘quant_mode’,), support: {(‘static’,): None, (‘dynamic’,): &lt;SpecialParamValue.IGNORED: ‘OLIVE_IGNORED_PARAM_VALUE’&gt;}, default: OLIVE_INVALID_PARAM_VALUE)</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-97">
<span class="sig-name descname"><span class="pre">prepare_qdq_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-97" title="Link to this definition">#</a></dt>
<dd><p>
            Generate a quantization configuration for a full integer QDQ model. Otherwise, only a limited set of
            operators are quantized. Only supported after onnxruntime 1.21.0 for EPs other than QNN.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> ConditionalDefault(parents: (‘quant_mode’,), support: {(‘static’,): True, (‘dynamic’,): &lt;SpecialParamValue.IGNORED: ‘OLIVE_IGNORED_PARAM_VALUE’&gt;}, default: OLIVE_INVALID_PARAM_VALUE)</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-98">
<span class="sig-name descname"><span class="pre">extra_options</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-98" title="Link to this definition">#</a></dt>
<dd><p>
            Key value pair dictionary for <cite>extra_options</cite> in quantization. Please refer to
            <a class="github reference external" href="https://github.com/microsoft/onnxruntime/blob/main/onnxruntime/python/tools/quantization/quantize.py">microsoft/onnxruntime</a>
            for details about the supported options. If an option is one of
            ActivationSymmetric, WeightSymmetric, MinimumRealRange or TensorQuantOverrides, it will be overwritten
            by the corresponding config parameter value.</p>
<p><strong>type:</strong> dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-99">
<span class="sig-name descname"><span class="pre">save_as_external_data</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-99" title="Link to this definition">#</a></dt>
<dd><p>Serializes tensor data to separate files instead of directly in the ONNX file. Large models (&gt;2GB) may be forced to save external data regardless of the value of this parameter.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-100">
<span class="sig-name descname"><span class="pre">all_tensors_to_one_file</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-100" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, save all tensors to one external file specified by ‘external_data_name’. If false, save each tensor to a file named with the tensor name.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-101">
<span class="sig-name descname"><span class="pre">external_data_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-101" title="Link to this definition">#</a></dt>
<dd><p>Effective only if all_tensors_to_one_file is True and save_as_external_data is True. If not specified, the external data file will be named with &lt;model_path_name&gt;.data</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-102">
<span class="sig-name descname"><span class="pre">size_threshold</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-102" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. Threshold for size of data. Only when tensor’s data is &gt;= the size_threshold it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1024</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-103">
<span class="sig-name descname"><span class="pre">convert_attribute</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-103" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, convert all tensors to external data If false, convert only non-attribute tensors to external data</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="onnxmatmul4quantizer">
<span id="onnx-matmul4-quantizer"></span><h2>OnnxMatMul4Quantizer<a class="headerlink" href="#onnxmatmul4quantizer" title="Link to this heading">#</a></h2>
<p>Quantize ONNX models’ MatMul operations to 4-bit weights.</p>
<p><strong>Input:</strong> handler.onnx.ONNXModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-block_size">
<span class="sig-name descname"><span class="pre">block_size</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-block_size" title="Link to this definition">#</a></dt>
<dd><p>Block size for quantization. Default value is 32.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 32</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-is_symmetric">
<span class="sig-name descname"><span class="pre">is_symmetric</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-is_symmetric" title="Link to this definition">#</a></dt>
<dd><p>Symmetric quantization. Default value is True.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-104">
<span class="sig-name descname"><span class="pre">nodes_to_exclude</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-104" title="Link to this definition">#</a></dt>
<dd><p>List of node names to exclude from quantization.</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-nodes_to_include">
<span class="sig-name descname"><span class="pre">nodes_to_include</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-nodes_to_include" title="Link to this definition">#</a></dt>
<dd><p>List of node names to include in quantization.</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-105">
<span class="sig-name descname"><span class="pre">op_types_to_quantize</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-105" title="Link to this definition">#</a></dt>
<dd><p>List of operator types to quantize. Default value is None = [“MatMul”]. Supported op types are: MatMul, Gather.</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-quant_axes">
<span class="sig-name descname"><span class="pre">quant_axes</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-quant_axes" title="Link to this definition">#</a></dt>
<dd><p>op:axis, which axis to quantize for an op. Default is None = {“MatMul”: 0, “Gather”: 1}</p>
<p><strong>type:</strong> Dict[str, int]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-accuracy_level">
<span class="sig-name descname"><span class="pre">accuracy_level</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-accuracy_level" title="Link to this definition">#</a></dt>
<dd><p>Accuracy level of the 4-bit quantized MatMul computation. Refer to the MatMulNBits contrib op’s ‘accuracy_level’ attribute for details (<a class="github reference external" href="https://github.com/microsoft/onnxruntime/blob/main/docs/ContribOperators.md#commicrosoftmatmulnbits">microsoft/onnxruntime</a>).</p>
<p><strong>type:</strong> olive.passes.onnx.quantization.OnnxMatMul4Quantizer.AccuracyLevel</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-algorithm">
<span class="sig-name descname"><span class="pre">algorithm</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-algorithm" title="Link to this definition">#</a></dt>
<dd><p>The algorithm used to quantize weight. If None, the default algorithm is used with quant config created from the pass configuration.</p>
<p><strong>type:</strong> olive.passes.onnx.quantization.OnnxMatMul4Quantizer.Algorithm</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-weight_only_quant_configs">
<span class="sig-name descname"><span class="pre">weight_only_quant_configs</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-weight_only_quant_configs" title="Link to this definition">#</a></dt>
<dd><p>If ‘algorithm’ is provided and this is None, the config is constructed from the pass configuration. If provided, the it takes precedence. Refer to <a class="github reference external" href="https://github.com/microsoft/onnxruntime/blob/main/onnxruntime/python/tools/quantization/matmul_4bits_quantizer.py">microsoft/onnxruntime</a> for details.</p>
<p><strong>type:</strong> dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-106">
<span class="sig-name descname"><span class="pre">save_as_external_data</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-106" title="Link to this definition">#</a></dt>
<dd><p>Serializes tensor data to separate files instead of directly in the ONNX file. Large models (&gt;2GB) may be forced to save external data regardless of the value of this parameter.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-107">
<span class="sig-name descname"><span class="pre">all_tensors_to_one_file</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-107" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, save all tensors to one external file specified by ‘external_data_name’. If false, save each tensor to a file named with the tensor name.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-108">
<span class="sig-name descname"><span class="pre">external_data_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-108" title="Link to this definition">#</a></dt>
<dd><p>Effective only if all_tensors_to_one_file is True and save_as_external_data is True. If not specified, the external data file will be named with &lt;model_path_name&gt;.data</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-109">
<span class="sig-name descname"><span class="pre">size_threshold</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-109" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. Threshold for size of data. Only when tensor’s data is &gt;= the size_threshold it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1024</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-110">
<span class="sig-name descname"><span class="pre">convert_attribute</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-110" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, convert all tensors to external data If false, convert only non-attribute tensors to external data</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-111">
<span class="sig-name descname"><span class="pre">data_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-111" title="Link to this definition">#</a></dt>
<dd><p>
            Data config for calibration, required if quant_mode is ‘static’</p>
<p><strong>type:</strong> olive.data.config.DataConfig | Dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="graphsurgeries">
<span id="graph-surgeries"></span><h2>GraphSurgeries<a class="headerlink" href="#graphsurgeries" title="Link to this heading">#</a></h2>
<p>ONNX graph surgeries collections.

    This pass applies a list of surgeries to the ONNX model.
    Each surgery is a transformation on the ONNX graph.

    Example:
        surgeries: {
            type: “GraphSurgeries”,
            surgeries: [
                {
                    “surgeon”: “RenameInputs”,
                    “old_names”: [“input1”, “input2”]
                    “new_names”: [“renamed_input1”, “renamed_input2”]
                },
                {
                    “surgeon”: “RenameOutputs”,
                    “old_names”: [“output1”, “output2”]
                    “new_names”: [“renamed_output1”, “renamed_output2”]
                }
            ]
        }</p>
<p><strong>Input:</strong> handler.onnx.ONNXModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-surgeries">
<span class="sig-name descname"><span class="pre">surgeries</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-surgeries" title="Link to this definition">#</a></dt>
<dd><p>List of surgeries to apply, each with its type and parameters</p>
<p><strong>type:</strong> List[Dict[str, Any]]</p>
<p><strong>required:</strong> True</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-112">
<span class="sig-name descname"><span class="pre">save_as_external_data</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-112" title="Link to this definition">#</a></dt>
<dd><p>Serializes tensor data to separate files instead of directly in the ONNX file. Large models (&gt;2GB) may be forced to save external data regardless of the value of this parameter.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-113">
<span class="sig-name descname"><span class="pre">all_tensors_to_one_file</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-113" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, save all tensors to one external file specified by ‘external_data_name’. If false, save each tensor to a file named with the tensor name.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-114">
<span class="sig-name descname"><span class="pre">external_data_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-114" title="Link to this definition">#</a></dt>
<dd><p>Effective only if all_tensors_to_one_file is True and save_as_external_data is True. If not specified, the external data file will be named with &lt;model_path_name&gt;.data</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-115">
<span class="sig-name descname"><span class="pre">size_threshold</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-115" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. Threshold for size of data. Only when tensor’s data is &gt;= the size_threshold it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1024</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-116">
<span class="sig-name descname"><span class="pre">convert_attribute</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-116" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, convert all tensors to external data If false, convert only non-attribute tensors to external data</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="matmulnbitstoqdq">
<span id="matmulnbits-to-qdq"></span><h2>MatMulNBitsToQDQ<a class="headerlink" href="#matmulnbitstoqdq" title="Link to this heading">#</a></h2>
<p>Convert ONNX MatMulNBits nodes to standard ONNX quantized-dequantized (QDQ) format.</p>
<p><strong>Input:</strong> handler.onnx.ONNXModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-use_transpose_op">
<span class="sig-name descname"><span class="pre">use_transpose_op</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-use_transpose_op" title="Link to this definition">#</a></dt>
<dd><p>Whether to use a Transpose operator after the DequantizeLinear operator. If False, the weight initializer will be transposed instead. Default is False. True might be more efficient on some EPs such as DirectML.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-use_int4">
<span class="sig-name descname"><span class="pre">use_int4</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-use_int4" title="Link to this definition">#</a></dt>
<dd><p>Whether to use int4 data type for the quantized weight. Default is False and uses uint4 data type.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-add_zero_point">
<span class="sig-name descname"><span class="pre">add_zero_point</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-add_zero_point" title="Link to this definition">#</a></dt>
<dd><p>Whether to add zero point for symmetric quantized weights, i.e., DQ zero point is 0. Default is False.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-117">
<span class="sig-name descname"><span class="pre">nodes_to_exclude</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-117" title="Link to this definition">#</a></dt>
<dd><p>List of node names to exclude from the conversion. The node names should be the names of the MatMulNBits nodes. Default is None.</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-118">
<span class="sig-name descname"><span class="pre">save_as_external_data</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-118" title="Link to this definition">#</a></dt>
<dd><p>Serializes tensor data to separate files instead of directly in the ONNX file. Large models (&gt;2GB) may be forced to save external data regardless of the value of this parameter.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-119">
<span class="sig-name descname"><span class="pre">all_tensors_to_one_file</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-119" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, save all tensors to one external file specified by ‘external_data_name’. If false, save each tensor to a file named with the tensor name.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-120">
<span class="sig-name descname"><span class="pre">external_data_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-120" title="Link to this definition">#</a></dt>
<dd><p>Effective only if all_tensors_to_one_file is True and save_as_external_data is True. If not specified, the external data file will be named with &lt;model_path_name&gt;.data</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-121">
<span class="sig-name descname"><span class="pre">size_threshold</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-121" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. Threshold for size of data. Only when tensor’s data is &gt;= the size_threshold it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1024</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-122">
<span class="sig-name descname"><span class="pre">convert_attribute</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-122" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, convert all tensors to external data If false, convert only non-attribute tensors to external data</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="dynamictofixedshape">
<span id="dynamic-to-fixed-shape"></span><h2>DynamicToFixedShape<a class="headerlink" href="#dynamictofixedshape" title="Link to this heading">#</a></h2>
<p>Convert dynamic shape to fixed shape for ONNX model.</p>
<p><strong>Input:</strong> handler.onnx.ONNXModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-dim_param">
<span class="sig-name descname"><span class="pre">dim_param</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-dim_param" title="Link to this definition">#</a></dt>
<dd><p>Symbolic parameter name. Provide dim_value if specified.</p>
<p><strong>type:</strong> List[str]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-dim_value">
<span class="sig-name descname"><span class="pre">dim_value</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-dim_value" title="Link to this definition">#</a></dt>
<dd><p>Value to replace dim_param with in the model. Must be &gt; 0.</p>
<p><strong>type:</strong> List[int]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-input_name">
<span class="sig-name descname"><span class="pre">input_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-input_name" title="Link to this definition">#</a></dt>
<dd><p>Model input name to replace shape of. Provide input_shape if specified.</p>
<p><strong>type:</strong> List[str]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-input_shape">
<span class="sig-name descname"><span class="pre">input_shape</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-input_shape" title="Link to this definition">#</a></dt>
<dd><p>Shape to use for input_shape. Provide comma separated list for the shape. All values must be &gt; 0. e.g. [1,3,256,256]</p>
<p><strong>type:</strong> List[List[int]]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-123">
<span class="sig-name descname"><span class="pre">save_as_external_data</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-123" title="Link to this definition">#</a></dt>
<dd><p>Serializes tensor data to separate files instead of directly in the ONNX file. Large models (&gt;2GB) may be forced to save external data regardless of the value of this parameter.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-124">
<span class="sig-name descname"><span class="pre">all_tensors_to_one_file</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-124" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, save all tensors to one external file specified by ‘external_data_name’. If false, save each tensor to a file named with the tensor name.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-125">
<span class="sig-name descname"><span class="pre">external_data_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-125" title="Link to this definition">#</a></dt>
<dd><p>Effective only if all_tensors_to_one_file is True and save_as_external_data is True. If not specified, the external data file will be named with &lt;model_path_name&gt;.data</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-126">
<span class="sig-name descname"><span class="pre">size_threshold</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-126" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. Threshold for size of data. Only when tensor’s data is &gt;= the size_threshold it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1024</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-127">
<span class="sig-name descname"><span class="pre">convert_attribute</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-127" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, convert all tensors to external data If false, convert only non-attribute tensors to external data</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="incdynamicquantization">
<span id="inc-dynamic-quantization"></span><h2>IncDynamicQuantization<a class="headerlink" href="#incdynamicquantization" title="Link to this heading">#</a></h2>
<p>Intel® Neural Compressor Dynamic Quantization Pass.</p>
<p><strong>Input:</strong> handler.onnx.ONNXModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-approach">
<span class="sig-name descname"><span class="pre">approach</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-approach" title="Link to this definition">#</a></dt>
<dd><p>dynamic quantization mode</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> dynamic</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-128">
<span class="sig-name descname"><span class="pre">device</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-128" title="Link to this definition">#</a></dt>
<dd><p>
            Intel® Neural Compressor quantization device. Support ‘cpu’ and ‘gpu’.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> cpu</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-backend">
<span class="sig-name descname"><span class="pre">backend</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-backend" title="Link to this definition">#</a></dt>
<dd><p>
            Backend for model execution. Support ‘default’, ‘onnxrt_trt_ep’, ‘onnxrt_cuda_ep’</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> default</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-domain">
<span class="sig-name descname"><span class="pre">domain</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-domain" title="Link to this definition">#</a></dt>
<dd><p>
            Model domain. Support ‘auto’, ‘cv’, ‘object_detection’, ‘nlp’ and ‘recommendation_system’.
            Intel® Neural Compressor Adaptor will use specific quantization settings for different domains
            automatically, and explicitly specified quantization settings will override the automatic setting.
            If users set domain as auto, automatic detection for domain will be executed.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> auto</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-workspace">
<span class="sig-name descname"><span class="pre">workspace</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-workspace" title="Link to this definition">#</a></dt>
<dd><p>Workspace for Intel® Neural Compressor quantization where intermediate files and
            tuning history file are stored.  Default value is:
            “./nc_workspace/{}/”.format(datetime.datetime.now().strftime(“%Y-%m-%d_%H-%M-%S”))</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-recipes">
<span class="sig-name descname"><span class="pre">recipes</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-recipes" title="Link to this definition">#</a></dt>
<dd><p>
            Recipes for Intel® Neural Compressor quantization, support list is as below.
                ‘smooth_quant’: whether do smooth quant
                ‘smooth_quant_args’: parameters for smooth_quant
                ‘fast_bias_correction’: whether do fast bias correction
                ‘weight_correction’: whether do weight correction
                ‘gemm_to_matmul’: whether convert gemm to matmul and add, only valid for onnx models
                ‘graph_optimization_level’: support ‘DISABLE_ALL’, ‘ENABLE_BASIC’, ‘ENABLE_EXTENDED’, ‘ENABLE_ALL’
                                        only valid for onnx models
                ‘first_conv_or_matmul_quantization’: whether quantize the first conv or matmul
                ‘last_conv_or_matmul_quantization’: whether quantize the last conv or matmul
                ‘pre_post_process_quantization’: whether quantize the ops in preprocessing and postprocessing
                ‘add_qdq_pair_to_weight’: whether add QDQ pair for weights, only valid for onnxrt_trt_ep
                ‘optypes_to_exclude_output_quant’: don’t quantize output of specified optypes
                ‘dedicated_qdq_pair’: whether dedicate QDQ pair, only valid for onnxrt_trt_ep</p>
<p><strong>type:</strong> dict</p>
<p><strong>default_value:</strong> {}</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-129">
<span class="sig-name descname"><span class="pre">reduce_range</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-129" title="Link to this definition">#</a></dt>
<dd><p>
            Whether use 7 bit to quantization.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> Categorical([True, False])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-quant_level">
<span class="sig-name descname"><span class="pre">quant_level</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-quant_level" title="Link to this definition">#</a></dt>
<dd><p>
            Intel® Neural Compressor allows users to choose different tuning processes by specifying
            the quantization level (quant_level). Currently 3 quant_levels are supported.
            0 is conservative strategy, 1 is basic or user-specified strategy,
            auto (default) is the combination of 0 and 1.
            Please refer to
            <a class="github reference external" href="https://github.com/intel/neural-compressor/blob/master/docs/source/tuning_strategies.md#tuning-process">intel/neural-compressor</a>
            <a class="github reference external" href="https://github.com/intel/neural-compressor/blob/master/docs/source/tuning_strategies.md#tuning-algorithms">intel/neural-compressor</a>
            for more details</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> auto</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-excluded_precisions">
<span class="sig-name descname"><span class="pre">excluded_precisions</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-excluded_precisions" title="Link to this definition">#</a></dt>
<dd><p>
            Precisions to be excluded, Default value is empty list.
            Intel® Neural Compressor enable the mixed precision with
            fp32 + bf16(only when device is ‘gpu’ and backend is ‘onnxrt_cuda_ep’) + int8 by default.
            If you want to disable bf16 data type, you can specify excluded_precisions = [‘bf16’].</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> []</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-tuning_criterion">
<span class="sig-name descname"><span class="pre">tuning_criterion</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-tuning_criterion" title="Link to this definition">#</a></dt>
<dd><p>
            Instance of TuningCriterion class. In this class you can set strategy, strategy_kwargs,
            timeout, max_trials and objective.</p>
<p><strong>type:</strong> dict</p>
<p><strong>default_value:</strong> {‘strategy’: ‘basic’, ‘strategy_kwargs’: None, ‘timeout’: 0, ‘max_trials’: 5, ‘objective’: ‘performance’}</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-metric">
<span class="sig-name descname"><span class="pre">metric</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-metric" title="Link to this definition">#</a></dt>
<dd><p>
            Accuracy metric to generate an evaluation function for Intel® Neural Compressor
            accuracy aware tuning.</p>
<p><strong>type:</strong> olive.evaluator.metric.Metric | None</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-weight_only_config">
<span class="sig-name descname"><span class="pre">weight_only_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-weight_only_config" title="Link to this definition">#</a></dt>
<dd><p>
            INC weight only quantization config.</p>
<p><strong>type:</strong> dict</p>
<p><strong>default_value:</strong> {}</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-op_type_dict">
<span class="sig-name descname"><span class="pre">op_type_dict</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-op_type_dict" title="Link to this definition">#</a></dt>
<dd><p>
            INC weight only quantization config.</p>
<p><strong>type:</strong> dict</p>
<p><strong>default_value:</strong> {}</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-130">
<span class="sig-name descname"><span class="pre">save_as_external_data</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-130" title="Link to this definition">#</a></dt>
<dd><p>Serializes tensor data to separate files instead of directly in the ONNX file. Large models (&gt;2GB) may be forced to save external data regardless of the value of this parameter.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-131">
<span class="sig-name descname"><span class="pre">all_tensors_to_one_file</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-131" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, save all tensors to one external file specified by ‘external_data_name’. If false, save each tensor to a file named with the tensor name.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-132">
<span class="sig-name descname"><span class="pre">external_data_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-132" title="Link to this definition">#</a></dt>
<dd><p>Effective only if all_tensors_to_one_file is True and save_as_external_data is True. If not specified, the external data file will be named with &lt;model_path_name&gt;.data</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-133">
<span class="sig-name descname"><span class="pre">size_threshold</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-133" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. Threshold for size of data. Only when tensor’s data is &gt;= the size_threshold it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1024</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-134">
<span class="sig-name descname"><span class="pre">convert_attribute</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-134" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, convert all tensors to external data If false, convert only non-attribute tensors to external data</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="incstaticquantization">
<span id="inc-static-quantization"></span><h2>IncStaticQuantization<a class="headerlink" href="#incstaticquantization" title="Link to this heading">#</a></h2>
<p>Intel® Neural Compressor Static Quantization Pass.</p>
<p><strong>Input:</strong> handler.onnx.ONNXModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-135">
<span class="sig-name descname"><span class="pre">approach</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-135" title="Link to this definition">#</a></dt>
<dd><p>static quantization mode</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> static</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-136">
<span class="sig-name descname"><span class="pre">device</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-136" title="Link to this definition">#</a></dt>
<dd><p>
            Intel® Neural Compressor quantization device. Support ‘cpu’ and ‘gpu’.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> cpu</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-137">
<span class="sig-name descname"><span class="pre">backend</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-137" title="Link to this definition">#</a></dt>
<dd><p>
            Backend for model execution. Support ‘default’, ‘onnxrt_trt_ep’, ‘onnxrt_cuda_ep’</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> default</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-138">
<span class="sig-name descname"><span class="pre">domain</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-138" title="Link to this definition">#</a></dt>
<dd><p>
            Model domain. Support ‘auto’, ‘cv’, ‘object_detection’, ‘nlp’ and ‘recommendation_system’.
            Intel® Neural Compressor Adaptor will use specific quantization settings for different domains
            automatically, and explicitly specified quantization settings will override the automatic setting.
            If users set domain as auto, automatic detection for domain will be executed.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> auto</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-139">
<span class="sig-name descname"><span class="pre">workspace</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-139" title="Link to this definition">#</a></dt>
<dd><p>Workspace for Intel® Neural Compressor quantization where intermediate files and
            tuning history file are stored.  Default value is:
            “./nc_workspace/{}/”.format(datetime.datetime.now().strftime(“%Y-%m-%d_%H-%M-%S”))</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-140">
<span class="sig-name descname"><span class="pre">recipes</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-140" title="Link to this definition">#</a></dt>
<dd><p>
            Recipes for Intel® Neural Compressor quantization, support list is as below.
                ‘smooth_quant’: whether do smooth quant
                ‘smooth_quant_args’: parameters for smooth_quant
                ‘fast_bias_correction’: whether do fast bias correction
                ‘weight_correction’: whether do weight correction
                ‘gemm_to_matmul’: whether convert gemm to matmul and add, only valid for onnx models
                ‘graph_optimization_level’: support ‘DISABLE_ALL’, ‘ENABLE_BASIC’, ‘ENABLE_EXTENDED’, ‘ENABLE_ALL’
                                        only valid for onnx models
                ‘first_conv_or_matmul_quantization’: whether quantize the first conv or matmul
                ‘last_conv_or_matmul_quantization’: whether quantize the last conv or matmul
                ‘pre_post_process_quantization’: whether quantize the ops in preprocessing and postprocessing
                ‘add_qdq_pair_to_weight’: whether add QDQ pair for weights, only valid for onnxrt_trt_ep
                ‘optypes_to_exclude_output_quant’: don’t quantize output of specified optypes
                ‘dedicated_qdq_pair’: whether dedicate QDQ pair, only valid for onnxrt_trt_ep</p>
<p><strong>type:</strong> dict</p>
<p><strong>default_value:</strong> {}</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-141">
<span class="sig-name descname"><span class="pre">reduce_range</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-141" title="Link to this definition">#</a></dt>
<dd><p>
            Whether use 7 bit to quantization.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> Categorical([True, False])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-142">
<span class="sig-name descname"><span class="pre">quant_level</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-142" title="Link to this definition">#</a></dt>
<dd><p>
            Intel® Neural Compressor allows users to choose different tuning processes by specifying
            the quantization level (quant_level). Currently 3 quant_levels are supported.
            0 is conservative strategy, 1 is basic or user-specified strategy,
            auto (default) is the combination of 0 and 1.
            Please refer to
            <a class="github reference external" href="https://github.com/intel/neural-compressor/blob/master/docs/source/tuning_strategies.md#tuning-process">intel/neural-compressor</a>
            <a class="github reference external" href="https://github.com/intel/neural-compressor/blob/master/docs/source/tuning_strategies.md#tuning-algorithms">intel/neural-compressor</a>
            for more details</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> auto</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-143">
<span class="sig-name descname"><span class="pre">excluded_precisions</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-143" title="Link to this definition">#</a></dt>
<dd><p>
            Precisions to be excluded, Default value is empty list.
            Intel® Neural Compressor enable the mixed precision with
            fp32 + bf16(only when device is ‘gpu’ and backend is ‘onnxrt_cuda_ep’) + int8 by default.
            If you want to disable bf16 data type, you can specify excluded_precisions = [‘bf16’].</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> []</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-144">
<span class="sig-name descname"><span class="pre">tuning_criterion</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-144" title="Link to this definition">#</a></dt>
<dd><p>
            Instance of TuningCriterion class. In this class you can set strategy, strategy_kwargs,
            timeout, max_trials and objective.</p>
<p><strong>type:</strong> dict</p>
<p><strong>default_value:</strong> {‘strategy’: ‘basic’, ‘strategy_kwargs’: None, ‘timeout’: 0, ‘max_trials’: 5, ‘objective’: ‘performance’}</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-145">
<span class="sig-name descname"><span class="pre">metric</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-145" title="Link to this definition">#</a></dt>
<dd><p>
            Accuracy metric to generate an evaluation function for Intel® Neural Compressor
            accuracy aware tuning.</p>
<p><strong>type:</strong> olive.evaluator.metric.Metric | None</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-146">
<span class="sig-name descname"><span class="pre">weight_only_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-146" title="Link to this definition">#</a></dt>
<dd><p>
            INC weight only quantization config.</p>
<p><strong>type:</strong> dict</p>
<p><strong>default_value:</strong> {‘bits’: 4, ‘group_size’: 4, ‘scheme’: ‘asym’, ‘algorithm’: ‘RTN’}</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-147">
<span class="sig-name descname"><span class="pre">op_type_dict</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-147" title="Link to this definition">#</a></dt>
<dd><p>
            INC weight only quantization config.</p>
<p><strong>type:</strong> dict</p>
<p><strong>default_value:</strong> {}</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-148">
<span class="sig-name descname"><span class="pre">data_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-148" title="Link to this definition">#</a></dt>
<dd><p>
            Data config for calibration, required if approach is ‘static’.</p>
<p><strong>type:</strong> olive.data.config.DataConfig | Dict</p>
<p><strong>required:</strong> True</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-149">
<span class="sig-name descname"><span class="pre">quant_format</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-149" title="Link to this definition">#</a></dt>
<dd><p>
            Quantization format. Support ‘QDQ’ and ‘QOperator’.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> QOperator</p>
<p><strong>search_defaults:</strong> Categorical([‘QOperator’, ‘QDQ’])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-calibration_sampling_size">
<span class="sig-name descname"><span class="pre">calibration_sampling_size</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-calibration_sampling_size" title="Link to this definition">#</a></dt>
<dd><p>
            Number of calibration sample.</p>
<p><strong>type:</strong> list | int</p>
<p><strong>default_value:</strong> [100]</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-150">
<span class="sig-name descname"><span class="pre">save_as_external_data</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-150" title="Link to this definition">#</a></dt>
<dd><p>Serializes tensor data to separate files instead of directly in the ONNX file. Large models (&gt;2GB) may be forced to save external data regardless of the value of this parameter.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-151">
<span class="sig-name descname"><span class="pre">all_tensors_to_one_file</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-151" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, save all tensors to one external file specified by ‘external_data_name’. If false, save each tensor to a file named with the tensor name.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-152">
<span class="sig-name descname"><span class="pre">external_data_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-152" title="Link to this definition">#</a></dt>
<dd><p>Effective only if all_tensors_to_one_file is True and save_as_external_data is True. If not specified, the external data file will be named with &lt;model_path_name&gt;.data</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-153">
<span class="sig-name descname"><span class="pre">size_threshold</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-153" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. Threshold for size of data. Only when tensor’s data is &gt;= the size_threshold it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1024</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-154">
<span class="sig-name descname"><span class="pre">convert_attribute</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-154" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, convert all tensors to external data If false, convert only non-attribute tensors to external data</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="incquantization">
<span id="inc-quantization"></span><h2>IncQuantization<a class="headerlink" href="#incquantization" title="Link to this heading">#</a></h2>
<p>Quantize ONNX model with Intel® Neural Compressor.</p>
<p><strong>Input:</strong> handler.onnx.ONNXModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-155">
<span class="sig-name descname"><span class="pre">approach</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-155" title="Link to this definition">#</a></dt>
<dd><p>
                Intel® Neural Compressor Quantization mode. ‘dynamic’ for dynamic quantization,
                ‘static’ for static quantization, “weight_only” for 4-bits weight-only quantization.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> static</p>
<p><strong>search_defaults:</strong> Categorical([‘dynamic’, ‘static’, ‘weight_only’])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-156">
<span class="sig-name descname"><span class="pre">device</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-156" title="Link to this definition">#</a></dt>
<dd><p>
            Intel® Neural Compressor quantization device. Support ‘cpu’ and ‘gpu’.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> cpu</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-157">
<span class="sig-name descname"><span class="pre">backend</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-157" title="Link to this definition">#</a></dt>
<dd><p>
            Backend for model execution. Support ‘default’, ‘onnxrt_trt_ep’, ‘onnxrt_cuda_ep’</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> default</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-158">
<span class="sig-name descname"><span class="pre">domain</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-158" title="Link to this definition">#</a></dt>
<dd><p>
            Model domain. Support ‘auto’, ‘cv’, ‘object_detection’, ‘nlp’ and ‘recommendation_system’.
            Intel® Neural Compressor Adaptor will use specific quantization settings for different domains
            automatically, and explicitly specified quantization settings will override the automatic setting.
            If users set domain as auto, automatic detection for domain will be executed.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> auto</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-159">
<span class="sig-name descname"><span class="pre">workspace</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-159" title="Link to this definition">#</a></dt>
<dd><p>Workspace for Intel® Neural Compressor quantization where intermediate files and
            tuning history file are stored.  Default value is:
            “./nc_workspace/{}/”.format(datetime.datetime.now().strftime(“%Y-%m-%d_%H-%M-%S”))</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-160">
<span class="sig-name descname"><span class="pre">recipes</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-160" title="Link to this definition">#</a></dt>
<dd><p>
            Recipes for Intel® Neural Compressor quantization, support list is as below.
                ‘smooth_quant’: whether do smooth quant
                ‘smooth_quant_args’: parameters for smooth_quant
                ‘fast_bias_correction’: whether do fast bias correction
                ‘weight_correction’: whether do weight correction
                ‘gemm_to_matmul’: whether convert gemm to matmul and add, only valid for onnx models
                ‘graph_optimization_level’: support ‘DISABLE_ALL’, ‘ENABLE_BASIC’, ‘ENABLE_EXTENDED’, ‘ENABLE_ALL’
                                        only valid for onnx models
                ‘first_conv_or_matmul_quantization’: whether quantize the first conv or matmul
                ‘last_conv_or_matmul_quantization’: whether quantize the last conv or matmul
                ‘pre_post_process_quantization’: whether quantize the ops in preprocessing and postprocessing
                ‘add_qdq_pair_to_weight’: whether add QDQ pair for weights, only valid for onnxrt_trt_ep
                ‘optypes_to_exclude_output_quant’: don’t quantize output of specified optypes
                ‘dedicated_qdq_pair’: whether dedicate QDQ pair, only valid for onnxrt_trt_ep</p>
<p><strong>type:</strong> dict</p>
<p><strong>default_value:</strong> {}</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-161">
<span class="sig-name descname"><span class="pre">reduce_range</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-161" title="Link to this definition">#</a></dt>
<dd><p>
            Whether use 7 bit to quantization.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> Categorical([True, False])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-162">
<span class="sig-name descname"><span class="pre">quant_level</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-162" title="Link to this definition">#</a></dt>
<dd><p>
            Intel® Neural Compressor allows users to choose different tuning processes by specifying
            the quantization level (quant_level). Currently 3 quant_levels are supported.
            0 is conservative strategy, 1 is basic or user-specified strategy,
            auto (default) is the combination of 0 and 1.
            Please refer to
            <a class="github reference external" href="https://github.com/intel/neural-compressor/blob/master/docs/source/tuning_strategies.md#tuning-process">intel/neural-compressor</a>
            <a class="github reference external" href="https://github.com/intel/neural-compressor/blob/master/docs/source/tuning_strategies.md#tuning-algorithms">intel/neural-compressor</a>
            for more details</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> auto</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-163">
<span class="sig-name descname"><span class="pre">excluded_precisions</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-163" title="Link to this definition">#</a></dt>
<dd><p>
            Precisions to be excluded, Default value is empty list.
            Intel® Neural Compressor enable the mixed precision with
            fp32 + bf16(only when device is ‘gpu’ and backend is ‘onnxrt_cuda_ep’) + int8 by default.
            If you want to disable bf16 data type, you can specify excluded_precisions = [‘bf16’].</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> []</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-164">
<span class="sig-name descname"><span class="pre">tuning_criterion</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-164" title="Link to this definition">#</a></dt>
<dd><p>
            Instance of TuningCriterion class. In this class you can set strategy, strategy_kwargs,
            timeout, max_trials and objective.</p>
<p><strong>type:</strong> dict</p>
<p><strong>default_value:</strong> {‘strategy’: ‘basic’, ‘strategy_kwargs’: None, ‘timeout’: 0, ‘max_trials’: 5, ‘objective’: ‘performance’}</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-165">
<span class="sig-name descname"><span class="pre">metric</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-165" title="Link to this definition">#</a></dt>
<dd><p>
            Accuracy metric to generate an evaluation function for Intel® Neural Compressor
            accuracy aware tuning.</p>
<p><strong>type:</strong> olive.evaluator.metric.Metric | None</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-166">
<span class="sig-name descname"><span class="pre">weight_only_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-166" title="Link to this definition">#</a></dt>
<dd><p>
            INC weight only quantization config.</p>
<p><strong>type:</strong> dict</p>
<p><strong>default_value:</strong> {‘bits’: 4, ‘group_size’: 4, ‘scheme’: ‘asym’, ‘algorithm’: ‘RTN’}</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-167">
<span class="sig-name descname"><span class="pre">op_type_dict</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-167" title="Link to this definition">#</a></dt>
<dd><p>
            INC weight only quantization config.</p>
<p><strong>type:</strong> dict</p>
<p><strong>default_value:</strong> {}</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-168">
<span class="sig-name descname"><span class="pre">data_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-168" title="Link to this definition">#</a></dt>
<dd><p>
            Data config for calibration, required if approach is ‘static’.</p>
<p><strong>type:</strong> olive.data.config.DataConfig | Dict</p>
<p><strong>required:</strong> True</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-169">
<span class="sig-name descname"><span class="pre">quant_format</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-169" title="Link to this definition">#</a></dt>
<dd><p>
            Quantization format. Support ‘QDQ’ and ‘QOperator’.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> QOperator</p>
<p><strong>search_defaults:</strong> Conditional(parents: (‘approach’,), support: {(‘static’,): Categorical([‘QOperator’, ‘QDQ’])}, default: Categorical([‘default’]))</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-170">
<span class="sig-name descname"><span class="pre">calibration_sampling_size</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-170" title="Link to this definition">#</a></dt>
<dd><p>
            Number of calibration sample.</p>
<p><strong>type:</strong> list | int</p>
<p><strong>default_value:</strong> [100]</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-171">
<span class="sig-name descname"><span class="pre">save_as_external_data</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-171" title="Link to this definition">#</a></dt>
<dd><p>Serializes tensor data to separate files instead of directly in the ONNX file. Large models (&gt;2GB) may be forced to save external data regardless of the value of this parameter.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-172">
<span class="sig-name descname"><span class="pre">all_tensors_to_one_file</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-172" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, save all tensors to one external file specified by ‘external_data_name’. If false, save each tensor to a file named with the tensor name.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-173">
<span class="sig-name descname"><span class="pre">external_data_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-173" title="Link to this definition">#</a></dt>
<dd><p>Effective only if all_tensors_to_one_file is True and save_as_external_data is True. If not specified, the external data file will be named with &lt;model_path_name&gt;.data</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-174">
<span class="sig-name descname"><span class="pre">size_threshold</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-174" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. Threshold for size of data. Only when tensor’s data is &gt;= the size_threshold it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1024</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-175">
<span class="sig-name descname"><span class="pre">convert_attribute</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-175" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, convert all tensors to external data If false, convert only non-attribute tensors to external data</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="vitisaiquantization">
<span id="vitis-ai-quantization"></span><h2>VitisAIQuantization<a class="headerlink" href="#vitisaiquantization" title="Link to this heading">#</a></h2>
<p>Quantize ONNX model with onnxruntime.

    We can search for best parameters for vai_q_onnx quantization at same time.</p>
<p><strong>Input:</strong> handler.onnx.ONNXModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-176">
<span class="sig-name descname"><span class="pre">quant_mode</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-176" title="Link to this definition">#</a></dt>
<dd><p>
                    Onnx Quantization mode.
                    ‘static’ for vitis ai quantization.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> static</p>
<p><strong>search_defaults:</strong> Categorical([‘static’])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-177">
<span class="sig-name descname"><span class="pre">data_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-177" title="Link to this definition">#</a></dt>
<dd><p>Data config for calibration.</p>
<p><strong>type:</strong> olive.data.config.DataConfig | Dict</p>
<p><strong>required:</strong> True</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-178">
<span class="sig-name descname"><span class="pre">weight_type</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-178" title="Link to this definition">#</a></dt>
<dd><p>
            Data type for quantizing weights which is used in vai_q_onnx quantization.
            ‘QInt8’ for signed 8-bit integer,</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> QInt8</p>
<p><strong>search_defaults:</strong> Categorical([‘QInt8’])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-input_nodes">
<span class="sig-name descname"><span class="pre">input_nodes</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-input_nodes" title="Link to this definition">#</a></dt>
<dd><p>
            Start node that needs quantization. If None, all quantizable.</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-output_nodes">
<span class="sig-name descname"><span class="pre">output_nodes</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-output_nodes" title="Link to this definition">#</a></dt>
<dd><p>
            End node that needs quantization. If None, all quantizable.</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-179">
<span class="sig-name descname"><span class="pre">op_types_to_quantize</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-179" title="Link to this definition">#</a></dt>
<dd><p>
            List of operator types to quantize. If None, all quantizable.</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-180">
<span class="sig-name descname"><span class="pre">nodes_to_quantize</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-180" title="Link to this definition">#</a></dt>
<dd><p>
            List of node names to quantize. If None, all quantizable.</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-181">
<span class="sig-name descname"><span class="pre">nodes_to_exclude</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-181" title="Link to this definition">#</a></dt>
<dd><p>
            List of node names to exclude from quantization. If None, all quantizable.</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-182">
<span class="sig-name descname"><span class="pre">per_channel</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-182" title="Link to this definition">#</a></dt>
<dd><p>
            Quantize weights per channel.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> Categorical([True, False])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-optimize_model">
<span class="sig-name descname"><span class="pre">optimize_model</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-optimize_model" title="Link to this definition">#</a></dt>
<dd><p>
            Deprecating Soon in ONNX! Optimize model before quantization. NOT recommended, optimization will
            change the computation graph, making debugging of quantization loss difficult.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> Categorical([True, False])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-use_external_data_format">
<span class="sig-name descname"><span class="pre">use_external_data_format</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-use_external_data_format" title="Link to this definition">#</a></dt>
<dd><p>
            option used for large size (&gt;2GB) model. Set to True by default.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-183">
<span class="sig-name descname"><span class="pre">quant_preprocess</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-183" title="Link to this definition">#</a></dt>
<dd><p>
            Shape inference and model optimization, in preparation for quantization.
            <a class="reference external" href="https://onnxruntime.ai/docs/performance/quantization.html#pre-processing">https://onnxruntime.ai/docs/performance/quantization.html#pre-processing</a></p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> Categorical([True, False])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-184">
<span class="sig-name descname"><span class="pre">calibrate_method</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-184" title="Link to this definition">#</a></dt>
<dd><p>
            Current calibration methods supported are NonOverflow and MinMSE,
            Please use NonOverflow or MinMSE as options.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> MinMSE</p>
<p><strong>search_defaults:</strong> Categorical([‘NonOverflow’, ‘MinMSE’])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-185">
<span class="sig-name descname"><span class="pre">quant_format</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-185" title="Link to this definition">#</a></dt>
<dd><p>
            QDQ format quantize the model by inserting QuantizeLinear/DeQuantizeLinear on the tensor.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> QDQ</p>
<p><strong>search_defaults:</strong> Categorical([‘QDQ’, ‘QOperator’])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-need_layer_fusing">
<span class="sig-name descname"><span class="pre">need_layer_fusing</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-need_layer_fusing" title="Link to this definition">#</a></dt>
<dd><p>
            Perform layer fusion for conv-relu type operations</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> Categorical([True, False])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-186">
<span class="sig-name descname"><span class="pre">activation_type</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-186" title="Link to this definition">#</a></dt>
<dd><p>
            Quantization data type of activation.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> QUInt8</p>
<p><strong>search_defaults:</strong> Conditional(parents: (‘quant_format’, ‘weight_type’), support: {(‘QDQ’, ‘QInt8’): Categorical([‘QInt8’]), (‘QDQ’, ‘QUInt8’): Categorical([‘QUInt8’]), (‘QOperator’, ‘QUInt8’): Categorical([‘QUInt8’]), (‘QOperator’, ‘QInt8’): Categorical([&lt;SpecialParamValue.INVALID: ‘OLIVE_INVALID_PARAM_VALUE’&gt;])}, default: Categorical([&lt;SpecialParamValue.INVALID: ‘OLIVE_INVALID_PARAM_VALUE’&gt;]))</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-enable_dpu">
<span class="sig-name descname"><span class="pre">enable_dpu</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-enable_dpu" title="Link to this definition">#</a></dt>
<dd><p>
            Use QDQ format optimized specifically for DPU.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> Categorical([True, False])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-ActivationSymmetric">
<span class="sig-name descname"><span class="pre">ActivationSymmetric</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-ActivationSymmetric" title="Link to this definition">#</a></dt>
<dd><p>symmetrize calibration data for activations</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-WeightSymmetric">
<span class="sig-name descname"><span class="pre">WeightSymmetric</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-WeightSymmetric" title="Link to this definition">#</a></dt>
<dd><p>symmetrize calibration data for weights</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-AddQDQPairToWeight">
<span class="sig-name descname"><span class="pre">AddQDQPairToWeight</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-AddQDQPairToWeight" title="Link to this definition">#</a></dt>
<dd><p>remains floating-point weight and inserts both QuantizeLinear/DeQuantizeLinear nodes to weight</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-187">
<span class="sig-name descname"><span class="pre">extra_options</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-187" title="Link to this definition">#</a></dt>
<dd><p>
            Key value pair dictionary for <cite>extra_options</cite> in quantization. If an option is one of
            [‘ActivationSymmetric’, ‘WeightSymmetric’, ‘AddQDQPairToWeight’], it will be overwritten by the corresponding config parameter
            value.</p>
<p><strong>type:</strong> dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-188">
<span class="sig-name descname"><span class="pre">save_as_external_data</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-188" title="Link to this definition">#</a></dt>
<dd><p>Serializes tensor data to separate files instead of directly in the ONNX file. Large models (&gt;2GB) may be forced to save external data regardless of the value of this parameter.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-189">
<span class="sig-name descname"><span class="pre">all_tensors_to_one_file</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-189" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, save all tensors to one external file specified by ‘external_data_name’. If false, save each tensor to a file named with the tensor name.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-190">
<span class="sig-name descname"><span class="pre">external_data_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-190" title="Link to this definition">#</a></dt>
<dd><p>Effective only if all_tensors_to_one_file is True and save_as_external_data is True. If not specified, the external data file will be named with &lt;model_path_name&gt;.data</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-191">
<span class="sig-name descname"><span class="pre">size_threshold</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-191" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. Threshold for size of data. Only when tensor’s data is &gt;= the size_threshold it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1024</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-192">
<span class="sig-name descname"><span class="pre">convert_attribute</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-192" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, convert all tensors to external data If false, convert only non-attribute tensors to external data</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="appendprepostprocessingops">
<span id="append-pre-post-processing"></span><h2>AppendPrePostProcessingOps<a class="headerlink" href="#appendprepostprocessingops" title="Link to this heading">#</a></h2>
<p>Add Pre/Post nodes to the input model.</p>
<p><strong>Input:</strong> handler.onnx.ONNXModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-pre">
<span class="sig-name descname"><span class="pre">pre</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-pre" title="Link to this definition">#</a></dt>
<dd><p>List of pre-processing commands to add.</p>
<p><strong>type:</strong> List[Dict[str, Any]]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-post">
<span class="sig-name descname"><span class="pre">post</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-post" title="Link to this definition">#</a></dt>
<dd><p>List of post-processing commands to add.</p>
<p><strong>type:</strong> List[Dict[str, Any]]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-tool_command">
<span class="sig-name descname"><span class="pre">tool_command</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-tool_command" title="Link to this definition">#</a></dt>
<dd><p>Composited tool commands to invoke.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-tool_command_args">
<span class="sig-name descname"><span class="pre">tool_command_args</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-tool_command_args" title="Link to this definition">#</a></dt>
<dd><p>Arguments to pass to tool command or to PrePostProcessor.
                If it is used for PrePostProcessor, the schema would like:
                {
                    “name”: “image”,
                    “data_type”: “uint8”,
                    “shape”: [“num_bytes”],</p>
<p><strong>type:</strong> Dict[str, Any] | List[olive.passes.onnx.append_pre_post_processing_ops.PrePostProcessorInput]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-193">
<span class="sig-name descname"><span class="pre">target_opset</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-193" title="Link to this definition">#</a></dt>
<dd><p>The version of the default (ai.onnx) opset to target.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 16</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-194">
<span class="sig-name descname"><span class="pre">save_as_external_data</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-194" title="Link to this definition">#</a></dt>
<dd><p>Serializes tensor data to separate files instead of directly in the ONNX file. Large models (&gt;2GB) may be forced to save external data regardless of the value of this parameter.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-195">
<span class="sig-name descname"><span class="pre">all_tensors_to_one_file</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-195" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, save all tensors to one external file specified by ‘external_data_name’. If false, save each tensor to a file named with the tensor name.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-196">
<span class="sig-name descname"><span class="pre">external_data_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-196" title="Link to this definition">#</a></dt>
<dd><p>Effective only if all_tensors_to_one_file is True and save_as_external_data is True. If not specified, the external data file will be named with &lt;model_path_name&gt;.data</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-197">
<span class="sig-name descname"><span class="pre">size_threshold</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-197" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. Threshold for size of data. Only when tensor’s data is &gt;= the size_threshold it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1024</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-198">
<span class="sig-name descname"><span class="pre">convert_attribute</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-198" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, convert all tensors to external data If false, convert only non-attribute tensors to external data</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="insertbeamsearch">
<span id="insert-beam-search"></span><h2>InsertBeamSearch<a class="headerlink" href="#insertbeamsearch" title="Link to this heading">#</a></h2>
<p>Insert Beam Search Op. Only used for whisper models.

    Uses WhisperBeamSearch contrib op if ORT version &gt;= 1.17.1, else uses BeamSearch contrib op.</p>
<p><strong>Input:</strong> handler.base.OliveModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-no_repeat_ngram_size">
<span class="sig-name descname"><span class="pre">no_repeat_ngram_size</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-no_repeat_ngram_size" title="Link to this definition">#</a></dt>
<dd><blockquote>
<div><p>If set to int &gt; 0, all ngrams of that size can only occur once.</p>
</div></blockquote>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 0</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-use_vocab_mask">
<span class="sig-name descname"><span class="pre">use_vocab_mask</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-use_vocab_mask" title="Link to this definition">#</a></dt>
<dd><p>Use vocab_mask as an extra graph input to the beam search op. Only supported in ORT &gt;= 1.16.0</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-use_prefix_vocab_mask">
<span class="sig-name descname"><span class="pre">use_prefix_vocab_mask</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-use_prefix_vocab_mask" title="Link to this definition">#</a></dt>
<dd><p>Use prefix_vocab_mask as an extra graph input to the beam search op. Only supported in ORT &gt;= 1.16.0</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-use_forced_decoder_ids">
<span class="sig-name descname"><span class="pre">use_forced_decoder_ids</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-use_forced_decoder_ids" title="Link to this definition">#</a></dt>
<dd><p>Use decoder_input_ids as an extra graph input to the beam search op. Only supported in ORT &gt;= 1.16.0</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-use_logits_processor">
<span class="sig-name descname"><span class="pre">use_logits_processor</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-use_logits_processor" title="Link to this definition">#</a></dt>
<dd><p>Use logits_processor as an extra graph input to the beam search op. Only supported in ORT &gt;= 1.16.0</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-use_temperature">
<span class="sig-name descname"><span class="pre">use_temperature</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-use_temperature" title="Link to this definition">#</a></dt>
<dd><p>Use temperature as an extra graph input to the beam search op. Only supported in ORT &gt;= 1.17.1</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-fp16">
<span class="sig-name descname"><span class="pre">fp16</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-fp16" title="Link to this definition">#</a></dt>
<dd><p>Is the model in fp16 precision.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-199">
<span class="sig-name descname"><span class="pre">use_gpu</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-199" title="Link to this definition">#</a></dt>
<dd><p>Use GPU for beam search op.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-200">
<span class="sig-name descname"><span class="pre">save_as_external_data</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-200" title="Link to this definition">#</a></dt>
<dd><p>Serializes tensor data to separate files instead of directly in the ONNX file. Large models (&gt;2GB) may be forced to save external data regardless of the value of this parameter.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-201">
<span class="sig-name descname"><span class="pre">all_tensors_to_one_file</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-201" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, save all tensors to one external file specified by ‘external_data_name’. If false, save each tensor to a file named with the tensor name.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-202">
<span class="sig-name descname"><span class="pre">external_data_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-202" title="Link to this definition">#</a></dt>
<dd><p>Effective only if all_tensors_to_one_file is True and save_as_external_data is True. If not specified, the external data file will be named with &lt;model_path_name&gt;.data</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-203">
<span class="sig-name descname"><span class="pre">size_threshold</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-203" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. Threshold for size of data. Only when tensor’s data is &gt;= the size_threshold it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1024</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-204">
<span class="sig-name descname"><span class="pre">convert_attribute</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-204" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, convert all tensors to external data If false, convert only non-attribute tensors to external data</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="extractadapters">
<span id="extract-adapters"></span><h2>ExtractAdapters<a class="headerlink" href="#extractadapters" title="Link to this heading">#</a></h2>
<p>Extract adapter weights from ONNX model and save them as external weights file.

    If make_inputs is False, model proto is invalid after this pass as the adapter weights point to non-existent
    external files. Inference session must be created by first loading the adapter weights using
    SessionOptions.add_external_initializers.

    If make_inputs is True, the adapter weights are inputs to the model and must be provided during inference.</p>
<p><strong>Input:</strong> handler.onnx.ONNXModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-make_inputs">
<span class="sig-name descname"><span class="pre">make_inputs</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-make_inputs" title="Link to this definition">#</a></dt>
<dd><p>Convert adapter weights to inputs. If false, the adapter weights will be set as initializers with external data.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-dynamic_lora_r">
<span class="sig-name descname"><span class="pre">dynamic_lora_r</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-dynamic_lora_r" title="Link to this definition">#</a></dt>
<dd><p>Whether the model uses dynamic shape for lora_r. Only used if make_inputs is True. Valid only for float modules.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-optional_inputs">
<span class="sig-name descname"><span class="pre">optional_inputs</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-optional_inputs" title="Link to this definition">#</a></dt>
<dd><p>Create default initializers (empty tensor with lora_r dimension set to 0) for the adapter weights, if inputs not provided during inference. Only used if make_inputs is True. Valid only for float modules.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-save_format">
<span class="sig-name descname"><span class="pre">save_format</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-save_format" title="Link to this definition">#</a></dt>
<dd><p>Format to save the weights in.</p>
<p><strong>type:</strong> olive.common.utils.WeightsFileFormat</p>
<p><strong>default_value:</strong> onnx_adapter</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-205">
<span class="sig-name descname"><span class="pre">save_as_external_data</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-205" title="Link to this definition">#</a></dt>
<dd><p>Serializes tensor data to separate files instead of directly in the ONNX file. Large models (&gt;2GB) may be forced to save external data regardless of the value of this parameter.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-206">
<span class="sig-name descname"><span class="pre">all_tensors_to_one_file</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-206" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, save all tensors to one external file specified by ‘external_data_name’. If false, save each tensor to a file named with the tensor name.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-207">
<span class="sig-name descname"><span class="pre">external_data_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-207" title="Link to this definition">#</a></dt>
<dd><p>Effective only if all_tensors_to_one_file is True and save_as_external_data is True. If not specified, the external data file will be named with &lt;model_path_name&gt;.data</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-208">
<span class="sig-name descname"><span class="pre">size_threshold</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-208" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. Threshold for size of data. Only when tensor’s data is &gt;= the size_threshold it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1024</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-209">
<span class="sig-name descname"><span class="pre">convert_attribute</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-209" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, convert all tensors to external data If false, convert only non-attribute tensors to external data</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="splitmodel">
<span id="split-model"></span><h2>SplitModel<a class="headerlink" href="#splitmodel" title="Link to this heading">#</a></h2>
<p>Split an ONNX model into multiple smaller sub-models based on predefined assignments.</p>
<p><strong>Input:</strong> handler.onnx.ONNXModelHandler</p>
<p><strong>Output:</strong> handler.composite.CompositeModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-split_assignments">
<span class="sig-name descname"><span class="pre">split_assignments</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-split_assignments" title="Link to this definition">#</a></dt>
<dd><p>Set split assignments in the format of name1=0;name2=1 etc. Overwrite the one from CaptureSplitInfo pass.</p>
<p><strong>type:</strong> Dict[str, int] | str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-210">
<span class="sig-name descname"><span class="pre">save_as_external_data</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-210" title="Link to this definition">#</a></dt>
<dd><p>Serializes tensor data to separate files instead of directly in the ONNX file. Large models (&gt;2GB) may be forced to save external data regardless of the value of this parameter.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-211">
<span class="sig-name descname"><span class="pre">all_tensors_to_one_file</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-211" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, save all tensors to one external file specified by ‘external_data_name’. If false, save each tensor to a file named with the tensor name.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-212">
<span class="sig-name descname"><span class="pre">external_data_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-212" title="Link to this definition">#</a></dt>
<dd><p>Effective only if all_tensors_to_one_file is True and save_as_external_data is True. If not specified, the external data file will be named with &lt;model_path_name&gt;.data</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-213">
<span class="sig-name descname"><span class="pre">size_threshold</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-213" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. Threshold for size of data. Only when tensor’s data is &gt;= the size_threshold it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1024</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-214">
<span class="sig-name descname"><span class="pre">convert_attribute</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-214" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, convert all tensors to external data If false, convert only non-attribute tensors to external data</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="staticllm">
<span id="static-llm"></span><h2>StaticLLM<a class="headerlink" href="#staticllm" title="Link to this heading">#</a></h2>
<p>Convert a dynamic shaped LLM into a static shaped LLM.

    Expects a CompositeModelHandler with at least 3 components: embeddings, transformer layers, and lm_head.
    transformer layers can be split into multiple components. Each transformer layers component produces two
    new components:
        - context model (sequence length = context_length)
        - iterator model (sequence length = 1)
    embeddings and lm_head keep their original shapes.
    The output model has an attribute “llm_pipeline” that contains the mapping of the components with keys:
        - embeddings: name of the embeddings model
        - context: list of context model names
        - iterator: list of iterator model names
        - lm_head: name of the lm_head model</p>
<p><strong>Input:</strong> handler.composite.CompositeModelHandler</p>
<p><strong>Output:</strong> handler.composite.CompositeModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-batch_size">
<span class="sig-name descname"><span class="pre">batch_size</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-batch_size" title="Link to this definition">#</a></dt>
<dd><p>Batch size of the model.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-context_length">
<span class="sig-name descname"><span class="pre">context_length</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-context_length" title="Link to this definition">#</a></dt>
<dd><p>Input length of the context model.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 64</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="epcontextbinarygenerator">
<span id="ep-context-binary-generator"></span><h2>EPContextBinaryGenerator<a class="headerlink" href="#epcontextbinarygenerator" title="Link to this heading">#</a></h2>
<p>Generate EP specific context binary for the model.</p>
<p><strong>Input:</strong> handler.onnx.ONNXModelHandler | handler.composite.CompositeModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler | handler.composite.CompositeModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-embed_context">
<span class="sig-name descname"><span class="pre">embed_context</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-embed_context" title="Link to this definition">#</a></dt>
<dd><p>Whether to embed context bin into the model.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-weight_sharing">
<span class="sig-name descname"><span class="pre">weight_sharing</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-weight_sharing" title="Link to this definition">#</a></dt>
<dd><p>Whether to enable weight sharing between the component models. Only applicable to composite models.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-provider_options">
<span class="sig-name descname"><span class="pre">provider_options</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-provider_options" title="Link to this definition">#</a></dt>
<dd><p>Provider options for the EP.</p>
<p><strong>type:</strong> dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-session_options">
<span class="sig-name descname"><span class="pre">session_options</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-session_options" title="Link to this definition">#</a></dt>
<dd><p>Session options for the EP.</p>
<p><strong>type:</strong> dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-disable_cpu_fallback">
<span class="sig-name descname"><span class="pre">disable_cpu_fallback</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-disable_cpu_fallback" title="Link to this definition">#</a></dt>
<dd><p>Whether to disable CPU fallback.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="composeonnxmodels">
<span id="compose-onnx-models"></span><h2>ComposeOnnxModels<a class="headerlink" href="#composeonnxmodels" title="Link to this heading">#</a></h2>
<p>Compose multiple ONNX models into a single model.

    This pass chains multiple ONNX models together by itertively connecting the output of the preceding model to the
    input of the next model. The final inputs and outputs are the set of all inputs and outputs of the models excluding
    those used to connect the models together.

    It also handles llm_pipeline models:
    - embeddings: the embeddings model is saved as is
    - context: the context model is composed of all models in the context group
    - iterator: the iterator model is composed of all models in the iterator group
    - lm_head: the lm_head model is saved as is</p>
<p><strong>Input:</strong> handler.composite.CompositeModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler | handler.composite.CompositeModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-215">
<span class="sig-name descname"><span class="pre">save_as_external_data</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-215" title="Link to this definition">#</a></dt>
<dd><p>Serializes tensor data to separate files instead of directly in the ONNX file. Large models (&gt;2GB) may be forced to save external data regardless of the value of this parameter.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-216">
<span class="sig-name descname"><span class="pre">all_tensors_to_one_file</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-216" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, save all tensors to one external file specified by ‘external_data_name’. If false, save each tensor to a file named with the tensor name.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-217">
<span class="sig-name descname"><span class="pre">external_data_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-217" title="Link to this definition">#</a></dt>
<dd><p>Effective only if all_tensors_to_one_file is True and save_as_external_data is True. If not specified, the external data file will be named with &lt;model_path_name&gt;.data</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-218">
<span class="sig-name descname"><span class="pre">size_threshold</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-218" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. Threshold for size of data. Only when tensor’s data is &gt;= the size_threshold it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1024</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-219">
<span class="sig-name descname"><span class="pre">convert_attribute</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-219" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, convert all tensors to external data If false, convert only non-attribute tensors to external data</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="optimumconversion">
<span id="optimum-conversion"></span><h2>OptimumConversion<a class="headerlink" href="#optimumconversion" title="Link to this heading">#</a></h2>
<p>Convert a Hugging Face PyTorch model to ONNX model using the Optimum export function.</p>
<p><strong>Input:</strong> handler.hf.HfModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler | handler.composite.CompositeModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-220">
<span class="sig-name descname"><span class="pre">user_script</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-220" title="Link to this definition">#</a></dt>
<dd><p>Path to user script. The values for other parameters which were assigned function or object names will be imported from this script.</p>
<p><strong>type:</strong> pathlib.Path | str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-221">
<span class="sig-name descname"><span class="pre">script_dir</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-221" title="Link to this definition">#</a></dt>
<dd><p>Directory containing user script dependencies.</p>
<p><strong>type:</strong> pathlib.Path | str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-222">
<span class="sig-name descname"><span class="pre">target_opset</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-222" title="Link to this definition">#</a></dt>
<dd><p>The version of the default (ai.onnx) opset to target.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 14</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-components">
<span class="sig-name descname"><span class="pre">components</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-components" title="Link to this definition">#</a></dt>
<dd><p>List of component models to export. E.g. [‘decoder_model’, ‘decoder_with_past_model’]. None means export all components.</p>
<p><strong>type:</strong> List[str]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-223">
<span class="sig-name descname"><span class="pre">fp16</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-223" title="Link to this definition">#</a></dt>
<dd><p>Whether to use fp16 precision to load torch model and then convert it to onnx.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-224">
<span class="sig-name descname"><span class="pre">device</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-224" title="Link to this definition">#</a></dt>
<dd><p>The device to use to do the export. Defaults to ‘cpu’.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> cpu</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-extra_args">
<span class="sig-name descname"><span class="pre">extra_args</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-extra_args" title="Link to this definition">#</a></dt>
<dd><p>Extra arguments to pass to the <cite>optimum.exporters.onnx.main_export</cite> function.</p>
<p><strong>type:</strong> dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="optimummerging">
<span id="optimum-merging"></span><h2>OptimumMerging<a class="headerlink" href="#optimummerging" title="Link to this heading">#</a></h2>
<p>Merges a decoder_model with its decoder_with_past_model via the Optimum library.</p>
<p><strong>Input:</strong> handler.composite.CompositeModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-strict">
<span class="sig-name descname"><span class="pre">strict</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-strict" title="Link to this definition">#</a></dt>
<dd><p>When set, the decoder and decoder_with_past are expected to have strictly the same number of outputs. When False, the decoder is allowed to have more outputs that decoder_with_past, in which case constant outputs are added to match the number of outputs.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-225">
<span class="sig-name descname"><span class="pre">save_as_external_data</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-225" title="Link to this definition">#</a></dt>
<dd><p>Serializes tensor data to separate files instead of directly in the ONNX file. Large models (&gt;2GB) may be forced to save external data regardless of the value of this parameter.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-226">
<span class="sig-name descname"><span class="pre">all_tensors_to_one_file</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-226" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, save all tensors to one external file specified by ‘external_data_name’. If false, save each tensor to a file named with the tensor name.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-227">
<span class="sig-name descname"><span class="pre">external_data_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-227" title="Link to this definition">#</a></dt>
<dd><p>Effective only if all_tensors_to_one_file is True and save_as_external_data is True. If not specified, the external data file will be named with &lt;model_path_name&gt;.data</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-228">
<span class="sig-name descname"><span class="pre">size_threshold</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-228" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. Threshold for size of data. Only when tensor’s data is &gt;= the size_threshold it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1024</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-229">
<span class="sig-name descname"><span class="pre">convert_attribute</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-229" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, convert all tensors to external data If false, convert only non-attribute tensors to external data</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="modelbuilder">
<span id="model-builder"></span><h2>ModelBuilder<a class="headerlink" href="#modelbuilder" title="Link to this heading">#</a></h2>
<p>Converts a Huggingface generative PyTorch model to ONNX model using the Generative AI builder.

    See <a class="github reference external" href="https://github.com/microsoft/onnxruntime-genai">microsoft/onnxruntime-genai</a></p>
<p><strong>Input:</strong> handler.hf.HfModelHandler | handler.onnx.ONNXModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-precision">
<span class="sig-name descname"><span class="pre">precision</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-precision" title="Link to this definition">#</a></dt>
<dd><p>Precision of model.</p>
<p><strong>type:</strong> olive.passes.onnx.model_builder.ModelBuilder.Precision</p>
<p><strong>required:</strong> True</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-metadata_only">
<span class="sig-name descname"><span class="pre">metadata_only</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-metadata_only" title="Link to this definition">#</a></dt>
<dd><p>Whether to export the model or generate required metadata only.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-search">
<span class="sig-name descname"><span class="pre">search</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-search" title="Link to this definition">#</a></dt>
<dd><p>Search options to use for generate loop.</p>
<p><strong>type:</strong> Dict[str, Any]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-use_qdq">
<span class="sig-name descname"><span class="pre">use_qdq</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-use_qdq" title="Link to this definition">#</a></dt>
<dd><p>Use this option when you want to use quantize-dequantize ops. For example, you will have a quantized MatMul op instead of the MatMulNBits op.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-int4_block_size">
<span class="sig-name descname"><span class="pre">int4_block_size</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-int4_block_size" title="Link to this definition">#</a></dt>
<dd><p>Specify the block_size for int4 quantization. Acceptable values: 16/32/64/128/256.</p>
<p><strong>type:</strong> olive.passes.onnx.model_builder.ModelBuilder.BlockSize</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-int4_accuracy_level">
<span class="sig-name descname"><span class="pre">int4_accuracy_level</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-int4_accuracy_level" title="Link to this definition">#</a></dt>
<dd><p>Specify the minimum accuracy level for activation of MatMul in int4 quantization.</p>
<p><strong>type:</strong> olive.passes.onnx.model_builder.ModelBuilder.AccuracyLevel</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-int4_op_types_to_quantize">
<span class="sig-name descname"><span class="pre">int4_op_types_to_quantize</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-int4_op_types_to_quantize" title="Link to this definition">#</a></dt>
<dd><p>Specify the op types to quantize for int4 quantization. Default is None (= [ “MatMul” ]). Example: [“MatMul”, “Gemm”]</p>
<p><strong>type:</strong> List[str]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-exclude_embeds">
<span class="sig-name descname"><span class="pre">exclude_embeds</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-exclude_embeds" title="Link to this definition">#</a></dt>
<dd><p>Remove embedding layer from your ONNX model.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-exclude_lm_head">
<span class="sig-name descname"><span class="pre">exclude_lm_head</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-exclude_lm_head" title="Link to this definition">#</a></dt>
<dd><p>Remove language modeling head from your ONNX model.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-230">
<span class="sig-name descname"><span class="pre">enable_cuda_graph</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-230" title="Link to this definition">#</a></dt>
<dd><p>The model can use CUDA graph capture for CUDA execution provider. If enabled, all nodes being placed on the CUDA EP is the prerequisite for the CUDA graph to be used correctly.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
</section>
<section id="pytorch">
<h1>Pytorch<a class="headerlink" href="#pytorch" title="Link to this heading">#</a></h1>
<section id="capturesplitinfo">
<span id="capture-split-info"></span><h2>CaptureSplitInfo<a class="headerlink" href="#capturesplitinfo" title="Link to this heading">#</a></h2>
<p>Capture the split information of the model layers. Only splits the transformer layers.</p>
<p><strong>Input:</strong> handler.hf.HfModelHandler | handler.pytorch.PyTorchModelHandler</p>
<p><strong>Output:</strong> handler.hf.HfModelHandler | handler.pytorch.PyTorchModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-num_splits">
<span class="sig-name descname"><span class="pre">num_splits</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-num_splits" title="Link to this definition">#</a></dt>
<dd><p>Number of splits to divide the model layers into.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-block_to_split">
<span class="sig-name descname"><span class="pre">block_to_split</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-block_to_split" title="Link to this definition">#</a></dt>
<dd><p>Names of the model blocks to split. Children of the block will be divided into the splits. For supported transformers models, the default value is the transformers layer block name.</p>
<p><strong>type:</strong> str | List[str]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-cost_model">
<span class="sig-name descname"><span class="pre">cost_model</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-cost_model" title="Link to this definition">#</a></dt>
<dd><p>Path to the cost model csv file. One of num_splits or cost_model is required. Must be a csv with headers <cite>module,num_params,num_bytes,num_flops</cite> where each row corresponds to the name or a module (with no children), the number of parameters, the number of bytes, and the number of FLOPs(batch_size=1, seqlen=1) the module uses when in the desired precision.</p>
<p><strong>type:</strong> str | pathlib.Path</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-unique_embeds_lm_head_splits">
<span class="sig-name descname"><span class="pre">unique_embeds_lm_head_splits</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-unique_embeds_lm_head_splits" title="Link to this definition">#</a></dt>
<dd><p>Assign embeddings and lm_head layers to their own splits.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="lora">
<span id="id1"></span><h2>LoRA<a class="headerlink" href="#lora" title="Link to this heading">#</a></h2>
<p>Run LoRA fine-tuning on a Hugging Face PyTorch model.</p>
<p><strong>Input:</strong> handler.hf.HfModelHandler</p>
<p><strong>Output:</strong> handler.hf.HfModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-r">
<span class="sig-name descname"><span class="pre">r</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-r" title="Link to this definition">#</a></dt>
<dd><p>R dimension.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 64</p>
<p><strong>search_defaults:</strong> Categorical([16, 32, 64])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-alpha">
<span class="sig-name descname"><span class="pre">alpha</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-alpha" title="Link to this definition">#</a></dt>
<dd><p>The alpha parameter for scaling.</p>
<p><strong>type:</strong> float</p>
<p><strong>default_value:</strong> 16</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-lora_dropout">
<span class="sig-name descname"><span class="pre">lora_dropout</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-lora_dropout" title="Link to this definition">#</a></dt>
<dd><p>The dropout probability for Lora layers.</p>
<p><strong>type:</strong> float</p>
<p><strong>default_value:</strong> 0.05</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-target_modules">
<span class="sig-name descname"><span class="pre">target_modules</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-target_modules" title="Link to this definition">#</a></dt>
<dd><p>Target modules</p>
<p><strong>type:</strong> List[str]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-modules_to_save">
<span class="sig-name descname"><span class="pre">modules_to_save</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-modules_to_save" title="Link to this definition">#</a></dt>
<dd><p>List of modules apart from LoRA layers to be set as trainable and saved in the final checkpoint.</p>
<p><strong>type:</strong> None</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-231">
<span class="sig-name descname"><span class="pre">torch_dtype</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-231" title="Link to this definition">#</a></dt>
<dd><p>Data type to use for training. Should be one of <cite>bfloat16</cite>, <cite>float16</cite> or <cite>float32</cite>. If <cite>float16</cite> will use fp16 mixed-precision training.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> bfloat16</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-device_map">
<span class="sig-name descname"><span class="pre">device_map</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-device_map" title="Link to this definition">#</a></dt>
<dd><p>Device map to use to load the model.</p>
<p><strong>type:</strong> olive.passes.pytorch.lora.DeviceMap | None</p>
<p><strong>default_value:</strong> auto</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-allow_tf32">
<span class="sig-name descname"><span class="pre">allow_tf32</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-allow_tf32" title="Link to this definition">#</a></dt>
<dd><p>Whether or not to allow TF32 on Ampere GPUs. Can be used to speed up training. For more information, see ‘<a class="reference external" href="https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices">https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices</a>’</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-ephemeral_gpu_offload">
<span class="sig-name descname"><span class="pre">ephemeral_gpu_offload</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-ephemeral_gpu_offload" title="Link to this definition">#</a></dt>
<dd><p>Ephemeral GPU offload</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-train_data_config">
<span class="sig-name descname"><span class="pre">train_data_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-train_data_config" title="Link to this definition">#</a></dt>
<dd><p>Data config for fine-tuning training.</p>
<p><strong>type:</strong> olive.data.config.DataConfig | Dict</p>
<p><strong>required:</strong> True</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-eval_data_config">
<span class="sig-name descname"><span class="pre">eval_data_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-eval_data_config" title="Link to this definition">#</a></dt>
<dd><p>Data config for fine-tuning evaluation. Optional if evaluation is not needed.</p>
<p><strong>type:</strong> olive.data.config.DataConfig | Dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-training_args">
<span class="sig-name descname"><span class="pre">training_args</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-training_args" title="Link to this definition">#</a></dt>
<dd><p>Training arguments. If None, will use default arguments. See HFTrainingArguments for more details.</p>
<p><strong>type:</strong> olive.passes.pytorch.lora.HFTrainingArguments | Dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="loha">
<span id="id2"></span><h2>LoHa<a class="headerlink" href="#loha" title="Link to this heading">#</a></h2>
<p>Run LoHa fine-tuning on a Hugging Face PyTorch model.</p>
<p><strong>Input:</strong> handler.hf.HfModelHandler</p>
<p><strong>Output:</strong> handler.hf.HfModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-rank_dropout">
<span class="sig-name descname"><span class="pre">rank_dropout</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-rank_dropout" title="Link to this definition">#</a></dt>
<dd><p>The dropout probability for rank dimension during training.</p>
<p><strong>type:</strong> float</p>
<p><strong>default_value:</strong> 0.0</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-module_dropout">
<span class="sig-name descname"><span class="pre">module_dropout</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-module_dropout" title="Link to this definition">#</a></dt>
<dd><p>The dropout probability for disabling modules during training.</p>
<p><strong>type:</strong> float</p>
<p><strong>default_value:</strong> 0.0</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-use_effective_conv2d">
<span class="sig-name descname"><span class="pre">use_effective_conv2d</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-use_effective_conv2d" title="Link to this definition">#</a></dt>
<dd><p>Use parameter effective decomposition for Conv2d with ksize &gt; 1.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-exclude_modules">
<span class="sig-name descname"><span class="pre">exclude_modules</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-exclude_modules" title="Link to this definition">#</a></dt>
<dd><p>Modules to exclude from tuning.</p>
<p><strong>type:</strong> List[str] | str | None</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-init_weights">
<span class="sig-name descname"><span class="pre">init_weights</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-init_weights" title="Link to this definition">#</a></dt>
<dd><p>Whether to perform initialization of adapter weights.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-layers_to_transform">
<span class="sig-name descname"><span class="pre">layers_to_transform</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-layers_to_transform" title="Link to this definition">#</a></dt>
<dd><p>The layer indices to transform.</p>
<p><strong>type:</strong> List[int]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-layers_pattern">
<span class="sig-name descname"><span class="pre">layers_pattern</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-layers_pattern" title="Link to this definition">#</a></dt>
<dd><p>The layer pattern name, used only if layers_to_transform is different from None.</p>
<p><strong>type:</strong> List[str]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-rank_pattern">
<span class="sig-name descname"><span class="pre">rank_pattern</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-rank_pattern" title="Link to this definition">#</a></dt>
<dd><p>The mapping from layer names or regexp expression to ranks which are different from the default rank specified by r.</p>
<p><strong>type:</strong> Dict</p>
<p><strong>default_value:</strong> {}</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-alpha_pattern">
<span class="sig-name descname"><span class="pre">alpha_pattern</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-alpha_pattern" title="Link to this definition">#</a></dt>
<dd><p>The mapping from layer names or regexp expression to alphas which are different from the default alpha specified by alpha.</p>
<p><strong>type:</strong> Dict</p>
<p><strong>default_value:</strong> {}</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-232">
<span class="sig-name descname"><span class="pre">r</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-232" title="Link to this definition">#</a></dt>
<dd><p>R dimension.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 64</p>
<p><strong>search_defaults:</strong> Categorical([16, 32, 64])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-233">
<span class="sig-name descname"><span class="pre">alpha</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-233" title="Link to this definition">#</a></dt>
<dd><p>The alpha parameter for scaling.</p>
<p><strong>type:</strong> float</p>
<p><strong>default_value:</strong> 16</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-234">
<span class="sig-name descname"><span class="pre">lora_dropout</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-234" title="Link to this definition">#</a></dt>
<dd><p>The dropout probability for Lora layers.</p>
<p><strong>type:</strong> float</p>
<p><strong>default_value:</strong> 0.05</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-235">
<span class="sig-name descname"><span class="pre">target_modules</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-235" title="Link to this definition">#</a></dt>
<dd><p>Target modules</p>
<p><strong>type:</strong> List[str]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-236">
<span class="sig-name descname"><span class="pre">modules_to_save</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-236" title="Link to this definition">#</a></dt>
<dd><p>List of modules apart from LoRA layers to be set as trainable and saved in the final checkpoint.</p>
<p><strong>type:</strong> None</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-237">
<span class="sig-name descname"><span class="pre">torch_dtype</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-237" title="Link to this definition">#</a></dt>
<dd><p>Data type to use for training. Should be one of <cite>bfloat16</cite>, <cite>float16</cite> or <cite>float32</cite>. If <cite>float16</cite> will use fp16 mixed-precision training.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> bfloat16</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-238">
<span class="sig-name descname"><span class="pre">device_map</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-238" title="Link to this definition">#</a></dt>
<dd><p>Device map to use to load the model.</p>
<p><strong>type:</strong> olive.passes.pytorch.lora.DeviceMap | None</p>
<p><strong>default_value:</strong> auto</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-239">
<span class="sig-name descname"><span class="pre">allow_tf32</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-239" title="Link to this definition">#</a></dt>
<dd><p>Whether or not to allow TF32 on Ampere GPUs. Can be used to speed up training. For more information, see ‘<a class="reference external" href="https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices">https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices</a>’</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-240">
<span class="sig-name descname"><span class="pre">ephemeral_gpu_offload</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-240" title="Link to this definition">#</a></dt>
<dd><p>Ephemeral GPU offload</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-241">
<span class="sig-name descname"><span class="pre">train_data_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-241" title="Link to this definition">#</a></dt>
<dd><p>Data config for fine-tuning training.</p>
<p><strong>type:</strong> olive.data.config.DataConfig | Dict</p>
<p><strong>required:</strong> True</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-242">
<span class="sig-name descname"><span class="pre">eval_data_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-242" title="Link to this definition">#</a></dt>
<dd><p>Data config for fine-tuning evaluation. Optional if evaluation is not needed.</p>
<p><strong>type:</strong> olive.data.config.DataConfig | Dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-243">
<span class="sig-name descname"><span class="pre">training_args</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-243" title="Link to this definition">#</a></dt>
<dd><p>Training arguments. If None, will use default arguments. See HFTrainingArguments for more details.</p>
<p><strong>type:</strong> olive.passes.pytorch.lora.HFTrainingArguments | Dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="lokr">
<span id="id3"></span><h2>LoKr<a class="headerlink" href="#lokr" title="Link to this heading">#</a></h2>
<p>Run LoKr fine-tuning on a Hugging Face PyTorch model.</p>
<p><strong>Input:</strong> handler.hf.HfModelHandler</p>
<p><strong>Output:</strong> handler.hf.HfModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-decompose_both">
<span class="sig-name descname"><span class="pre">decompose_both</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-decompose_both" title="Link to this definition">#</a></dt>
<dd><p>Perform rank decomposition of left kronecker product matrix.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-decompose_factor">
<span class="sig-name descname"><span class="pre">decompose_factor</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-decompose_factor" title="Link to this definition">#</a></dt>
<dd><p>Kronecker product decomposition factor.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> -1</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-rank_dropout_scale">
<span class="sig-name descname"><span class="pre">rank_dropout_scale</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-rank_dropout_scale" title="Link to this definition">#</a></dt>
<dd><p>Whether to scale the rank dropout while training.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-244">
<span class="sig-name descname"><span class="pre">rank_dropout</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-244" title="Link to this definition">#</a></dt>
<dd><p>The dropout probability for rank dimension during training.</p>
<p><strong>type:</strong> float</p>
<p><strong>default_value:</strong> 0.0</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-245">
<span class="sig-name descname"><span class="pre">module_dropout</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-245" title="Link to this definition">#</a></dt>
<dd><p>The dropout probability for disabling modules during training.</p>
<p><strong>type:</strong> float</p>
<p><strong>default_value:</strong> 0.0</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-246">
<span class="sig-name descname"><span class="pre">use_effective_conv2d</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-246" title="Link to this definition">#</a></dt>
<dd><p>Use parameter effective decomposition for Conv2d with ksize &gt; 1.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-247">
<span class="sig-name descname"><span class="pre">exclude_modules</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-247" title="Link to this definition">#</a></dt>
<dd><p>Modules to exclude from tuning.</p>
<p><strong>type:</strong> List[str] | str | None</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-248">
<span class="sig-name descname"><span class="pre">init_weights</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-248" title="Link to this definition">#</a></dt>
<dd><p>Whether to perform initialization of adapter weights.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-249">
<span class="sig-name descname"><span class="pre">layers_to_transform</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-249" title="Link to this definition">#</a></dt>
<dd><p>The layer indices to transform.</p>
<p><strong>type:</strong> List[int]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-250">
<span class="sig-name descname"><span class="pre">layers_pattern</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-250" title="Link to this definition">#</a></dt>
<dd><p>The layer pattern name, used only if layers_to_transform is different from None.</p>
<p><strong>type:</strong> List[str]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-251">
<span class="sig-name descname"><span class="pre">rank_pattern</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-251" title="Link to this definition">#</a></dt>
<dd><p>The mapping from layer names or regexp expression to ranks which are different from the default rank specified by r.</p>
<p><strong>type:</strong> Dict</p>
<p><strong>default_value:</strong> {}</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-252">
<span class="sig-name descname"><span class="pre">alpha_pattern</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-252" title="Link to this definition">#</a></dt>
<dd><p>The mapping from layer names or regexp expression to alphas which are different from the default alpha specified by alpha.</p>
<p><strong>type:</strong> Dict</p>
<p><strong>default_value:</strong> {}</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-253">
<span class="sig-name descname"><span class="pre">r</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-253" title="Link to this definition">#</a></dt>
<dd><p>R dimension.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 64</p>
<p><strong>search_defaults:</strong> Categorical([16, 32, 64])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-254">
<span class="sig-name descname"><span class="pre">alpha</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-254" title="Link to this definition">#</a></dt>
<dd><p>The alpha parameter for scaling.</p>
<p><strong>type:</strong> float</p>
<p><strong>default_value:</strong> 16</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-255">
<span class="sig-name descname"><span class="pre">lora_dropout</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-255" title="Link to this definition">#</a></dt>
<dd><p>The dropout probability for Lora layers.</p>
<p><strong>type:</strong> float</p>
<p><strong>default_value:</strong> 0.05</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-256">
<span class="sig-name descname"><span class="pre">target_modules</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-256" title="Link to this definition">#</a></dt>
<dd><p>Target modules</p>
<p><strong>type:</strong> List[str]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-257">
<span class="sig-name descname"><span class="pre">modules_to_save</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-257" title="Link to this definition">#</a></dt>
<dd><p>List of modules apart from LoRA layers to be set as trainable and saved in the final checkpoint.</p>
<p><strong>type:</strong> None</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-258">
<span class="sig-name descname"><span class="pre">torch_dtype</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-258" title="Link to this definition">#</a></dt>
<dd><p>Data type to use for training. Should be one of <cite>bfloat16</cite>, <cite>float16</cite> or <cite>float32</cite>. If <cite>float16</cite> will use fp16 mixed-precision training.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> bfloat16</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-259">
<span class="sig-name descname"><span class="pre">device_map</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-259" title="Link to this definition">#</a></dt>
<dd><p>Device map to use to load the model.</p>
<p><strong>type:</strong> olive.passes.pytorch.lora.DeviceMap | None</p>
<p><strong>default_value:</strong> auto</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-260">
<span class="sig-name descname"><span class="pre">allow_tf32</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-260" title="Link to this definition">#</a></dt>
<dd><p>Whether or not to allow TF32 on Ampere GPUs. Can be used to speed up training. For more information, see ‘<a class="reference external" href="https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices">https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices</a>’</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-261">
<span class="sig-name descname"><span class="pre">ephemeral_gpu_offload</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-261" title="Link to this definition">#</a></dt>
<dd><p>Ephemeral GPU offload</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-262">
<span class="sig-name descname"><span class="pre">train_data_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-262" title="Link to this definition">#</a></dt>
<dd><p>Data config for fine-tuning training.</p>
<p><strong>type:</strong> olive.data.config.DataConfig | Dict</p>
<p><strong>required:</strong> True</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-263">
<span class="sig-name descname"><span class="pre">eval_data_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-263" title="Link to this definition">#</a></dt>
<dd><p>Data config for fine-tuning evaluation. Optional if evaluation is not needed.</p>
<p><strong>type:</strong> olive.data.config.DataConfig | Dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-264">
<span class="sig-name descname"><span class="pre">training_args</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-264" title="Link to this definition">#</a></dt>
<dd><p>Training arguments. If None, will use default arguments. See HFTrainingArguments for more details.</p>
<p><strong>type:</strong> olive.passes.pytorch.lora.HFTrainingArguments | Dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="qlora">
<span id="id4"></span><h2>QLoRA<a class="headerlink" href="#qlora" title="Link to this heading">#</a></h2>
<p>Run QLoRA fine-tuning on a Hugging Face PyTorch model.</p>
<p><strong>Input:</strong> handler.hf.HfModelHandler</p>
<p><strong>Output:</strong> handler.hf.HfModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-double_quant">
<span class="sig-name descname"><span class="pre">double_quant</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-double_quant" title="Link to this definition">#</a></dt>
<dd><p>Whether to use nested quantization where the quantization constants from the first quantization are quantized again.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-quant_type">
<span class="sig-name descname"><span class="pre">quant_type</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-quant_type" title="Link to this definition">#</a></dt>
<dd><p>Quantization data type to use. Should be one of <cite>fp4</cite> or <cite>nf4</cite>.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> nf4</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-compute_dtype">
<span class="sig-name descname"><span class="pre">compute_dtype</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-compute_dtype" title="Link to this definition">#</a></dt>
<dd><p>Computation data type for the quantized modules. If not provided, will use the same dtype as torch_dtype</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-save_quant_config">
<span class="sig-name descname"><span class="pre">save_quant_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-save_quant_config" title="Link to this definition">#</a></dt>
<dd><p>Whether to save the output model with the bitsandbytes quantization config. If False, the base model will be in the original precision. If True, the base model will be quantized on load.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-265">
<span class="sig-name descname"><span class="pre">r</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-265" title="Link to this definition">#</a></dt>
<dd><p>R dimension.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 64</p>
<p><strong>search_defaults:</strong> Categorical([16, 32, 64])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-266">
<span class="sig-name descname"><span class="pre">alpha</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-266" title="Link to this definition">#</a></dt>
<dd><p>The alpha parameter for scaling.</p>
<p><strong>type:</strong> float</p>
<p><strong>default_value:</strong> 16</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-267">
<span class="sig-name descname"><span class="pre">lora_dropout</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-267" title="Link to this definition">#</a></dt>
<dd><p>The dropout probability for Lora layers.</p>
<p><strong>type:</strong> float</p>
<p><strong>default_value:</strong> 0.05</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-268">
<span class="sig-name descname"><span class="pre">target_modules</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-268" title="Link to this definition">#</a></dt>
<dd><p>Target modules</p>
<p><strong>type:</strong> List[str]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-269">
<span class="sig-name descname"><span class="pre">modules_to_save</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-269" title="Link to this definition">#</a></dt>
<dd><p>List of modules apart from LoRA layers to be set as trainable and saved in the final checkpoint.</p>
<p><strong>type:</strong> None</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-270">
<span class="sig-name descname"><span class="pre">torch_dtype</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-270" title="Link to this definition">#</a></dt>
<dd><p>Data type to use for training. Should be one of <cite>bfloat16</cite>, <cite>float16</cite> or <cite>float32</cite>. If <cite>float16</cite> will use fp16 mixed-precision training.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> bfloat16</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-271">
<span class="sig-name descname"><span class="pre">device_map</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-271" title="Link to this definition">#</a></dt>
<dd><p>Device map to use to load the model.</p>
<p><strong>type:</strong> olive.passes.pytorch.lora.DeviceMap | None</p>
<p><strong>default_value:</strong> auto</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-272">
<span class="sig-name descname"><span class="pre">allow_tf32</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-272" title="Link to this definition">#</a></dt>
<dd><p>Whether or not to allow TF32 on Ampere GPUs. Can be used to speed up training. For more information, see ‘<a class="reference external" href="https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices">https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices</a>’</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-273">
<span class="sig-name descname"><span class="pre">ephemeral_gpu_offload</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-273" title="Link to this definition">#</a></dt>
<dd><p>Ephemeral GPU offload</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-274">
<span class="sig-name descname"><span class="pre">train_data_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-274" title="Link to this definition">#</a></dt>
<dd><p>Data config for fine-tuning training.</p>
<p><strong>type:</strong> olive.data.config.DataConfig | Dict</p>
<p><strong>required:</strong> True</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-275">
<span class="sig-name descname"><span class="pre">eval_data_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-275" title="Link to this definition">#</a></dt>
<dd><p>Data config for fine-tuning evaluation. Optional if evaluation is not needed.</p>
<p><strong>type:</strong> olive.data.config.DataConfig | Dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-276">
<span class="sig-name descname"><span class="pre">training_args</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-276" title="Link to this definition">#</a></dt>
<dd><p>Training arguments. If None, will use default arguments. See HFTrainingArguments for more details.</p>
<p><strong>type:</strong> olive.passes.pytorch.lora.HFTrainingArguments | Dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="dora">
<span id="id5"></span><h2>DoRA<a class="headerlink" href="#dora" title="Link to this heading">#</a></h2>
<p>Run DoRA fine-tuning on a Hugging Face PyTorch model.</p>
<p><strong>Input:</strong> handler.hf.HfModelHandler</p>
<p><strong>Output:</strong> handler.hf.HfModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-277">
<span class="sig-name descname"><span class="pre">r</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-277" title="Link to this definition">#</a></dt>
<dd><p>R dimension.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 64</p>
<p><strong>search_defaults:</strong> Categorical([16, 32, 64])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-278">
<span class="sig-name descname"><span class="pre">alpha</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-278" title="Link to this definition">#</a></dt>
<dd><p>The alpha parameter for scaling.</p>
<p><strong>type:</strong> float</p>
<p><strong>default_value:</strong> 16</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-279">
<span class="sig-name descname"><span class="pre">lora_dropout</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-279" title="Link to this definition">#</a></dt>
<dd><p>The dropout probability for Lora layers.</p>
<p><strong>type:</strong> float</p>
<p><strong>default_value:</strong> 0.05</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-280">
<span class="sig-name descname"><span class="pre">target_modules</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-280" title="Link to this definition">#</a></dt>
<dd><p>Target modules</p>
<p><strong>type:</strong> List[str]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-281">
<span class="sig-name descname"><span class="pre">modules_to_save</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-281" title="Link to this definition">#</a></dt>
<dd><p>List of modules apart from LoRA layers to be set as trainable and saved in the final checkpoint.</p>
<p><strong>type:</strong> None</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-282">
<span class="sig-name descname"><span class="pre">torch_dtype</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-282" title="Link to this definition">#</a></dt>
<dd><p>Data type to use for training. Should be one of <cite>bfloat16</cite>, <cite>float16</cite> or <cite>float32</cite>. If <cite>float16</cite> will use fp16 mixed-precision training.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> bfloat16</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-283">
<span class="sig-name descname"><span class="pre">device_map</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-283" title="Link to this definition">#</a></dt>
<dd><p>Device map to use to load the model.</p>
<p><strong>type:</strong> olive.passes.pytorch.lora.DeviceMap | None</p>
<p><strong>default_value:</strong> auto</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-284">
<span class="sig-name descname"><span class="pre">allow_tf32</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-284" title="Link to this definition">#</a></dt>
<dd><p>Whether or not to allow TF32 on Ampere GPUs. Can be used to speed up training. For more information, see ‘<a class="reference external" href="https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices">https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices</a>’</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-285">
<span class="sig-name descname"><span class="pre">ephemeral_gpu_offload</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-285" title="Link to this definition">#</a></dt>
<dd><p>Ephemeral GPU offload</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-286">
<span class="sig-name descname"><span class="pre">train_data_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-286" title="Link to this definition">#</a></dt>
<dd><p>Data config for fine-tuning training.</p>
<p><strong>type:</strong> olive.data.config.DataConfig | Dict</p>
<p><strong>required:</strong> True</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-287">
<span class="sig-name descname"><span class="pre">eval_data_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-287" title="Link to this definition">#</a></dt>
<dd><p>Data config for fine-tuning evaluation. Optional if evaluation is not needed.</p>
<p><strong>type:</strong> olive.data.config.DataConfig | Dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-288">
<span class="sig-name descname"><span class="pre">training_args</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-288" title="Link to this definition">#</a></dt>
<dd><p>Training arguments. If None, will use default arguments. See HFTrainingArguments for more details.</p>
<p><strong>type:</strong> olive.passes.pytorch.lora.HFTrainingArguments | Dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="loftq">
<span id="id6"></span><h2>LoftQ<a class="headerlink" href="#loftq" title="Link to this heading">#</a></h2>
<p>Run LoftQ fine-tuning on a Hugging Face PyTorch model.</p>
<p><strong>Input:</strong> handler.hf.HfModelHandler</p>
<p><strong>Output:</strong> handler.hf.HfModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-loftq_iter">
<span class="sig-name descname"><span class="pre">loftq_iter</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-loftq_iter" title="Link to this definition">#</a></dt>
<dd><p>Number of LoftQ iterations.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-289">
<span class="sig-name descname"><span class="pre">compute_dtype</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-289" title="Link to this definition">#</a></dt>
<dd><p>Computation data type for the quantized modules. If not provided, will use the same dtype as torch_dtype</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-290">
<span class="sig-name descname"><span class="pre">save_quant_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-290" title="Link to this definition">#</a></dt>
<dd><p>Whether to save the output model with the bitsandbytes quantization config. If False, the base model will be in the original precision. If True, the base model will be quantized on load.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-291">
<span class="sig-name descname"><span class="pre">r</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-291" title="Link to this definition">#</a></dt>
<dd><p>R dimension.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 64</p>
<p><strong>search_defaults:</strong> Categorical([16, 32, 64])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-292">
<span class="sig-name descname"><span class="pre">alpha</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-292" title="Link to this definition">#</a></dt>
<dd><p>The alpha parameter for scaling.</p>
<p><strong>type:</strong> float</p>
<p><strong>default_value:</strong> 16</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-293">
<span class="sig-name descname"><span class="pre">lora_dropout</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-293" title="Link to this definition">#</a></dt>
<dd><p>The dropout probability for Lora layers.</p>
<p><strong>type:</strong> float</p>
<p><strong>default_value:</strong> 0.05</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-294">
<span class="sig-name descname"><span class="pre">target_modules</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-294" title="Link to this definition">#</a></dt>
<dd><p>Target modules</p>
<p><strong>type:</strong> List[str]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-295">
<span class="sig-name descname"><span class="pre">modules_to_save</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-295" title="Link to this definition">#</a></dt>
<dd><p>List of modules apart from LoRA layers to be set as trainable and saved in the final checkpoint.</p>
<p><strong>type:</strong> None</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-296">
<span class="sig-name descname"><span class="pre">torch_dtype</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-296" title="Link to this definition">#</a></dt>
<dd><p>Data type to use for training. Should be one of <cite>bfloat16</cite>, <cite>float16</cite> or <cite>float32</cite>. If <cite>float16</cite> will use fp16 mixed-precision training.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> bfloat16</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-297">
<span class="sig-name descname"><span class="pre">device_map</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-297" title="Link to this definition">#</a></dt>
<dd><p>Device map to use to load the model.</p>
<p><strong>type:</strong> olive.passes.pytorch.lora.DeviceMap | None</p>
<p><strong>default_value:</strong> auto</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-298">
<span class="sig-name descname"><span class="pre">allow_tf32</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-298" title="Link to this definition">#</a></dt>
<dd><p>Whether or not to allow TF32 on Ampere GPUs. Can be used to speed up training. For more information, see ‘<a class="reference external" href="https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices">https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices</a>’</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-299">
<span class="sig-name descname"><span class="pre">ephemeral_gpu_offload</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-299" title="Link to this definition">#</a></dt>
<dd><p>Ephemeral GPU offload</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-300">
<span class="sig-name descname"><span class="pre">train_data_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-300" title="Link to this definition">#</a></dt>
<dd><p>Data config for fine-tuning training.</p>
<p><strong>type:</strong> olive.data.config.DataConfig | Dict</p>
<p><strong>required:</strong> True</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-301">
<span class="sig-name descname"><span class="pre">eval_data_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-301" title="Link to this definition">#</a></dt>
<dd><p>Data config for fine-tuning evaluation. Optional if evaluation is not needed.</p>
<p><strong>type:</strong> olive.data.config.DataConfig | Dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-302">
<span class="sig-name descname"><span class="pre">training_args</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-302" title="Link to this definition">#</a></dt>
<dd><p>Training arguments. If None, will use default arguments. See HFTrainingArguments for more details.</p>
<p><strong>type:</strong> olive.passes.pytorch.lora.HFTrainingArguments | Dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<section id="lora-qlora-loftq-hftrainingarguments">
<span id="lora-hf-training-arguments"></span><h3>LoRA/QLoRA/LoftQ HFTrainingArguments<a class="headerlink" href="#lora-qlora-loftq-hftrainingarguments" title="Link to this heading">#</a></h3>
<dl class="py class pydantic_settings">
<dt class="sig sig-object py" id="olive.passes.pytorch.lora.HFTrainingArguments">
<em class="property"><span class="pre">pydantic</span> <span class="pre">settings</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olive.passes.pytorch.lora.</span></span><span class="sig-name descname"><span class="pre">HFTrainingArguments</span></span><a class="reference internal" href="../_modules/olive/passes/pytorch/lora.html#HFTrainingArguments"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olive.passes.pytorch.lora.HFTrainingArguments" title="Link to this definition">#</a></dt>
<dd><p>Training arguments for transformers.Trainer.</p>
<p>Has the same fields as transformers.TrainingArguments with recommended default values for QLoRA fine-tuning.</p>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="olive.passes.pytorch.lora.HFTrainingArguments.optim">
<em class="property"><span class="pre">field</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">optim</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'paged_adamw_32bit'</span></em><a class="headerlink" href="#olive.passes.pytorch.lora.HFTrainingArguments.optim" title="Link to this definition">#</a></dt>
<dd><p>The optimizer to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="olive.passes.pytorch.lora.HFTrainingArguments.learning_rate">
<em class="property"><span class="pre">field</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">learning_rate</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.0002</span></em><a class="headerlink" href="#olive.passes.pytorch.lora.HFTrainingArguments.learning_rate" title="Link to this definition">#</a></dt>
<dd><p>The initial learning rate for AdamW.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="olive.passes.pytorch.lora.HFTrainingArguments.lr_scheduler_type">
<em class="property"><span class="pre">field</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">lr_scheduler_type</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'constant'</span></em><a class="headerlink" href="#olive.passes.pytorch.lora.HFTrainingArguments.lr_scheduler_type" title="Link to this definition">#</a></dt>
<dd><p>Learning rate schedule. Constant a bit better than cosine, and has advantage for analysis.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="olive.passes.pytorch.lora.HFTrainingArguments.warmup_ratio">
<em class="property"><span class="pre">field</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">warmup_ratio</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.03</span></em><a class="headerlink" href="#olive.passes.pytorch.lora.HFTrainingArguments.warmup_ratio" title="Link to this definition">#</a></dt>
<dd><p>Fraction of steps to do a warmup for.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="olive.passes.pytorch.lora.HFTrainingArguments.evaluation_strategy">
<em class="property"><span class="pre">field</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">evaluation_strategy</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#olive.passes.pytorch.lora.HFTrainingArguments.evaluation_strategy" title="Link to this definition">#</a></dt>
<dd><p>The evaluation strategy to use. Forced to ‘no’ if eval_dataset is not provided. Otherwise, ‘steps’ unless set to ‘epoch’.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="olive.passes.pytorch.lora.HFTrainingArguments.overwrite_output_dir">
<em class="property"><span class="pre">field</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">overwrite_output_dir</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#olive.passes.pytorch.lora.HFTrainingArguments.overwrite_output_dir" title="Link to this definition">#</a></dt>
<dd><p>If True, overwrite the content of output_dir. Otherwise, will continue training if <cite>output_dir</cite> points to a checkpoint directory.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="olive.passes.pytorch.lora.HFTrainingArguments.resume_from_checkpoint">
<em class="property"><span class="pre">field</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">resume_from_checkpoint</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#olive.passes.pytorch.lora.HFTrainingArguments.resume_from_checkpoint" title="Link to this definition">#</a></dt>
<dd><p>The path to a folder with a valid checkpoint for the model. Supercedes any checkpoint found in output_dir.</p>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="quantizationawaretraining">
<span id="quantization-aware-training"></span><h2>QuantizationAwareTraining<a class="headerlink" href="#quantizationawaretraining" title="Link to this heading">#</a></h2>
<p>Run quantization aware training on PyTorch model.</p>
<p><strong>Input:</strong> handler.pytorch.PyTorchModelHandler</p>
<p><strong>Output:</strong> handler.pytorch.PyTorchModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-303">
<span class="sig-name descname"><span class="pre">user_script</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-303" title="Link to this definition">#</a></dt>
<dd><p>Path to user script. The values for other parameters which were assigned function or object names will be imported from this script.</p>
<p><strong>type:</strong> pathlib.Path | str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-304">
<span class="sig-name descname"><span class="pre">script_dir</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-304" title="Link to this definition">#</a></dt>
<dd><p>Directory containing user script dependencies.</p>
<p><strong>type:</strong> pathlib.Path | str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-305">
<span class="sig-name descname"><span class="pre">train_data_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-305" title="Link to this definition">#</a></dt>
<dd><p>Data config for training.</p>
<p><strong>type:</strong> olive.data.config.DataConfig | Dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-val_data_config">
<span class="sig-name descname"><span class="pre">val_data_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-val_data_config" title="Link to this definition">#</a></dt>
<dd><p>Data config for validation.</p>
<p><strong>type:</strong> olive.data.config.DataConfig | Dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-training_loop_func">
<span class="sig-name descname"><span class="pre">training_loop_func</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-training_loop_func" title="Link to this definition">#</a></dt>
<dd><p>Customized training loop function.</p>
<p><strong>type:</strong> Callable | str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-ptl_module">
<span class="sig-name descname"><span class="pre">ptl_module</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-ptl_module" title="Link to this definition">#</a></dt>
<dd><p>LightningModule for PyTorch Lightning trainer. It is a way of encapsulating all the logic related to the training, validation, and testing of a PyTorch model. Please refer to <a class="reference external" href="https://pytorch-lightning.readthedocs.io/en/stable/common/lightning_module.html">https://pytorch-lightning.readthedocs.io/en/stable/common/lightning_module.html</a> for more details.</p>
<p><strong>type:</strong> Callable | str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-ptl_data_module">
<span class="sig-name descname"><span class="pre">ptl_data_module</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-ptl_data_module" title="Link to this definition">#</a></dt>
<dd><p>LightningDataModule for PyTorch Lightning trainer. It is a way of encapsulating all the data-related logic for training, validation, and testing of a PyTorch model. Please refer to <a class="reference external" href="https://pytorch-lightning.readthedocs.io/en/stable/data/datamodule.html">https://pytorch-lightning.readthedocs.io/en/stable/data/datamodule.html</a> for more details.</p>
<p><strong>type:</strong> Callable | str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-num_epochs">
<span class="sig-name descname"><span class="pre">num_epochs</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-num_epochs" title="Link to this definition">#</a></dt>
<dd><p>Maximum number of epochs for training.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-num_steps">
<span class="sig-name descname"><span class="pre">num_steps</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-num_steps" title="Link to this definition">#</a></dt>
<dd><p>Maximum number of steps for training.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> -1</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-do_validate">
<span class="sig-name descname"><span class="pre">do_validate</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-do_validate" title="Link to this definition">#</a></dt>
<dd><p>Whether perform one evaluation epoch over the validation set after training.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-modules_to_fuse">
<span class="sig-name descname"><span class="pre">modules_to_fuse</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-modules_to_fuse" title="Link to this definition">#</a></dt>
<dd><p>List of list of module names to fuse.</p>
<p><strong>type:</strong> List[List[str]]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-qconfig_func">
<span class="sig-name descname"><span class="pre">qconfig_func</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-qconfig_func" title="Link to this definition">#</a></dt>
<dd><p>Customized function to create a QConfig for QAT. Please refer to <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.ao.quantization.qconfig.QConfig.html">https://pytorch.org/docs/stable/generated/torch.ao.quantization.qconfig.QConfig.html</a> for details.</p>
<p><strong>type:</strong> Callable | str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-logger">
<span class="sig-name descname"><span class="pre">logger</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-logger" title="Link to this definition">#</a></dt>
<dd><p>Logger for training.</p>
<p><strong>type:</strong> pytorch_lightning.loggers.logger.Logger | Iterable[pytorch_lightning.loggers.logger.Logger] | Callable | bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-gpus">
<span class="sig-name descname"><span class="pre">gpus</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-gpus" title="Link to this definition">#</a></dt>
<dd><p>Number of GPUs to use.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-seed">
<span class="sig-name descname"><span class="pre">seed</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-seed" title="Link to this definition">#</a></dt>
<dd><p>Random seed for training.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-checkpoint_path">
<span class="sig-name descname"><span class="pre">checkpoint_path</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-checkpoint_path" title="Link to this definition">#</a></dt>
<dd><p>Path to save checkpoints.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="mergeadapterweights">
<span id="merge-adapter-weights"></span><h2>MergeAdapterWeights<a class="headerlink" href="#mergeadapterweights" title="Link to this heading">#</a></h2>
<p>Merge adapter weights into the base model.</p>
<p><strong>Input:</strong> handler.hf.HfModelHandler</p>
<p><strong>Output:</strong> handler.hf.HfModelHandler</p>
</section>
<section id="sparsegpt">
<span id="id7"></span><h2>SparseGPT<a class="headerlink" href="#sparsegpt" title="Link to this heading">#</a></h2>
<p>Run SparseGPT on a Hugging Face PyTorch model.

    See <a class="reference external" href="https://arxiv.org/abs/2301.00774">https://arxiv.org/abs/2301.00774</a> for more details on the algorithm.

    This pass only supports HfModelHandler.
    The transformers model type must be one of [bloom, gpt2, gpt_neox, llama, opt].</p>
<p><strong>Input:</strong> handler.hf.HfModelHandler</p>
<p><strong>Output:</strong> handler.hf.HfModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-sparsity">
<span class="sig-name descname"><span class="pre">sparsity</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-sparsity" title="Link to this definition">#</a></dt>
<dd><p>Target sparsity. This can be a float or a list of two integers. Float is the target sparsity per layer. List [n,m] applies semi-structured (n:m) sparsity patterns. Refer to https://developer.nvidia.com/blog/accelerating-inference-with-sparsity-using-ampere-and-tensorrt/ for more details on 2:4 sparsity pattern.</p>
<p><strong>type:</strong> float | List[int]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-blocksize">
<span class="sig-name descname"><span class="pre">blocksize</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-blocksize" title="Link to this definition">#</a></dt>
<dd><p>Blocksize to use for adaptive mask selection.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 128</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-percdamp">
<span class="sig-name descname"><span class="pre">percdamp</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-percdamp" title="Link to this definition">#</a></dt>
<dd><p>Percentage of the average Hessian diagonal to use for dampening. Must be in [0,1].</p>
<p><strong>type:</strong> float</p>
<p><strong>default_value:</strong> 0.01</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-min_layer">
<span class="sig-name descname"><span class="pre">min_layer</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-min_layer" title="Link to this definition">#</a></dt>
<dd><p>Prune all layers with id &gt;= min_layer.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-max_layer">
<span class="sig-name descname"><span class="pre">max_layer</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-max_layer" title="Link to this definition">#</a></dt>
<dd><p>Prune all layers with id &lt; max_layer.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-layer_name_filter">
<span class="sig-name descname"><span class="pre">layer_name_filter</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-layer_name_filter" title="Link to this definition">#</a></dt>
<dd><p>Only prune layers whose name contains the given string(s).</p>
<p><strong>type:</strong> str | List[str]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-306">
<span class="sig-name descname"><span class="pre">device</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-306" title="Link to this definition">#</a></dt>
<dd><p>Device to use for performing computations. Can be ‘auto, ‘cpu’, ‘cuda’, ‘cuda:0’, etc. If ‘auto’, will use cuda if available. Does not affect the final model.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> auto</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-307">
<span class="sig-name descname"><span class="pre">data_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-307" title="Link to this definition">#</a></dt>
<dd><p>Data config to use for pruning weights. All samples in the data are expected to be of the same length, most likely the max sequence length of the model.</p>
<p><strong>type:</strong> olive.data.config.DataConfig | Dict</p>
<p><strong>required:</strong> True</p>
</dd></dl>

</section>
<section id="slicegpt">
<span id="id8"></span><h2>SliceGPT<a class="headerlink" href="#slicegpt" title="Link to this heading">#</a></h2>
<p>Run SliceGPT on a Hugging Face PyTorch model.

    See <a class="reference external" href="https://arxiv.org/pdf/2401.15024.pdf">https://arxiv.org/pdf/2401.15024.pdf</a> for more details on the algorithm.

    This pass only supports HfModelHandler.</p>
<p><strong>Input:</strong> handler.hf.HfModelHandler</p>
<p><strong>Output:</strong> handler.pytorch.PyTorchModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-calibration_data_config">
<span class="sig-name descname"><span class="pre">calibration_data_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-calibration_data_config" title="Link to this definition">#</a></dt>
<dd><p>Data config for Dataset to calibrate and calculate perplexity on.</p>
<p><strong>type:</strong> olive.data.config.DataConfig | Dict</p>
<p><strong>required:</strong> True</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-calibration_nsamples">
<span class="sig-name descname"><span class="pre">calibration_nsamples</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-calibration_nsamples" title="Link to this definition">#</a></dt>
<dd><p>Number of samples of the calibration data to load.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 128</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-calibration_batch_size">
<span class="sig-name descname"><span class="pre">calibration_batch_size</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-calibration_batch_size" title="Link to this definition">#</a></dt>
<dd><p>Batch size for loading the calibration data.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 16</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-308">
<span class="sig-name descname"><span class="pre">seed</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-308" title="Link to this definition">#</a></dt>
<dd><p>Seed for sampling the calibration data.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 42</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-309">
<span class="sig-name descname"><span class="pre">sparsity</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-309" title="Link to this definition">#</a></dt>
<dd><p>A measure of how much slicing is applied (in the range [0, 1))</p>
<p><strong>type:</strong> float</p>
<p><strong>default_value:</strong> 0.0</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-round_interval">
<span class="sig-name descname"><span class="pre">round_interval</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-round_interval" title="Link to this definition">#</a></dt>
<dd><p>Interval for rounding the weights (the best value may depend on your hardware)</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 8</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-final_orientation">
<span class="sig-name descname"><span class="pre">final_orientation</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-final_orientation" title="Link to this definition">#</a></dt>
<dd><p>Final orientation of the sliced weights. Choices are random or pca.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> random</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="quarot">
<span id="id9"></span><h2>QuaRot<a class="headerlink" href="#quarot" title="Link to this heading">#</a></h2>
<p>Rotate model using QuaRot.

    See <a class="reference external" href="https://arxiv.org/pdf/2404.00456">https://arxiv.org/pdf/2404.00456</a> for more details on the algorithm. Only offline weight rotation is supported.
    Can be followed by a pass such as GPTQ to quantize the rotated model weights.

    This pass only supports HfModelHandler.</p>
<p><strong>Input:</strong> handler.hf.HfModelHandler</p>
<p><strong>Output:</strong> handler.hf.HfModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-310">
<span class="sig-name descname"><span class="pre">seed</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-310" title="Link to this definition">#</a></dt>
<dd><p>Random seed for rotation. Default value is 0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 0</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-rotate_mode">
<span class="sig-name descname"><span class="pre">rotate_mode</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-rotate_mode" title="Link to this definition">#</a></dt>
<dd><p>Rotation method to use. Default value is ‘hadamard’.</p>
<p><strong>type:</strong> olive.passes.pytorch.rotate.RotateBase.RotateMode</p>
<p><strong>default_value:</strong> hadamard</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="spinquant">
<span id="id10"></span><h2>SpinQuant<a class="headerlink" href="#spinquant" title="Link to this heading">#</a></h2>
<p>Rotate model using SpinQuant.

    See <a class="reference external" href="https://arxiv.org/pdf/2405.16406">https://arxiv.org/pdf/2405.16406</a> for more details on the algorithm. Only offline weight rotation is supported.
    Can be followed by a pass such as GPTQ to quantize the rotated model weights.

    This pass only supports HfModelHandler.</p>
<p><strong>Input:</strong> handler.hf.HfModelHandler</p>
<p><strong>Output:</strong> handler.hf.HfModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-311">
<span class="sig-name descname"><span class="pre">seed</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-311" title="Link to this definition">#</a></dt>
<dd><p>Random seed for rotation. Default value is 0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 0</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-312">
<span class="sig-name descname"><span class="pre">rotate_mode</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-312" title="Link to this definition">#</a></dt>
<dd><p>Rotation method to use. Default value is ‘hadamard’.</p>
<p><strong>type:</strong> olive.passes.pytorch.rotate.RotateBase.RotateMode</p>
<p><strong>default_value:</strong> hadamard</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-a_bits">
<span class="sig-name descname"><span class="pre">a_bits</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-a_bits" title="Link to this definition">#</a></dt>
<dd><p>Number of bits for dynamic quantization of activations.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 16</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-a_symmetric">
<span class="sig-name descname"><span class="pre">a_symmetric</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-a_symmetric" title="Link to this definition">#</a></dt>
<dd><p>Whether to use symmetric quantization for activations.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-a_per_token">
<span class="sig-name descname"><span class="pre">a_per_token</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-a_per_token" title="Link to this definition">#</a></dt>
<dd><p>Whether to quantize activations per token. If False, quantize activations per tensor.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-313">
<span class="sig-name descname"><span class="pre">training_args</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-313" title="Link to this definition">#</a></dt>
<dd><p>Training arguments. If None, will use default arguments.</p>
<p><strong>type:</strong> olive.passes.pytorch.rotate.HFTrainingArguments | Dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="gptqquantizer">
<span id="gptq-quantizer"></span><h2>GptqQuantizer<a class="headerlink" href="#gptqquantizer" title="Link to this heading">#</a></h2>
<p>GPTQ quantization using Hugging Face Optimum and export model with onnxruntime optimized kernel.</p>
<p><strong>Input:</strong> handler.hf.HfModelHandler | handler.pytorch.PyTorchModelHandler</p>
<p><strong>Output:</strong> handler.pytorch.PyTorchModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-314">
<span class="sig-name descname"><span class="pre">user_script</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-314" title="Link to this definition">#</a></dt>
<dd><p>Path to user script. The values for other parameters which were assigned function or object names will be imported from this script.</p>
<p><strong>type:</strong> pathlib.Path | str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-315">
<span class="sig-name descname"><span class="pre">script_dir</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-315" title="Link to this definition">#</a></dt>
<dd><p>Directory containing user script dependencies.</p>
<p><strong>type:</strong> pathlib.Path | str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-bits">
<span class="sig-name descname"><span class="pre">bits</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-bits" title="Link to this definition">#</a></dt>
<dd><p>quantization bits. Default value is 4</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 4</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-layers_block_name">
<span class="sig-name descname"><span class="pre">layers_block_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-layers_block_name" title="Link to this definition">#</a></dt>
<dd><p>Block name to quantize. For models can’t be auto filled, you can refer this link to fill these parameters.
<a class="github reference external" href="https://github.com/AutoGPTQ/AutoGPTQ/blob/896d8204bc89a7cfbda42bf3314e13cf4ce20b02/auto_gptq/modeling/llama.py#L19-L26">AutoGPTQ/AutoGPTQ</a></p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-outside_layer_modules">
<span class="sig-name descname"><span class="pre">outside_layer_modules</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-outside_layer_modules" title="Link to this definition">#</a></dt>
<dd><p>Names of other nn modules that in the same level as the transformer layer block. Default value is None.</p>
<p><strong>type:</strong> List[str]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-inside_layer_modules">
<span class="sig-name descname"><span class="pre">inside_layer_modules</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-inside_layer_modules" title="Link to this definition">#</a></dt>
<dd><p>Names of linear layers in transformer layer module. Default value is None.</p>
<p><strong>type:</strong> List[List[str]]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-group_size">
<span class="sig-name descname"><span class="pre">group_size</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-group_size" title="Link to this definition">#</a></dt>
<dd><p>Block size for quantization. Default value is 128.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 128</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-damp_percent">
<span class="sig-name descname"><span class="pre">damp_percent</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-damp_percent" title="Link to this definition">#</a></dt>
<dd><p>Damping factor for quantization. Default value is 0.01.</p>
<p><strong>type:</strong> float</p>
<p><strong>default_value:</strong> 0.01</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-static_groups">
<span class="sig-name descname"><span class="pre">static_groups</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-static_groups" title="Link to this definition">#</a></dt>
<dd><p>Use static groups for quantization. Default value is False.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-true_sequential">
<span class="sig-name descname"><span class="pre">true_sequential</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-true_sequential" title="Link to this definition">#</a></dt>
<dd><p>Use true sequential for quantization. Default value is False.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-desc_act">
<span class="sig-name descname"><span class="pre">desc_act</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-desc_act" title="Link to this definition">#</a></dt>
<dd><p>Use descriptive activation for quantization. Default value is False.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-sym">
<span class="sig-name descname"><span class="pre">sym</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-sym" title="Link to this definition">#</a></dt>
<dd><p>Symmetric quantization. Default value is False.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-316">
<span class="sig-name descname"><span class="pre">data_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-316" title="Link to this definition">#</a></dt>
<dd><p>Data config for quantization. If not provided, wikitest train data will be used for HfModels. Required for PyTorch models.</p>
<p><strong>type:</strong> olive.data.config.DataConfig | Dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="autoawqquantizer">
<span id="awq-quantizer"></span><h2>AutoAWQQuantizer<a class="headerlink" href="#autoawqquantizer" title="Link to this heading">#</a></h2>
<p>AWQ quantization.</p>
<p><strong>Input:</strong> handler.hf.HfModelHandler</p>
<p><strong>Output:</strong> handler.hf.HfModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-317">
<span class="sig-name descname"><span class="pre">user_script</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-317" title="Link to this definition">#</a></dt>
<dd><p>Path to user script. The values for other parameters which were assigned function or object names will be imported from this script.</p>
<p><strong>type:</strong> pathlib.Path | str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-318">
<span class="sig-name descname"><span class="pre">script_dir</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-318" title="Link to this definition">#</a></dt>
<dd><p>Directory containing user script dependencies.</p>
<p><strong>type:</strong> pathlib.Path | str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-input_model_dtype">
<span class="sig-name descname"><span class="pre">input_model_dtype</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-input_model_dtype" title="Link to this definition">#</a></dt>
<dd><p>The input model data type.</p>
<p><strong>type:</strong> olive.passes.pytorch.autoawq.AutoAWQQuantizer.ModelDtype</p>
<p><strong>default_value:</strong> fp16</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-zero_point">
<span class="sig-name descname"><span class="pre">zero_point</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-zero_point" title="Link to this definition">#</a></dt>
<dd><p>Whether to use zero point quantization to calculate the scales and zeros. If False, it use the symmetric quantization.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-q_group_size">
<span class="sig-name descname"><span class="pre">q_group_size</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-q_group_size" title="Link to this definition">#</a></dt>
<dd><p>The group size to use for quantization. Recommended value is 128 and -1 uses per-column quantization.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 128</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-w_bit">
<span class="sig-name descname"><span class="pre">w_bit</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-w_bit" title="Link to this definition">#</a></dt>
<dd><p>The number of bits to quantize to.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 4</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-version">
<span class="sig-name descname"><span class="pre">version</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-version" title="Link to this definition">#</a></dt>
<dd><p>The version of the quantization algorithm to use. gemm is better for big batch_size (e.g. &gt;= 8) otherwise, gemv is better (e.g. &lt; 8 ). gemm models are compatible with Exllama kernels.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> gemm</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-duo_scaling">
<span class="sig-name descname"><span class="pre">duo_scaling</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-duo_scaling" title="Link to this definition">#</a></dt>
<dd><p>Whether to scale using both w/x(True) or just x(False).</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-modules_to_not_convert">
<span class="sig-name descname"><span class="pre">modules_to_not_convert</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-modules_to_not_convert" title="Link to this definition">#</a></dt>
<dd><p>The list of modules to not quantize, useful for quantizing models that explicitly require to have some modules left in their original precision (e.g. Whisper encoder, Llava encoder, Mixtral gate layers). Please refer to AutoAWQ documentation for quantizing HF models.</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> []</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-export_compatible">
<span class="sig-name descname"><span class="pre">export_compatible</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-export_compatible" title="Link to this definition">#</a></dt>
<dd><p>If True, this argument avoids real quantization by only applying the scales quantizing down to FP16.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-319">
<span class="sig-name descname"><span class="pre">data_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-319" title="Link to this definition">#</a></dt>
<dd><p>Data config for quantization. If not provided, pile validation data will be used.</p>
<p><strong>type:</strong> olive.data.config.DataConfig | Dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="torchtrtconversion">
<span id="torch-trt-conversion"></span><h2>TorchTRTConversion<a class="headerlink" href="#torchtrtconversion" title="Link to this heading">#</a></h2>
<p>Convert torch.nn.Linear modules in the transformer layers of a HuggingFace PyTorch model to TensorRT modules.

    The conversion would include fp16 precision and sparse weights, if applicable.
    The entire model is saved using <cite>torch.save</cite> and can be loaded using <cite>torch.load</cite>. Loading the model requires
    <cite>torch-tensorrt</cite> and Olive to be installed.

    This pass only supports HfModelHandler.
    The transformers model type must be one of [bloom, gpt2, gpt_neox, llama, opt].</p>
<p><strong>Input:</strong> handler.hf.HfModelHandler</p>
<p><strong>Output:</strong> handler.pytorch.PyTorchModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-320">
<span class="sig-name descname"><span class="pre">min_layer</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-320" title="Link to this definition">#</a></dt>
<dd><p>Convert all layers with id &gt;= min_layer.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-321">
<span class="sig-name descname"><span class="pre">max_layer</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-321" title="Link to this definition">#</a></dt>
<dd><p>Convert all layers with id &lt; max_layer.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-322">
<span class="sig-name descname"><span class="pre">layer_name_filter</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-322" title="Link to this definition">#</a></dt>
<dd><p>Only convert layers whose name contains the given string(s).</p>
<p><strong>type:</strong> str | List[str]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-323">
<span class="sig-name descname"><span class="pre">float16</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-323" title="Link to this definition">#</a></dt>
<dd><p>Convert entire model to fp16. If False, only the sparse modules are converted to fp16.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-324">
<span class="sig-name descname"><span class="pre">data_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-324" title="Link to this definition">#</a></dt>
<dd><p>Data config to use for compiling module to TensorRT. The batch size of the compiled module is set to the batch size of the first batch of the dataloader.</p>
<p><strong>type:</strong> olive.data.config.DataConfig | Dict</p>
<p><strong>required:</strong> True</p>
</dd></dl>

</section>
</section>
<section id="openvino">
<h1>OpenVINO<a class="headerlink" href="#openvino" title="Link to this heading">#</a></h1>
<section id="openvinoconversion">
<span id="openvino-conversion"></span><h2>OpenVINOConversion<a class="headerlink" href="#openvinoconversion" title="Link to this heading">#</a></h2>
<p>Converts PyTorch, ONNX or TensorFlow Model to OpenVino Model.</p>
<p><strong>Input:</strong> handler.hf.HfModelHandler | handler.pytorch.PyTorchModelHandler | handler.onnx.ONNXModelHandler</p>
<p><strong>Output:</strong> handler.openvino.OpenVINOModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-325">
<span class="sig-name descname"><span class="pre">user_script</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-325" title="Link to this definition">#</a></dt>
<dd><p>Path to user script. The values for other parameters which were assigned function or object names will be imported from this script.</p>
<p><strong>type:</strong> pathlib.Path | str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-326">
<span class="sig-name descname"><span class="pre">script_dir</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-326" title="Link to this definition">#</a></dt>
<dd><p>Directory containing user script dependencies.</p>
<p><strong>type:</strong> pathlib.Path | str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-input_shapes">
<span class="sig-name descname"><span class="pre">input_shapes</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-input_shapes" title="Link to this definition">#</a></dt>
<dd><p>Set or override shapes for model inputs.It configures dynamic and static dimensions in model inputsdepending on your inference requirements.Static parameter is required if static models are required.</p>
<p><strong>type:</strong> Callable | str | List</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-example_input_func">
<span class="sig-name descname"><span class="pre">example_input_func</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-example_input_func" title="Link to this definition">#</a></dt>
<dd><p>Function/function name to generate sample of model input in original framework.For PyTorch it can be torch.Tensor.For Tensorflow it can be tf.Tensor or numpy.ndarray.By default a pytorch float tensor is created.</p>
<p><strong>type:</strong> Callable | str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-compress_to_fp16">
<span class="sig-name descname"><span class="pre">compress_to_fp16</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-compress_to_fp16" title="Link to this definition">#</a></dt>
<dd><p>Compress weights in output OpenVINO model to FP16. Default is True.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-extra_configs">
<span class="sig-name descname"><span class="pre">extra_configs</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-extra_configs" title="Link to this definition">#</a></dt>
<dd><p>Extra configurations for OpenVINO model conversion. extra_config can be set by passing a dictionary where key is the parameter name, and the value is the parameter value. Please check Conversion Parameters documentation for more details: <a class="reference external" href="https://docs.openvino.ai/2023.3/openvino_docs_OV_Converter_UG_Conversion_Options.html">https://docs.openvino.ai/2023.3/openvino_docs_OV_Converter_UG_Conversion_Options.html</a></p>
<p><strong>type:</strong> Dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-model_name">
<span class="sig-name descname"><span class="pre">model_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-model_name" title="Link to this definition">#</a></dt>
<dd><p>Name of output openVINO model.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> ov_model</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-static">
<span class="sig-name descname"><span class="pre">static</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-static" title="Link to this definition">#</a></dt>
<dd><p>Create a static model instead of a dynamic model.Enabled by default.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="openvinoioupdate">
<span id="openvino-ioupdate"></span><h2>OpenVINOIoUpdate<a class="headerlink" href="#openvinoioupdate" title="Link to this heading">#</a></h2>
<p>Converts dynamic OpenVINO Model to static OpenVino Model and updates IO names.</p>
<p><strong>Input:</strong> handler.openvino.OpenVINOModelHandler</p>
<p><strong>Output:</strong> handler.openvino.OpenVINOModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-327">
<span class="sig-name descname"><span class="pre">user_script</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-327" title="Link to this definition">#</a></dt>
<dd><p>Path to user script. The values for other parameters which were assigned function or object names will be imported from this script.</p>
<p><strong>type:</strong> pathlib.Path | str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-328">
<span class="sig-name descname"><span class="pre">script_dir</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-328" title="Link to this definition">#</a></dt>
<dd><p>Directory containing user script dependencies.</p>
<p><strong>type:</strong> pathlib.Path | str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-329">
<span class="sig-name descname"><span class="pre">extra_configs</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-329" title="Link to this definition">#</a></dt>
<dd><p>Extra configurations for OpenVINO model conversion. extra_config can be set by passing a dictionary where key is the parameter name, and the value is the parameter value. Please check Conversion Parameters documentation for more details: <a class="reference external" href="https://docs.openvino.ai/2025/openvino-workflow/model-preparation/conversion-parameters.html">https://docs.openvino.ai/2025/openvino-workflow/model-preparation/conversion-parameters.html</a></p>
<p><strong>type:</strong> Dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-330">
<span class="sig-name descname"><span class="pre">input_shapes</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-330" title="Link to this definition">#</a></dt>
<dd><p>Reshapes the model with given inputs. It configures dynamic and static dimensions in model inputs depending on your inference requirements. Static parameter is required to be enabled if static dimensions are required.</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-331">
<span class="sig-name descname"><span class="pre">static</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-331" title="Link to this definition">#</a></dt>
<dd><p>Create a static model instead of a dynamic model.Enabled by default.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="openvinoquantization">
<span id="openvino-quantization"></span><h2>OpenVINOQuantization<a class="headerlink" href="#openvinoquantization" title="Link to this heading">#</a></h2>
<p><strong>Input:</strong> handler.openvino.OpenVINOModelHandler</p>
<p><strong>Output:</strong> handler.openvino.OpenVINOModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-332">
<span class="sig-name descname"><span class="pre">user_script</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-332" title="Link to this definition">#</a></dt>
<dd><p>Path to user script. The values for other parameters which were assigned function or object names will be imported from this script.</p>
<p><strong>type:</strong> pathlib.Path | str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-333">
<span class="sig-name descname"><span class="pre">script_dir</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-333" title="Link to this definition">#</a></dt>
<dd><p>Directory containing user script dependencies.</p>
<p><strong>type:</strong> pathlib.Path | str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-334">
<span class="sig-name descname"><span class="pre">data_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-334" title="Link to this definition">#</a></dt>
<dd><p>Data config for calibration.</p>
<p><strong>type:</strong> olive.data.config.DataConfig | Dict</p>
<p><strong>required:</strong> True</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-335">
<span class="sig-name descname"><span class="pre">model_type</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-335" title="Link to this definition">#</a></dt>
<dd><p>Used to specify quantization scheme required for specific type of the model. ‘TRANSFORMER’ is the only supported special quantization scheme to preserve accuracy after quantization of Transformer models (BERT, DistilBERT, etc.). None is default.</p>
<p><strong>type:</strong> olive.passes.openvino.quantization.ModelTypeEnum</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-preset">
<span class="sig-name descname"><span class="pre">preset</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-preset" title="Link to this definition">#</a></dt>
<dd><p>Defines quantization scheme for the model. Supported values: ‘PERFORMANCE’, ‘MIXED’.</p>
<p><strong>type:</strong> olive.passes.openvino.quantization.PresetEnum</p>
<p><strong>default_value:</strong> PERFORMANCE</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-ignored_scope">
<span class="sig-name descname"><span class="pre">ignored_scope</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-ignored_scope" title="Link to this definition">#</a></dt>
<dd><p>This parameter can be used to exclude some layers from the quantization process to preserve the model accuracy. Please refer to <a class="reference external" href="https://docs.openvino.ai/2023.3/basic_quantization_flow.html#tune-quantization-parameters">https://docs.openvino.ai/2023.3/basic_quantization_flow.html#tune-quantization-parameters</a>.</p>
<p><strong>type:</strong> str | List[str]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-ignored_scope_type">
<span class="sig-name descname"><span class="pre">ignored_scope_type</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-ignored_scope_type" title="Link to this definition">#</a></dt>
<dd><p>Defines the type of the ignored scope. Supported values: ‘names’, ‘types’, ‘patterns’.</p>
<p><strong>type:</strong> olive.passes.openvino.quantization.IgnoreScopeTypeEnum</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-target_device">
<span class="sig-name descname"><span class="pre">target_device</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-target_device" title="Link to this definition">#</a></dt>
<dd><p>Target device for the model. Supported values: ‘any’, ‘cpu’, ‘gpu’, ‘cpu_spr’, ‘npu’. Default value is the same as the accelerator type of this workflow run.</p>
<p><strong>type:</strong> olive.hardware.accelerator.Device</p>
<p><strong>default_value:</strong> cpu</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-transform_fn">
<span class="sig-name descname"><span class="pre">transform_fn</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-transform_fn" title="Link to this definition">#</a></dt>
<dd><p>Transform function for the input data.</p>
<p><strong>type:</strong> Callable | str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-336">
<span class="sig-name descname"><span class="pre">extra_configs</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-336" title="Link to this definition">#</a></dt>
<dd><p>Extra configurations for OpenVINO model quantization. Please refer to <a class="reference external" href="https://docs.openvino.ai/2023.3/basic_quantization_flow.html#tune-quantization-parameters">https://docs.openvino.ai/2023.3/basic_quantization_flow.html#tune-quantization-parameters</a>.</p>
<p><strong>type:</strong> List[Dict]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="openvinoencapsulation">
<span id="openvino-encapsulation"></span><h2>OpenVINOEncapsulation<a class="headerlink" href="#openvinoencapsulation" title="Link to this heading">#</a></h2>
<p>Encapsulates OpenVINO models with onnx context nodes.</p>
<p><strong>Input:</strong> handler.openvino.OpenVINOModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-337">
<span class="sig-name descname"><span class="pre">target_device</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-337" title="Link to this definition">#</a></dt>
<dd><p>Device the encapsulated model should run on.Available devices are cpu, gpu, npu.</p>
<p><strong>type:</strong> olive.hardware.accelerator.Device</p>
<p><strong>default_value:</strong> cpu</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-ov_version">
<span class="sig-name descname"><span class="pre">ov_version</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-ov_version" title="Link to this definition">#</a></dt>
<dd><p>Name of the OpenVINO version to override in model SDK version.Requires a minimum version of OpenVINO 2025.1</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-opset_imports">
<span class="sig-name descname"><span class="pre">opset_imports</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-opset_imports" title="Link to this definition">#</a></dt>
<dd><p>Opset name and version to be add in the generate context model</p>
<p><strong>type:</strong> list</p>
<p><strong>default_value:</strong> [[‘com.microsoft.nchwc’, 1], [‘’, 11], [‘ai.onnx.ml’, 5], [‘com.ms.internal.nhwc’, 11], [‘ai.onnx.training’, 1], [‘ai.onnx.preview.training’, 1], [‘com.microsoft.experimental’, 1], [‘com.microsoft’, 1], [‘org.pytorch.aten’, 1]]</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="openvinooptimumconversion">
<span id="openvino-optimum-conversion"></span><h2>OpenVINOOptimumConversion<a class="headerlink" href="#openvinooptimumconversion" title="Link to this heading">#</a></h2>
<p>Convert a Hugging Face PyTorch model to OpenVINO model using the Optimum export function.</p>
<p><strong>Input:</strong> handler.hf.HfModelHandler</p>
<p><strong>Output:</strong> handler.openvino.OpenVINOModelHandler | handler.composite.CompositeModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-338">
<span class="sig-name descname"><span class="pre">user_script</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-338" title="Link to this definition">#</a></dt>
<dd><p>Path to user script. The values for other parameters which were assigned function or object names will be imported from this script.</p>
<p><strong>type:</strong> pathlib.Path | str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-339">
<span class="sig-name descname"><span class="pre">script_dir</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-339" title="Link to this definition">#</a></dt>
<dd><p>Directory containing user script dependencies.</p>
<p><strong>type:</strong> pathlib.Path | str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-340">
<span class="sig-name descname"><span class="pre">components</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-340" title="Link to this definition">#</a></dt>
<dd><p>List of component models to export. E.g. [‘decoder_model’, ‘decoder_with_past_model’]. None means export all components.</p>
<p><strong>type:</strong> List[str]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-341">
<span class="sig-name descname"><span class="pre">device</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-341" title="Link to this definition">#</a></dt>
<dd><p>The device to use to do the export. Defaults to ‘cpu’.This is the parameter that is directly passed to Optimum Intel export function in certain cases.</p>
<p><strong>type:</strong> olive.hardware.accelerator.Device</p>
<p><strong>default_value:</strong> cpu</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-342">
<span class="sig-name descname"><span class="pre">extra_args</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-342" title="Link to this definition">#</a></dt>
<dd><p>Extra arguments to pass to the <cite>optimum.exporters.openvino.main_export</cite> function.</p>
<p><strong>type:</strong> dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-ov_quant_config">
<span class="sig-name descname"><span class="pre">ov_quant_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-ov_quant_config" title="Link to this definition">#</a></dt>
<dd><p>Parameters for optimum OpenVINO quantization. Please refer to <a class="reference external" href="https://huggingface.co/docs/optimum/main/intel/openvino/optimization#4-bit">https://huggingface.co/docs/optimum/main/intel/openvino/optimization#4-bit</a></p>
<p><strong>type:</strong> dict</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
</section>
<section id="snpe">
<h1>SNPE<a class="headerlink" href="#snpe" title="Link to this heading">#</a></h1>
<section id="snpeconversion">
<span id="snpe-conversion"></span><h2>SNPEConversion<a class="headerlink" href="#snpeconversion" title="Link to this heading">#</a></h2>
<p>Convert ONNX or TensorFlow model to SNPE DLC.

    Uses snpe-tensorflow-to-dlc or snpe-onnx-to-dlc tools from the SNPE SDK.</p>
<p><strong>Input:</strong> handler.onnx.ONNXModelHandler | handler.tensorflow.TensorFlowModelHandler</p>
<p><strong>Output:</strong> handler.snpe.SNPEModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-input_names">
<span class="sig-name descname"><span class="pre">input_names</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-input_names" title="Link to this definition">#</a></dt>
<dd><p>List of input names.</p>
<p><strong>type:</strong> List[str]</p>
<p><strong>required:</strong> True</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-343">
<span class="sig-name descname"><span class="pre">input_shapes</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-343" title="Link to this definition">#</a></dt>
<dd><p>List of input shapes. Must be the same length as input_names.</p>
<p><strong>type:</strong> List[List[int]]</p>
<p><strong>required:</strong> True</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-output_names">
<span class="sig-name descname"><span class="pre">output_names</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-output_names" title="Link to this definition">#</a></dt>
<dd><p>List of output names.</p>
<p><strong>type:</strong> List[str]</p>
<p><strong>required:</strong> True</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-input_types">
<span class="sig-name descname"><span class="pre">input_types</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-input_types" title="Link to this definition">#</a></dt>
<dd><p>List of input types. If not None, it must be a list of the same length as input_names. List members can be None to use default value. Refer to olive.platform_sdk.qualcomm.constants.InputType for valid values.</p>
<p><strong>type:</strong> List[str | None]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-input_layouts">
<span class="sig-name descname"><span class="pre">input_layouts</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-input_layouts" title="Link to this definition">#</a></dt>
<dd><p>List of input layouts. If not None, it must be a list of the same length as input_names. List members can be None to use inferred value. Refer to olive.platform_sdk.qualcomm.constants.InputLayout for valid values.</p>
<p><strong>type:</strong> List[str | None]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-344">
<span class="sig-name descname"><span class="pre">extra_args</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-344" title="Link to this definition">#</a></dt>
<dd><p>Extra arguments to pass to snpe conversion tool. Refer to snpe-onnx-to-dlc and snpe-tensorflow-to-dlc at <a class="reference external" href="https://developer.qualcomm.com/sites/default/files/docs/snpe/tools.html">https://developer.qualcomm.com/sites/default/files/docs/snpe/tools.html</a> for more additional arguments. The value is a string that will be passed as is to the tool. e.g.: –enable_cpu_fallback –priority_hint low</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="snpequantization">
<span id="snpe-quantization"></span><h2>SNPEQuantization<a class="headerlink" href="#snpequantization" title="Link to this heading">#</a></h2>
<p>Quantize SNPE model.

    Uses snpe-dlc-quantize tool from the SNPE SDK.</p>
<p><strong>Input:</strong> handler.snpe.SNPEModelHandler</p>
<p><strong>Output:</strong> handler.snpe.SNPEModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-345">
<span class="sig-name descname"><span class="pre">data_config</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-345" title="Link to this definition">#</a></dt>
<dd><p>Data config for quantization</p>
<p><strong>type:</strong> olive.data.config.DataConfig | Dict</p>
<p><strong>required:</strong> True</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-use_enhanced_quantizer">
<span class="sig-name descname"><span class="pre">use_enhanced_quantizer</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-use_enhanced_quantizer" title="Link to this definition">#</a></dt>
<dd><p>Use the enhanced quantizer feature when quantizing the model. Uses an algorithm to determine optimal range instead of min and max range of data.  It can be useful for quantizing models that have long tails in the distribution of the data being quantized.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> Categorical([True, False])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-enable_htp">
<span class="sig-name descname"><span class="pre">enable_htp</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-enable_htp" title="Link to this definition">#</a></dt>
<dd><p>Pack HTP information in quantized DLC, which is not available in Windows.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> Categorical([True, False])</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-htp_socs">
<span class="sig-name descname"><span class="pre">htp_socs</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-htp_socs" title="Link to this definition">#</a></dt>
<dd><p>List of SoCs to generate HTP Offline cache for.</p>
<p><strong>type:</strong> List[str]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-346">
<span class="sig-name descname"><span class="pre">extra_args</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-346" title="Link to this definition">#</a></dt>
<dd><p>Extra arguments to pass to snpe conversion tool. Refer to <a class="reference external" href="https://developer.qualcomm.com/sites/default/files/docs/snpe/tools.html#tools_snpe-dlc-quantize">https://developer.qualcomm.com/sites/default/files/docs/snpe/tools.html#tools_snpe-dlc-quantize</a> for more additional arguments. The value is a string that will be passed as is to the tool. e.g.: –bias_bitwidth 16 –overwrite_cache_records</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="snpetoonnxconversion">
<span id="snpe-to-onnx-conversion"></span><h2>SNPEtoONNXConversion<a class="headerlink" href="#snpetoonnxconversion" title="Link to this heading">#</a></h2>
<p>Convert a SNPE DLC to ONNX to use with SNPE Execution Provider.

    Creates a ONNX graph with the SNPE DLC as a node.</p>
<p><strong>Input:</strong> handler.snpe.SNPEModelHandler</p>
<p><strong>Output:</strong> handler.onnx.ONNXModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-347">
<span class="sig-name descname"><span class="pre">target_device</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-347" title="Link to this definition">#</a></dt>
<dd><p>Target device for the ONNX model. Refer to oliveolive.platform_sdk.qualcomm.constants.SNPEDevice for valid values.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> cpu</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-348">
<span class="sig-name descname"><span class="pre">target_opset</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-348" title="Link to this definition">#</a></dt>
<dd><p>Target ONNX opset version.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 12</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-349">
<span class="sig-name descname"><span class="pre">save_as_external_data</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-349" title="Link to this definition">#</a></dt>
<dd><p>Serializes tensor data to separate files instead of directly in the ONNX file. Large models (&gt;2GB) may be forced to save external data regardless of the value of this parameter.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-350">
<span class="sig-name descname"><span class="pre">all_tensors_to_one_file</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-350" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, save all tensors to one external file specified by ‘external_data_name’. If false, save each tensor to a file named with the tensor name.</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> True</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-351">
<span class="sig-name descname"><span class="pre">external_data_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-351" title="Link to this definition">#</a></dt>
<dd><p>Effective only if all_tensors_to_one_file is True and save_as_external_data is True. If not specified, the external data file will be named with &lt;model_path_name&gt;.data</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-352">
<span class="sig-name descname"><span class="pre">size_threshold</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-352" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. Threshold for size of data. Only when tensor’s data is &gt;= the size_threshold it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.</p>
<p><strong>type:</strong> int</p>
<p><strong>default_value:</strong> 1024</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-353">
<span class="sig-name descname"><span class="pre">convert_attribute</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-353" title="Link to this definition">#</a></dt>
<dd><p>Effective only if save_as_external_data is True. If true, convert all tensors to external data If false, convert only non-attribute tensors to external data</p>
<p><strong>type:</strong> bool</p>
<p><strong>default_value:</strong> False</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
</section>
<section id="qnn">
<h1>QNN<a class="headerlink" href="#qnn" title="Link to this heading">#</a></h1>
<section id="qnnconversion">
<span id="qnn-conversion"></span><h2>QNNConversion<a class="headerlink" href="#qnnconversion" title="Link to this heading">#</a></h2>
<p>Convert ONNX, TensorFlow, or PyTorch model to QNN C++ model.

    Quantize the model if <cite>–input_list</cite> is provided as extra_args.
    Uses qnn-[framework]-converter tool from the QNN SDK.</p>
<p><strong>Input:</strong> handler.tensorflow.TensorFlowModelHandler | handler.pytorch.PyTorchModelHandler | handler.onnx.ONNXModelHandler</p>
<p><strong>Output:</strong> handler.qnn.QNNModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-input_dim">
<span class="sig-name descname"><span class="pre">input_dim</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-input_dim" title="Link to this definition">#</a></dt>
<dd><p>The names and dimensions of the network input layers specified in the format [input_name comma-separated-dimensions], for example:        [“data 1,224,224,3”] Note that the quotes should always be included in order to handle special characters, spaces, etc. For multiple inputs specify multiple –input_dim on the command line like:        [“data 1,224,224,3”, “data2 1,224,224,3”] If –input_dim is not specified, the input dimensions will be inferred from the model. If –input_dim is specified, the input dimensions will be used as-is.</p>
<p><strong>type:</strong> List[str]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-out_node">
<span class="sig-name descname"><span class="pre">out_node</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-out_node" title="Link to this definition">#</a></dt>
<dd><p>The name of the output node. If not specified, the output node will be inferred from the model. If specified, the output node will be used as-is. Example: [“out_1”, “out_2”]</p>
<p><strong>type:</strong> List[str]</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-354">
<span class="sig-name descname"><span class="pre">extra_args</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-354" title="Link to this definition">#</a></dt>
<dd><p>Extra arguments to pass to qnn-[framework]-converter tool, e.g. –show_unconsumed_nodes –custom_io CUSTOM_IO. See the documentation for more details: <a class="reference external" href="https://docs.qualcomm.com/bundle/publicresource/topics/80-63442-50/tools.html">https://docs.qualcomm.com/bundle/publicresource/topics/80-63442-50/tools.html</a></p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="qnnmodellibgenerator">
<span id="qnn-model-lib-generator"></span><h2>QNNModelLibGenerator<a class="headerlink" href="#qnnmodellibgenerator" title="Link to this heading">#</a></h2>
<p>Compile QNN C++ model source code into QNN model library for a specific target.

    Uses qnn-model-lib-generator tool from the QNN SDK.</p>
<p><strong>Input:</strong> handler.qnn.QNNModelHandler</p>
<p><strong>Output:</strong> handler.qnn.QNNModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-lib_targets">
<span class="sig-name descname"><span class="pre">lib_targets</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-lib_targets" title="Link to this definition">#</a></dt>
<dd><p>Specifies the targets to build the models for. Default: aarch64-android x86_64-linux-clang</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-lib_name">
<span class="sig-name descname"><span class="pre">lib_name</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-lib_name" title="Link to this definition">#</a></dt>
<dd><p>Specifies the name to use for libraries. Default: uses name in &lt;model.bin&gt; if provided,  else generic qnn_model.so</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
<section id="qnncontextbinarygenerator">
<span id="qnn-context-binary-generator"></span><h2>QNNContextBinaryGenerator<a class="headerlink" href="#qnncontextbinarygenerator" title="Link to this heading">#</a></h2>
<p>Create QNN context binary from a QNN model library using a particular backend.

    Uses qnn-context-binary-generator tool from the QNN SDK.</p>
<p><strong>Input:</strong> handler.qnn.QNNModelHandler | handler.snpe.SNPEModelHandler</p>
<p><strong>Output:</strong> handler.qnn.QNNModelHandler</p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-355">
<span class="sig-name descname"><span class="pre">backend</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-355" title="Link to this definition">#</a></dt>
<dd><p>Path to a QNN backend .so library to create the context binary.</p>
<p><strong>type:</strong> str</p>
<p><strong>required:</strong> True</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-binary_file">
<span class="sig-name descname"><span class="pre">binary_file</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-binary_file" title="Link to this definition">#</a></dt>
<dd><p>Name of the binary file to save the context binary to. Saved in the same path as –output_dir option with .bin as the binary file extension. If not provided, no backend binary is created.</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-356">
<span class="sig-name descname"><span class="pre">extra_args</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-356" title="Link to this definition">#</a></dt>
<dd><p>Extra arguments to qnn-context-binary-generator</p>
<p><strong>type:</strong> str</p>
<p><strong>default_value:</strong> None</p>
<p><strong>search_defaults:</strong> None</p>
</dd></dl>

</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="options.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Olive Options</p>
      </div>
    </a>
    <a class="right-next"
       href="../extending/index.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Extending Olive</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Passes</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#onnx">ONNX</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#onnxconversion">OnnxConversion</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#onnxopversionconversion">OnnxOpVersionConversion</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#onnxscriptfusion">OnnxScriptFusion</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#onnxpeepholeoptimizer">OnnxPeepholeOptimizer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#orttransformersoptimization">OrtTransformersOptimization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ortsessionparamstuning">OrtSessionParamsTuning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#onnxfloattofloat16">OnnxFloatToFloat16</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#onnxiodatatypeconverter">OnnxIODataTypeConverter</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ortmixedprecision">OrtMixedPrecision</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#qnnpreprocess">QNNPreprocess</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#onnxquantizationpreprocess">OnnxQuantizationPreprocess</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mixedprecisionoverrides">MixedPrecisionOverrides</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#onnxdynamicquantization">OnnxDynamicQuantization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#onnxstaticquantization">OnnxStaticQuantization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#onnxquantization">OnnxQuantization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#onnxmatmul4quantizer">OnnxMatMul4Quantizer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#graphsurgeries">GraphSurgeries</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#matmulnbitstoqdq">MatMulNBitsToQDQ</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dynamictofixedshape">DynamicToFixedShape</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#incdynamicquantization">IncDynamicQuantization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#incstaticquantization">IncStaticQuantization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#incquantization">IncQuantization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#vitisaiquantization">VitisAIQuantization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#appendprepostprocessingops">AppendPrePostProcessingOps</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#insertbeamsearch">InsertBeamSearch</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#extractadapters">ExtractAdapters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#splitmodel">SplitModel</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#staticllm">StaticLLM</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#epcontextbinarygenerator">EPContextBinaryGenerator</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#composeonnxmodels">ComposeOnnxModels</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optimumconversion">OptimumConversion</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optimummerging">OptimumMerging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelbuilder">ModelBuilder</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch">Pytorch</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#capturesplitinfo">CaptureSplitInfo</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lora">LoRA</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loha">LoHa</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lokr">LoKr</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#qlora">QLoRA</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dora">DoRA</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loftq">LoftQ</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lora-qlora-loftq-hftrainingarguments">LoRA/QLoRA/LoftQ HFTrainingArguments</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#olive.passes.pytorch.lora.HFTrainingArguments"><code class="docutils literal notranslate"><span class="pre">HFTrainingArguments</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#olive.passes.pytorch.lora.HFTrainingArguments.optim"><code class="docutils literal notranslate"><span class="pre">HFTrainingArguments.optim</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#olive.passes.pytorch.lora.HFTrainingArguments.learning_rate"><code class="docutils literal notranslate"><span class="pre">HFTrainingArguments.learning_rate</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#olive.passes.pytorch.lora.HFTrainingArguments.lr_scheduler_type"><code class="docutils literal notranslate"><span class="pre">HFTrainingArguments.lr_scheduler_type</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#olive.passes.pytorch.lora.HFTrainingArguments.warmup_ratio"><code class="docutils literal notranslate"><span class="pre">HFTrainingArguments.warmup_ratio</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#olive.passes.pytorch.lora.HFTrainingArguments.evaluation_strategy"><code class="docutils literal notranslate"><span class="pre">HFTrainingArguments.evaluation_strategy</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#olive.passes.pytorch.lora.HFTrainingArguments.overwrite_output_dir"><code class="docutils literal notranslate"><span class="pre">HFTrainingArguments.overwrite_output_dir</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#olive.passes.pytorch.lora.HFTrainingArguments.resume_from_checkpoint"><code class="docutils literal notranslate"><span class="pre">HFTrainingArguments.resume_from_checkpoint</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quantizationawaretraining">QuantizationAwareTraining</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mergeadapterweights">MergeAdapterWeights</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sparsegpt">SparseGPT</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#slicegpt">SliceGPT</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quarot">QuaRot</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spinquant">SpinQuant</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gptqquantizer">GptqQuantizer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#autoawqquantizer">AutoAWQQuantizer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#torchtrtconversion">TorchTRTConversion</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#openvino">OpenVINO</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#openvinoconversion">OpenVINOConversion</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#openvinoioupdate">OpenVINOIoUpdate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#openvinoquantization">OpenVINOQuantization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#openvinoencapsulation">OpenVINOEncapsulation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#openvinooptimumconversion">OpenVINOOptimumConversion</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#snpe">SNPE</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#snpeconversion">SNPEConversion</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#snpequantization">SNPEQuantization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#snpetoonnxconversion">SNPEtoONNXConversion</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#qnn">QNN</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#qnnconversion">QNNConversion</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#qnnmodellibgenerator">QNNModelLibGenerator</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#qnncontextbinarygenerator">QNNContextBinaryGenerator</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2023-2025, Olive Dev team.
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>