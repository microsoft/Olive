{
    "input_model": { "type": "OnnxModel", "model_path": "models/mobilenetv2-12.onnx" },
    "systems": { "local_system": { "type": "LocalSystem", "accelerators": [ { "device": "cpu" } ] } },
    "data_configs": [
        {
            "name": "accuracy_data_config",
            "user_script": "user_script.py",
            "load_dataset_config": { "type": "local_dataset" },
            "dataloader_config": { "type": "qnn_dataloader", "data_dir": "data", "batch_size": 1 },
            "post_process_data_config": { "type": "qnn_sdk_post_process" }
        },
        {
            "name": "latency_data_config",
            "user_script": "user_script.py",
            "load_dataset_config": { "type": "local_dataset" },
            "dataloader_config": { "type": "qnn_dataloader", "data_dir": "data", "batch_size": 1 }
        }
    ],
    "evaluators": {
        "common_evaluator": {
            "metrics": [
                {
                    "name": "accuracy",
                    "type": "accuracy",
                    "sub_types": [
                        {
                            "name": "accuracy_score",
                            "priority": 1,
                            "metric_config": { "task": "multiclass", "num_classes": 1000 }
                        }
                    ],
                    "data_config": "accuracy_data_config",
                    "user_config": { "inference_settings": { "qnn": { "backend": "libQnnCpu" } } }
                },
                {
                    "name": "latency",
                    "type": "latency",
                    "sub_types": [ { "name": "avg", "priority": 2 } ],
                    "data_config": "latency_data_config",
                    "user_config": { "inference_settings": { "qnn": { "backend": "libQnnCpu" } } }
                }
            ]
        }
    },
    "passes": {
        "converter": { "type": "QNNConversion" },
        "quantization": { "type": "QNNConversion", "extra_args": "--input_list <input_list.txt>" },
        "build_model_lib": { "type": "QNNModelLibGenerator", "lib_targets": "x86_64-linux-clang" }
    },
    "pass_flows": [ [ "converter", "build_model_lib" ], [ "quantization", "build_model_lib" ] ],
    "log_severity_level": 0,
    "host": "local_system",
    "target": "local_system",
    "evaluator": "common_evaluator",
    "cache_dir": "cache",
    "output_dir": "models",
    "evaluate_input_model": false
}
