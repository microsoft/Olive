{
    "input_model": {
        "type": "PyTorchModel",
        "model_path": "stabilityai/stable-diffusion-xl-base-1.0",
        "model_loader": "unet_load",
        "model_script": "user_script.py",
        "io_config": {
            "input_names": [ "sample", "timestep", "encoder_hidden_states", "text_embeds", "time_ids" ],
            "output_names": [ "out_sample" ],
            "dynamic_axes": {
                "sample": {
                    "0": "unet_sample_batch",
                    "1": "unet_sample_channels",
                    "2": "unet_sample_height",
                    "3": "unet_sample_width"
                },
                "timestep": { "0": "unet_time_batch" },
                "encoder_hidden_states": { "0": "unet_hidden_batch", "1": "unet_hidden_sequence" },
                "text_embeds": { "0": "unet_text_embeds_batch", "1": "unet_text_embeds_size" },
                "time_ids": { "0": "unet_time_ids_batch", "1": "unet_time_ids_size" }
            }
        },
        "dummy_inputs_func": "unet_conversion_inputs"
    },
    "systems": {
        "local_system": {
            "type": "LocalSystem",
            "accelerators": [ { "device": "gpu", "execution_providers": [ "DmlExecutionProvider" ] } ]
        }
    },
    "data_configs": [
        {
            "name": "latency_data_config",
            "user_script": "user_script.py",
            "load_dataset_config": { "type": "simple_dataset" },
            "dataloader_config": { "type": "unet_data_loader", "batch_size": 2 }
        },
        {
            "name": "quantize_data_config",
            "user_script": "user_script.py",
            "load_dataset_config": { "type": "local_dataset" },
            "dataloader_config": { "type": "unet_quantize_data_loader", "data_num": 200 }
        }
    ],
    "evaluators": {
        "common_evaluator": {
            "metrics": [
                {
                    "name": "latency",
                    "type": "latency",
                    "sub_types": [ { "name": "avg" } ],
                    "data_config": "latency_data_config"
                }
            ]
        }
    },
    "passes": {
        "convert": {
            "type": "OnnxConversion",
            "target_opset": 17,
            "save_as_external_data": true,
            "all_tensors_to_one_file": true,
            "external_data_name": "weights.pb"
        },
        "optimize": {
            "type": "OrtTransformersOptimization",
            "model_type": "unet",
            "opt_level": 0,
            "float16": true,
            "use_gpu": true,
            "keep_io_types": true,
            "optimization_options": {
                "enable_gelu": true,
                "enable_layer_norm": true,
                "enable_attention": true,
                "use_multi_head_attention": true,
                "enable_skip_layer_norm": false,
                "enable_embed_layer_norm": true,
                "enable_bias_skip_layer_norm": false,
                "enable_bias_gelu": true,
                "enable_gelu_approximation": false,
                "enable_qordered_matmul": false,
                "enable_shape_inference": true,
                "enable_gemm_fast_gelu": false,
                "enable_nhwc_conv": false,
                "enable_group_norm": true,
                "enable_bias_splitgelu": false,
                "enable_packed_qkv": true,
                "enable_packed_kv": true,
                "enable_bias_add": false,
                "group_norm_channels_last": false
            },
            "force_fp32_ops": [ "RandomNormalLike" ],
            "force_fp16_inputs": { "GroupNorm": [ 0, 1, 2 ] }
        },
        "optimize_cuda": {
            "type": "OrtTransformersOptimization",
            "model_type": "unet",
            "opt_level": 0,
            "float16": true,
            "use_gpu": true,
            "keep_io_types": true
        },
        "dynamic_shape_to_fixed": {
            "type": "DynamicToFixedShape",
            "dim_param": [
                "unet_sample_batch",
                "unet_sample_channels",
                "unet_sample_height",
                "unet_sample_width",
                "unet_time_batch",
                "unet_hidden_batch",
                "unet_hidden_sequence",
                "unet_text_embeds_batch",
                "unet_text_embeds_size",
                "unet_time_ids_batch",
                "unet_time_ids_size"
            ],
            "dim_value": [ 1, 4, 64, 64, 1, 1, 77, 1, 1280, 1, 6 ],
            "save_as_external_data": true
        },
        "optimize_qdq": {
            "type": "OrtTransformersOptimization",
            "model_type": "unet",
            "opt_level": 0,
            "optimization_options": {
                "enable_gelu": true,
                "enable_layer_norm": true,
                "enable_attention": false,
                "use_multi_head_attention": false,
                "enable_skip_layer_norm": false,
                "enable_embed_layer_norm": false,
                "enable_bias_skip_layer_norm": false,
                "enable_bias_gelu": false,
                "enable_gelu_approximation": false,
                "enable_qordered_matmul": false,
                "enable_shape_inference": true,
                "enable_gemm_fast_gelu": false,
                "enable_nhwc_conv": false,
                "enable_group_norm": false,
                "enable_bias_splitgelu": false,
                "enable_packed_qkv": false,
                "enable_packed_kv": false,
                "enable_bias_add": false,
                "group_norm_channels_last": false
            }
        },
        "quantization": {
            "type": "OnnxStaticQuantization",
            "data_config": "quantize_data_config",
            "activation_type": "uint16",
            "precision": "uint8",
            "calibrate_method": "MinMax",
            "quant_preprocess": true
        }
    },
    "evaluator": "common_evaluator",
    "evaluate_input_model": false,
    "host": "local_system",
    "target": "local_system",
    "cache_dir": "cache",
    "output_dir": "footprints/unet"
}
