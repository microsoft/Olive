{
    "input_model":{
        "type": "PyTorchModel",
        "config": {
            "hf_config": {
                "model_name": "EleutherAI/gpt-j-6B",
                "task": "text-generation",
                "feature": "causal-lm-with-past"
            }
        }
    },
    "evaluators": {
        "common_evaluator": {
            "metrics":[
                {
                    "name": "latency",
                    "type": "latency",
                    "sub_types": [
                        {"name": "avg", "priority": 1}
                    ],
                    "user_config":{
                        "user_script": "user_script.py",
                        "dataloader_func": "create_dataloader",
                        "batch_size": 1
                    }
                }
            ]
        }
    },
    "passes": {
        "conversion": {
            "type": "OnnxConversion",
            "config": {
                "target_opset": 13,
                "save_as_external_data": true,
                "all_tensors_to_one_file": true
            }
        },
        "quantization": {
            "type": "IncStaticQuantization",
            "config": {
                "quant_format": "QDQ",
                "calibration_sampling_size": [8],
                "recipes": {"optypes_to_exclude_output_quant": ["MatMul"]},
                "user_script": "user_script.py",
                "dataloader_func": "create_onnx_dataloader",
                "save_as_external_data": true,
                "all_tensors_to_one_file": true
            }
        }
    },
    "engine": {
        "log_severity_level": 0,
        "evaluator": "common_evaluator",
        "cache_dir": "cache",
        "output_dir": "models/gptj_inc_static_ptq_cpu"
    }
}
