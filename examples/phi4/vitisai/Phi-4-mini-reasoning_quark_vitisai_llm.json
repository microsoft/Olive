{
    "input_model": { "type": "HFModel", "model_path": "microsoft/Phi-4-mini-reasoning" },
    "passes": {
        "qq": {
            "type": "QuarkQuantization",
            "quant_scheme": "w_uint4_per_group_asym",
            "quant_algo": "gptq",
            "dataset": "pileval_for_awq_benchmark",
            "data_type": "float32",
            "num_calib_data": 128,
            "model_export": [ "hf_format" ],
            "exclude_layers": [  ],
            "quant_config": {
                "name": "gptq",
                "inside_layer_modules": [
                    "self_attn.qkv_proj",
                    "self_attn.o_proj",
                    "mlp.gate_up_proj",
                    "mlp.down_proj"
                ],
                "model_decoder_layers": "model.layers"
            }
        },
        "mg": { "type": "VitisGenerateModelLLM", "packed_const": false, "cpu_only": false }
    },
    "log_severity_level": 1,
    "output_dir": "models/Phi-4-mini-reasoning-vai",
    "cache_dir": "cache",
    "no_artifacts": true
}
