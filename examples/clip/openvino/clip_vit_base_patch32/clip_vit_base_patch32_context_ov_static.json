{
    "input_model": { "type": "HfModel", "model_path": "openai/clip-vit-base-patch32" },
    "systems": {
        "local_system": {
            "type": "LocalSystem",
            "accelerators": [ { "execution_providers": [ "OpenVINOExecutionProvider" ] } ]
        }
    },
    "data_configs": [
        {
            "name": "session_params_tuning_data_config",
            "user_script": "user_script.py",
            "load_dataset_config": { "type": "conceptual_captions_dataset" },
            "dataloader_config": { "batch_size": 1, "drop_last": true }
        }
    ],
    "passes": {
        "optimum_convert": { "type": "OpenVINOOptimumConversion", "extra_args": { "device": "npu" } },
        "ov_quantize": {
            "type": "OpenVINOQuantization",
            "target_device": "npu",
            "data_config": "session_params_tuning_data_config",
            "model_type": "TRANSFORMER",
            "user_script": "user_script.py",
            "transform_fn": "custom_transform_func",
            "extra_configs": [ { "advanced_quantization_parameters": { "smooth_quant_alpha": 0.6 } } ]
        },
        "io_update": {
            "type": "OpenVINOIoUpdate",
            "input_shapes": [ [ 10, 77 ], [ 1, 3, 224, 224 ], [ 10, 77 ] ],
            "static": true
        },
        "encapsulation": { "type": "OpenVINOEncapsulation", "target_device": "npu", "ov_version": "2025.1" }
    },
    "search_strategy": false,
    "host": "local_system",
    "evaluate_input_model": false,
    "output_dir": "models/clip_vit_base_patch32_context_ov"
}
