# Acceleration on CPU
[Whisper optimization with PTQ and pre/post processing](https://github.com/microsoft/Olive/tree/main/examples/whisper)

[BERT optimization with IntelÂ® Neural Compressor Post Training quantization](https://github.com/microsoft/Olive/tree/main/examples/bert#bert-optimization-with-ptq-on-cpu)

[BERT optimization with QAT Customized Training Loop](https://github.com/microsoft/Olive/tree/main/examples/bert#bert-optimization-with-qat-customized-training-loop-on-cpu)

[ResNet optimization with QAT Default Training Loop](https://github.com/microsoft/Olive/tree/main/examples/quantization_aware_training/resnet_qat_default_train_loop_cpu)

[ResNet optimization with QAT PyTorch Lightning Module](https://github.com/microsoft/Olive/tree/main/examples/quantization_aware_training/resnet_qat_lightning_module_cpu)

[ResNet optimization with PTQ using Vitis-AI](https://github.com/microsoft/Olive/tree/main/examples/resnet#resnet-optimization-with-amd-vitis-ai-ptq-on-cpu)

[Cifar10 optimization with OpenVINO for Intel HW](https://github.com/microsoft/Olive/tree/main/examples/cifar10_openvino_intel_hw)

# Acceleration on GPU
[SqueezeNet latency optimization with DirectML](https://github.com/microsoft/Olive/tree/main/examples/directml/squeezenet)

[Stable Diffusion optimization with DirectML](https://github.com/microsoft/Olive/tree/main/examples/directml/stable_diffusion)

[Dolly V2 optimization with DirectML](https://github.com/microsoft/Olive/tree/main/examples/directml/dolly_v2)

# Acceleration on NPU
[Inception model optimization on Qualcomm NPU](https://github.com/microsoft/Olive/tree/main/examples/snpe/inception_snpe_qualcomm_npu)
